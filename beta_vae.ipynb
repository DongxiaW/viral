{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import re, random, pickle, glob, os, difflib\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from utils import *\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root = 'train/'\n",
    "test_root = 'test/'\n",
    "model_root = 'models/'\n",
    "plot_root = 'beta_plots/'\n",
    "train_set = ['x10_reads.fa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_fasta(train_root + train_set[0])\n",
    "train_reads_original = np.array(seqs2onehot(np.array(df.seqs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reads = np.delete(train_reads_original,3,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(169538, 150, 4, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reads = np.expand_dims(train_reads, -1)\n",
    "train_reads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        output = z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, beta, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.beta = beta\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = encoder(data)\n",
    "            reconstruction = decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(data, reconstruction)\n",
    "            )\n",
    "            reconstruction_loss *= 150 * 4\n",
    "            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "            kl_loss = -1*tf.reduce_mean(kl_loss)\n",
    "            total_loss = reconstruction_loss + beta * kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "        }\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7')\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent_dim = 16\n",
    "width = 32\n",
    "input_size = (150,4,1)\n",
    "# filter_size = (10, 4) \n",
    "epochs = 3000\n",
    "batch_size = 1024\n",
    "beta = 10e-10\n",
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_num = 'beta_vae'\n",
    "ckpt_dir = os.path.join(model_root, ckpt_num, '')\n",
    "if (os.path.isdir(ckpt_dir) == False):\n",
    "    os.mkdir(os.path.join(ckpt_dir, ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 128)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2432)              313728    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 19, 4, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 38, 4, 32)         40992     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 76, 4, 32)         40992     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 76, 4, 32)         128       \n",
      "_________________________________________________________________\n",
      "cropping2d (Cropping2D)      (None, 75, 4, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 150, 4, 32)        40992     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 150, 4, 1)         1281      \n",
      "=================================================================\n",
      "Total params: 438,113\n",
      "Trainable params: 438,049\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3000\n",
      "WARNING:tensorflow:From /opt/conda/envs/ecseg/lib/python3.7/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "INFO:tensorflow:batch_all_reduce: 26 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 26 all-reduces with algorithm = nccl, num_packs = 1\n",
      "166/166 [==============================] - 3s 21ms/step - loss: 342.9047 - reconstruction_loss: 342.9047 - kl_loss: 1.2483\n",
      "Epoch 2/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 335.8340 - reconstruction_loss: 335.8340 - kl_loss: 1.6431\n",
      "Epoch 3/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 335.6287 - reconstruction_loss: 335.6287 - kl_loss: 2.2118\n",
      "Epoch 4/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 335.5215 - reconstruction_loss: 335.5215 - kl_loss: 3.5884\n",
      "Epoch 5/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 335.4163 - reconstruction_loss: 335.4163 - kl_loss: 5.2568\n",
      "Epoch 6/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 335.4169 - reconstruction_loss: 335.4169 - kl_loss: 6.6270\n",
      "Epoch 7/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 335.4316 - reconstruction_loss: 335.4316 - kl_loss: 7.5719\n",
      "Epoch 8/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 335.4171 - reconstruction_loss: 335.4171 - kl_loss: 8.2612\n",
      "Epoch 9/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 335.3657 - reconstruction_loss: 335.3657 - kl_loss: 8.7223\n",
      "Epoch 10/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 335.4040 - reconstruction_loss: 335.4040 - kl_loss: 8.9589\n",
      "Epoch 11/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 335.4539 - reconstruction_loss: 335.4539 - kl_loss: 9.1124\n",
      "Epoch 12/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 335.3444 - reconstruction_loss: 335.3444 - kl_loss: 9.1473\n",
      "Epoch 13/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 335.3693 - reconstruction_loss: 335.3693 - kl_loss: 8.9528\n",
      "Epoch 14/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 335.3645 - reconstruction_loss: 335.3645 - kl_loss: 8.3484\n",
      "Epoch 15/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 335.2848 - reconstruction_loss: 335.2848 - kl_loss: 7.3010\n",
      "Epoch 16/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 333.8158 - reconstruction_loss: 333.8158 - kl_loss: 7.9115\n",
      "Epoch 17/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 330.9729 - reconstruction_loss: 330.9729 - kl_loss: 9.6652\n",
      "Epoch 18/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 327.5060 - reconstruction_loss: 327.5060 - kl_loss: 12.7750\n",
      "Epoch 19/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 326.0455 - reconstruction_loss: 326.0455 - kl_loss: 14.4261\n",
      "Epoch 20/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 325.7725 - reconstruction_loss: 325.7725 - kl_loss: 14.8372\n",
      "Epoch 21/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 325.4469 - reconstruction_loss: 325.4469 - kl_loss: 14.6832\n",
      "Epoch 22/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 325.0791 - reconstruction_loss: 325.0791 - kl_loss: 14.6513\n",
      "Epoch 23/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 324.9506 - reconstruction_loss: 324.9506 - kl_loss: 14.8491\n",
      "Epoch 24/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 324.9632 - reconstruction_loss: 324.9632 - kl_loss: 14.7918\n",
      "Epoch 25/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 324.8757 - reconstruction_loss: 324.8757 - kl_loss: 14.7607\n",
      "Epoch 26/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 324.8042 - reconstruction_loss: 324.8042 - kl_loss: 14.6886\n",
      "Epoch 27/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 324.8717 - reconstruction_loss: 324.8717 - kl_loss: 14.5656\n",
      "Epoch 28/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 324.7301 - reconstruction_loss: 324.7301 - kl_loss: 14.3801\n",
      "Epoch 29/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 324.7185 - reconstruction_loss: 324.7185 - kl_loss: 14.1937\n",
      "Epoch 30/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 324.6546 - reconstruction_loss: 324.6546 - kl_loss: 14.0431\n",
      "Epoch 31/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 324.6295 - reconstruction_loss: 324.6295 - kl_loss: 13.8882\n",
      "Epoch 32/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 324.5869 - reconstruction_loss: 324.5869 - kl_loss: 13.6866\n",
      "Epoch 33/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 324.3045 - reconstruction_loss: 324.3045 - kl_loss: 13.4176\n",
      "Epoch 34/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 324.2800 - reconstruction_loss: 324.2800 - kl_loss: 13.1600\n",
      "Epoch 35/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 324.0032 - reconstruction_loss: 324.0032 - kl_loss: 12.8824\n",
      "Epoch 36/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.8179 - reconstruction_loss: 323.8179 - kl_loss: 12.7482\n",
      "Epoch 37/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.6456 - reconstruction_loss: 323.6456 - kl_loss: 12.6107\n",
      "Epoch 38/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.6576 - reconstruction_loss: 323.6576 - kl_loss: 12.5420\n",
      "Epoch 39/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.6521 - reconstruction_loss: 323.6521 - kl_loss: 12.5076\n",
      "Epoch 40/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.6251 - reconstruction_loss: 323.6251 - kl_loss: 12.5182\n",
      "Epoch 41/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.6349 - reconstruction_loss: 323.6349 - kl_loss: 12.5529\n",
      "Epoch 42/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.5465 - reconstruction_loss: 323.5465 - kl_loss: 12.5200\n",
      "Epoch 43/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.4522 - reconstruction_loss: 323.4522 - kl_loss: 12.4861\n",
      "Epoch 44/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.5849 - reconstruction_loss: 323.5849 - kl_loss: 12.3777\n",
      "Epoch 45/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.5436 - reconstruction_loss: 323.5436 - kl_loss: 12.2975\n",
      "Epoch 46/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.5317 - reconstruction_loss: 323.5317 - kl_loss: 12.1784\n",
      "Epoch 47/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.5438 - reconstruction_loss: 323.5438 - kl_loss: 12.1218\n",
      "Epoch 48/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.5569 - reconstruction_loss: 323.5569 - kl_loss: 11.9924\n",
      "Epoch 49/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.5850 - reconstruction_loss: 323.5850 - kl_loss: 11.9058\n",
      "Epoch 50/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.5076 - reconstruction_loss: 323.5076 - kl_loss: 11.8792\n",
      "Epoch 51/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.5253 - reconstruction_loss: 323.5253 - kl_loss: 11.8085\n",
      "Epoch 52/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.4060 - reconstruction_loss: 323.4060 - kl_loss: 11.7138\n",
      "Epoch 53/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.4558 - reconstruction_loss: 323.4558 - kl_loss: 11.6571\n",
      "Epoch 54/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.4599 - reconstruction_loss: 323.4599 - kl_loss: 11.5991\n",
      "Epoch 55/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.4510 - reconstruction_loss: 323.4510 - kl_loss: 11.5155\n",
      "Epoch 56/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.4409 - reconstruction_loss: 323.4409 - kl_loss: 11.4843\n",
      "Epoch 57/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.4069 - reconstruction_loss: 323.4069 - kl_loss: 11.3922\n",
      "Epoch 58/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.4401 - reconstruction_loss: 323.4401 - kl_loss: 11.3536\n",
      "Epoch 59/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.4164 - reconstruction_loss: 323.4164 - kl_loss: 11.2647\n",
      "Epoch 60/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.4022 - reconstruction_loss: 323.4022 - kl_loss: 11.2012\n",
      "Epoch 61/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.3860 - reconstruction_loss: 323.3860 - kl_loss: 11.1222\n",
      "Epoch 62/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.3037 - reconstruction_loss: 323.3037 - kl_loss: 10.9951\n",
      "Epoch 63/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.3410 - reconstruction_loss: 323.3410 - kl_loss: 10.9170\n",
      "Epoch 64/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.3574 - reconstruction_loss: 323.3574 - kl_loss: 10.7766\n",
      "Epoch 65/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.3004 - reconstruction_loss: 323.3004 - kl_loss: 10.6546\n",
      "Epoch 66/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.2472 - reconstruction_loss: 323.2472 - kl_loss: 10.4628\n",
      "Epoch 67/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.3530 - reconstruction_loss: 323.3530 - kl_loss: 10.2636\n",
      "Epoch 68/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.3321 - reconstruction_loss: 323.3321 - kl_loss: 9.8607\n",
      "Epoch 69/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 323.1420 - reconstruction_loss: 323.1420 - kl_loss: 9.1707\n",
      "Epoch 70/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.9762 - reconstruction_loss: 322.9762 - kl_loss: 8.1069\n",
      "Epoch 71/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.5838 - reconstruction_loss: 322.5838 - kl_loss: 8.7328\n",
      "Epoch 72/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.5720 - reconstruction_loss: 322.5720 - kl_loss: 9.3314\n",
      "Epoch 73/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.4578 - reconstruction_loss: 322.4578 - kl_loss: 9.6192\n",
      "Epoch 74/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.5597 - reconstruction_loss: 322.5597 - kl_loss: 9.8770\n",
      "Epoch 75/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.5606 - reconstruction_loss: 322.5606 - kl_loss: 10.0347\n",
      "Epoch 76/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.5022 - reconstruction_loss: 322.5022 - kl_loss: 10.1430\n",
      "Epoch 77/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.4172 - reconstruction_loss: 322.4172 - kl_loss: 10.2852\n",
      "Epoch 78/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.4318 - reconstruction_loss: 322.4318 - kl_loss: 10.3135\n",
      "Epoch 79/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.4964 - reconstruction_loss: 322.4964 - kl_loss: 10.4725\n",
      "Epoch 80/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.4802 - reconstruction_loss: 322.4802 - kl_loss: 10.5199\n",
      "Epoch 81/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.4454 - reconstruction_loss: 322.4454 - kl_loss: 10.4790\n",
      "Epoch 82/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.4900 - reconstruction_loss: 322.4900 - kl_loss: 10.6052\n",
      "Epoch 83/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.3496 - reconstruction_loss: 322.3496 - kl_loss: 10.6564\n",
      "Epoch 84/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.4464 - reconstruction_loss: 322.4464 - kl_loss: 10.6472\n",
      "Epoch 85/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.4207 - reconstruction_loss: 322.4207 - kl_loss: 10.7318\n",
      "Epoch 86/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.3847 - reconstruction_loss: 322.3847 - kl_loss: 10.7947\n",
      "Epoch 87/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.4264 - reconstruction_loss: 322.4264 - kl_loss: 10.8429\n",
      "Epoch 88/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.4333 - reconstruction_loss: 322.4333 - kl_loss: 10.8019\n",
      "Epoch 89/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.4070 - reconstruction_loss: 322.4070 - kl_loss: 10.8075\n",
      "Epoch 90/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.3466 - reconstruction_loss: 322.3466 - kl_loss: 10.8525\n",
      "Epoch 91/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.4268 - reconstruction_loss: 322.4268 - kl_loss: 10.9373\n",
      "Epoch 92/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.3740 - reconstruction_loss: 322.3740 - kl_loss: 10.9395\n",
      "Epoch 93/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.4285 - reconstruction_loss: 322.4285 - kl_loss: 10.9265\n",
      "Epoch 94/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 322.2941 - reconstruction_loss: 322.2941 - kl_loss: 10.8874\n",
      "Epoch 95/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.3204 - reconstruction_loss: 322.3204 - kl_loss: 10.9810\n",
      "Epoch 96/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.3332 - reconstruction_loss: 322.3332 - kl_loss: 10.9365\n",
      "Epoch 97/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.4020 - reconstruction_loss: 322.4020 - kl_loss: 11.0003\n",
      "Epoch 98/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.3208 - reconstruction_loss: 322.3208 - kl_loss: 10.9963\n",
      "Epoch 99/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.2829 - reconstruction_loss: 322.2829 - kl_loss: 10.9820\n",
      "Epoch 100/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.3465 - reconstruction_loss: 322.3465 - kl_loss: 11.0365\n",
      "Epoch 101/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.3284 - reconstruction_loss: 322.3284 - kl_loss: 11.0183\n",
      "Epoch 102/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.2758 - reconstruction_loss: 322.2758 - kl_loss: 11.0137\n",
      "Epoch 103/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.2196 - reconstruction_loss: 322.2196 - kl_loss: 11.0586\n",
      "Epoch 104/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.2961 - reconstruction_loss: 322.2961 - kl_loss: 11.1119\n",
      "Epoch 105/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.2779 - reconstruction_loss: 322.2779 - kl_loss: 11.1112\n",
      "Epoch 106/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.0951 - reconstruction_loss: 322.0951 - kl_loss: 11.1135\n",
      "Epoch 107/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.1713 - reconstruction_loss: 322.1713 - kl_loss: 11.1221\n",
      "Epoch 108/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.2692 - reconstruction_loss: 322.2692 - kl_loss: 11.1710\n",
      "Epoch 109/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.2098 - reconstruction_loss: 322.2098 - kl_loss: 11.1597\n",
      "Epoch 110/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.1746 - reconstruction_loss: 322.1746 - kl_loss: 11.1723\n",
      "Epoch 111/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.2108 - reconstruction_loss: 322.2108 - kl_loss: 11.1113\n",
      "Epoch 112/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.1407 - reconstruction_loss: 322.1407 - kl_loss: 11.1867\n",
      "Epoch 113/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.1699 - reconstruction_loss: 322.1699 - kl_loss: 11.1925\n",
      "Epoch 114/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.1945 - reconstruction_loss: 322.1945 - kl_loss: 11.1951\n",
      "Epoch 115/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.2326 - reconstruction_loss: 322.2326 - kl_loss: 11.2490\n",
      "Epoch 116/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.1626 - reconstruction_loss: 322.1626 - kl_loss: 11.2820\n",
      "Epoch 117/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.0947 - reconstruction_loss: 322.0947 - kl_loss: 11.2750\n",
      "Epoch 118/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.0319 - reconstruction_loss: 322.0319 - kl_loss: 11.2950\n",
      "Epoch 119/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.1781 - reconstruction_loss: 322.1781 - kl_loss: 11.3038\n",
      "Epoch 120/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.0987 - reconstruction_loss: 322.0987 - kl_loss: 11.2923\n",
      "Epoch 121/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.9627 - reconstruction_loss: 321.9627 - kl_loss: 11.3019\n",
      "Epoch 122/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.0544 - reconstruction_loss: 322.0544 - kl_loss: 11.3430\n",
      "Epoch 123/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.1798 - reconstruction_loss: 322.1798 - kl_loss: 11.3775\n",
      "Epoch 124/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.0925 - reconstruction_loss: 322.0925 - kl_loss: 11.3920\n",
      "Epoch 125/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.0207 - reconstruction_loss: 322.0207 - kl_loss: 11.4117\n",
      "Epoch 126/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.0330 - reconstruction_loss: 322.0330 - kl_loss: 11.4521\n",
      "Epoch 127/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.1430 - reconstruction_loss: 322.1430 - kl_loss: 11.4735\n",
      "Epoch 128/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.0366 - reconstruction_loss: 322.0366 - kl_loss: 11.4546\n",
      "Epoch 129/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.0443 - reconstruction_loss: 322.0443 - kl_loss: 11.4815\n",
      "Epoch 130/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.9837 - reconstruction_loss: 321.9837 - kl_loss: 11.4845\n",
      "Epoch 131/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.0674 - reconstruction_loss: 322.0674 - kl_loss: 11.5203\n",
      "Epoch 132/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 322.0467 - reconstruction_loss: 322.0467 - kl_loss: 11.5746\n",
      "Epoch 133/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.9781 - reconstruction_loss: 321.9781 - kl_loss: 11.6009\n",
      "Epoch 134/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.9987 - reconstruction_loss: 321.9987 - kl_loss: 11.6229\n",
      "Epoch 135/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.8834 - reconstruction_loss: 321.8834 - kl_loss: 11.6607\n",
      "Epoch 136/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.9182 - reconstruction_loss: 321.9182 - kl_loss: 11.6968\n",
      "Epoch 137/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.8391 - reconstruction_loss: 321.8391 - kl_loss: 11.7135\n",
      "Epoch 138/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.8932 - reconstruction_loss: 321.8932 - kl_loss: 11.7000\n",
      "Epoch 139/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.8927 - reconstruction_loss: 321.8927 - kl_loss: 11.7473\n",
      "Epoch 140/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.8966 - reconstruction_loss: 321.8966 - kl_loss: 11.7549\n",
      "Epoch 141/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.9032 - reconstruction_loss: 321.9032 - kl_loss: 11.7844\n",
      "Epoch 142/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.9134 - reconstruction_loss: 321.9134 - kl_loss: 11.7962\n",
      "Epoch 143/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.8803 - reconstruction_loss: 321.8803 - kl_loss: 11.8303\n",
      "Epoch 144/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.8984 - reconstruction_loss: 321.8984 - kl_loss: 11.8767\n",
      "Epoch 145/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.7997 - reconstruction_loss: 321.7997 - kl_loss: 11.9216\n",
      "Epoch 146/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.9890 - reconstruction_loss: 321.9890 - kl_loss: 11.9405\n",
      "Epoch 147/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.9277 - reconstruction_loss: 321.9277 - kl_loss: 11.9472\n",
      "Epoch 148/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.7554 - reconstruction_loss: 321.7554 - kl_loss: 11.9802\n",
      "Epoch 149/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.8147 - reconstruction_loss: 321.8147 - kl_loss: 12.0022\n",
      "Epoch 150/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.8071 - reconstruction_loss: 321.8071 - kl_loss: 12.0046\n",
      "Epoch 151/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.7807 - reconstruction_loss: 321.7807 - kl_loss: 12.0540\n",
      "Epoch 152/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.7903 - reconstruction_loss: 321.7903 - kl_loss: 12.0621\n",
      "Epoch 153/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 321.7678 - reconstruction_loss: 321.7678 - kl_loss: 12.0984\n",
      "Epoch 154/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.8257 - reconstruction_loss: 321.8257 - kl_loss: 12.1509\n",
      "Epoch 155/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.7764 - reconstruction_loss: 321.7764 - kl_loss: 12.1661\n",
      "Epoch 156/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.8141 - reconstruction_loss: 321.8141 - kl_loss: 12.2160\n",
      "Epoch 157/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.6695 - reconstruction_loss: 321.6695 - kl_loss: 12.2456\n",
      "Epoch 158/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.7597 - reconstruction_loss: 321.7597 - kl_loss: 12.2844\n",
      "Epoch 159/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.8899 - reconstruction_loss: 321.8899 - kl_loss: 12.3102\n",
      "Epoch 160/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.7155 - reconstruction_loss: 321.7155 - kl_loss: 12.3297\n",
      "Epoch 161/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.7370 - reconstruction_loss: 321.7370 - kl_loss: 12.3665\n",
      "Epoch 162/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.7639 - reconstruction_loss: 321.7639 - kl_loss: 12.3858\n",
      "Epoch 163/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.7146 - reconstruction_loss: 321.7146 - kl_loss: 12.4477\n",
      "Epoch 164/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.7505 - reconstruction_loss: 321.7505 - kl_loss: 12.4562\n",
      "Epoch 165/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.7303 - reconstruction_loss: 321.7303 - kl_loss: 12.4985\n",
      "Epoch 166/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.6917 - reconstruction_loss: 321.6917 - kl_loss: 12.5286\n",
      "Epoch 167/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.7611 - reconstruction_loss: 321.7611 - kl_loss: 12.5713\n",
      "Epoch 168/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.6998 - reconstruction_loss: 321.6998 - kl_loss: 12.5693\n",
      "Epoch 169/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.5817 - reconstruction_loss: 321.5817 - kl_loss: 12.6004\n",
      "Epoch 170/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.6529 - reconstruction_loss: 321.6529 - kl_loss: 12.6433\n",
      "Epoch 171/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.7431 - reconstruction_loss: 321.7431 - kl_loss: 12.6738\n",
      "Epoch 172/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.6731 - reconstruction_loss: 321.6731 - kl_loss: 12.6840\n",
      "Epoch 173/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.5674 - reconstruction_loss: 321.5674 - kl_loss: 12.7114\n",
      "Epoch 174/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.6619 - reconstruction_loss: 321.6619 - kl_loss: 12.7611\n",
      "Epoch 175/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.6298 - reconstruction_loss: 321.6298 - kl_loss: 12.8270\n",
      "Epoch 176/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.7364 - reconstruction_loss: 321.7364 - kl_loss: 12.8375\n",
      "Epoch 177/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.5814 - reconstruction_loss: 321.5814 - kl_loss: 12.8776\n",
      "Epoch 178/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.5163 - reconstruction_loss: 321.5163 - kl_loss: 12.9095\n",
      "Epoch 179/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.6527 - reconstruction_loss: 321.6527 - kl_loss: 12.9373\n",
      "Epoch 180/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.6281 - reconstruction_loss: 321.6281 - kl_loss: 12.9424\n",
      "Epoch 181/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.6195 - reconstruction_loss: 321.6195 - kl_loss: 12.9723\n",
      "Epoch 182/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.6300 - reconstruction_loss: 321.6300 - kl_loss: 12.9895\n",
      "Epoch 183/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.5667 - reconstruction_loss: 321.5667 - kl_loss: 13.0189\n",
      "Epoch 184/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.5121 - reconstruction_loss: 321.5121 - kl_loss: 13.0563\n",
      "Epoch 185/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.6205 - reconstruction_loss: 321.6205 - kl_loss: 13.0876\n",
      "Epoch 186/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.5714 - reconstruction_loss: 321.5714 - kl_loss: 13.1103\n",
      "Epoch 187/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.4679 - reconstruction_loss: 321.4679 - kl_loss: 13.1308\n",
      "Epoch 188/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.4791 - reconstruction_loss: 321.4791 - kl_loss: 13.1467\n",
      "Epoch 189/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.5060 - reconstruction_loss: 321.5060 - kl_loss: 13.1700\n",
      "Epoch 190/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.6560 - reconstruction_loss: 321.6560 - kl_loss: 13.1833\n",
      "Epoch 191/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.5378 - reconstruction_loss: 321.5378 - kl_loss: 13.2087\n",
      "Epoch 192/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.5083 - reconstruction_loss: 321.5083 - kl_loss: 13.2458\n",
      "Epoch 193/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.5599 - reconstruction_loss: 321.5599 - kl_loss: 13.2676\n",
      "Epoch 194/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.5232 - reconstruction_loss: 321.5232 - kl_loss: 13.3011\n",
      "Epoch 195/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.5548 - reconstruction_loss: 321.5548 - kl_loss: 13.3336\n",
      "Epoch 196/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.5153 - reconstruction_loss: 321.5153 - kl_loss: 13.3278\n",
      "Epoch 197/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.5358 - reconstruction_loss: 321.5358 - kl_loss: 13.3587\n",
      "Epoch 198/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.6187 - reconstruction_loss: 321.6187 - kl_loss: 13.4016\n",
      "Epoch 199/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.5144 - reconstruction_loss: 321.5144 - kl_loss: 13.4357\n",
      "Epoch 200/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.5671 - reconstruction_loss: 321.5671 - kl_loss: 13.4606\n",
      "Epoch 201/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.5536 - reconstruction_loss: 321.5536 - kl_loss: 13.4633\n",
      "Epoch 202/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.4778 - reconstruction_loss: 321.4778 - kl_loss: 13.5040\n",
      "Epoch 203/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.5745 - reconstruction_loss: 321.5745 - kl_loss: 13.5232\n",
      "Epoch 204/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.4793 - reconstruction_loss: 321.4793 - kl_loss: 13.5377\n",
      "Epoch 205/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.5742 - reconstruction_loss: 321.5742 - kl_loss: 13.5632\n",
      "Epoch 206/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.4445 - reconstruction_loss: 321.4445 - kl_loss: 13.5700\n",
      "Epoch 207/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.5221 - reconstruction_loss: 321.5221 - kl_loss: 13.5995\n",
      "Epoch 208/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.4458 - reconstruction_loss: 321.4458 - kl_loss: 13.6241\n",
      "Epoch 209/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.5154 - reconstruction_loss: 321.5154 - kl_loss: 13.6636\n",
      "Epoch 210/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.5056 - reconstruction_loss: 321.5056 - kl_loss: 13.6936\n",
      "Epoch 211/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.5115 - reconstruction_loss: 321.5115 - kl_loss: 13.6828\n",
      "Epoch 212/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 321.5371 - reconstruction_loss: 321.5371 - kl_loss: 13.6842\n",
      "Epoch 213/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.4315 - reconstruction_loss: 321.4315 - kl_loss: 13.6995\n",
      "Epoch 214/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.4345 - reconstruction_loss: 321.4345 - kl_loss: 13.7707\n",
      "Epoch 215/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.4256 - reconstruction_loss: 321.4256 - kl_loss: 13.7783\n",
      "Epoch 216/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.4220 - reconstruction_loss: 321.4220 - kl_loss: 13.7956\n",
      "Epoch 217/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.4947 - reconstruction_loss: 321.4947 - kl_loss: 13.7883\n",
      "Epoch 218/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.4612 - reconstruction_loss: 321.4612 - kl_loss: 13.8127\n",
      "Epoch 219/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.4516 - reconstruction_loss: 321.4516 - kl_loss: 13.8553\n",
      "Epoch 220/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.3951 - reconstruction_loss: 321.3951 - kl_loss: 13.8609\n",
      "Epoch 221/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.3445 - reconstruction_loss: 321.3445 - kl_loss: 13.8882\n",
      "Epoch 222/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.4119 - reconstruction_loss: 321.4119 - kl_loss: 13.9095\n",
      "Epoch 223/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.4110 - reconstruction_loss: 321.4110 - kl_loss: 13.9215\n",
      "Epoch 224/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.4530 - reconstruction_loss: 321.4530 - kl_loss: 13.9420\n",
      "Epoch 225/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.4341 - reconstruction_loss: 321.4341 - kl_loss: 13.9532\n",
      "Epoch 226/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.4209 - reconstruction_loss: 321.4209 - kl_loss: 13.9572\n",
      "Epoch 227/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.3566 - reconstruction_loss: 321.3566 - kl_loss: 13.9967\n",
      "Epoch 228/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.4313 - reconstruction_loss: 321.4313 - kl_loss: 13.9948\n",
      "Epoch 229/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.3954 - reconstruction_loss: 321.3954 - kl_loss: 14.0031\n",
      "Epoch 230/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.4119 - reconstruction_loss: 321.4119 - kl_loss: 13.9885\n",
      "Epoch 231/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.2919 - reconstruction_loss: 321.2919 - kl_loss: 14.0227\n",
      "Epoch 232/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.4434 - reconstruction_loss: 321.4434 - kl_loss: 14.0310\n",
      "Epoch 233/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.4113 - reconstruction_loss: 321.4113 - kl_loss: 14.0386\n",
      "Epoch 234/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.4221 - reconstruction_loss: 321.4221 - kl_loss: 14.0779\n",
      "Epoch 235/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.3540 - reconstruction_loss: 321.3540 - kl_loss: 14.0578\n",
      "Epoch 236/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.4017 - reconstruction_loss: 321.4017 - kl_loss: 14.0819\n",
      "Epoch 237/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.4339 - reconstruction_loss: 321.4339 - kl_loss: 14.1068\n",
      "Epoch 238/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.3844 - reconstruction_loss: 321.3844 - kl_loss: 14.1069\n",
      "Epoch 239/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.3773 - reconstruction_loss: 321.3773 - kl_loss: 14.1234\n",
      "Epoch 240/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.3181 - reconstruction_loss: 321.3181 - kl_loss: 14.1483\n",
      "Epoch 241/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.2861 - reconstruction_loss: 321.2861 - kl_loss: 14.1463\n",
      "Epoch 242/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.3898 - reconstruction_loss: 321.3898 - kl_loss: 14.1286\n",
      "Epoch 243/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.3912 - reconstruction_loss: 321.3912 - kl_loss: 14.1560\n",
      "Epoch 244/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.3569 - reconstruction_loss: 321.3569 - kl_loss: 14.1676\n",
      "Epoch 245/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.3400 - reconstruction_loss: 321.3400 - kl_loss: 14.1728\n",
      "Epoch 246/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.3291 - reconstruction_loss: 321.3291 - kl_loss: 14.1928\n",
      "Epoch 247/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.2875 - reconstruction_loss: 321.2875 - kl_loss: 14.2229\n",
      "Epoch 248/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.3396 - reconstruction_loss: 321.3396 - kl_loss: 14.2114\n",
      "Epoch 249/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.3321 - reconstruction_loss: 321.3321 - kl_loss: 14.2194\n",
      "Epoch 250/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.3091 - reconstruction_loss: 321.3091 - kl_loss: 14.2488\n",
      "Epoch 251/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.3423 - reconstruction_loss: 321.3423 - kl_loss: 14.2441\n",
      "Epoch 252/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.3962 - reconstruction_loss: 321.3962 - kl_loss: 14.2555\n",
      "Epoch 253/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.2596 - reconstruction_loss: 321.2596 - kl_loss: 14.2766\n",
      "Epoch 254/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.4119 - reconstruction_loss: 321.4119 - kl_loss: 14.2805\n",
      "Epoch 255/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.2638 - reconstruction_loss: 321.2638 - kl_loss: 14.2817\n",
      "Epoch 256/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.2273 - reconstruction_loss: 321.2273 - kl_loss: 14.2958\n",
      "Epoch 257/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.3522 - reconstruction_loss: 321.3522 - kl_loss: 14.3158\n",
      "Epoch 258/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.2551 - reconstruction_loss: 321.2551 - kl_loss: 14.2862\n",
      "Epoch 259/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.1286 - reconstruction_loss: 321.1286 - kl_loss: 14.3019\n",
      "Epoch 260/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.3172 - reconstruction_loss: 321.3172 - kl_loss: 14.3201\n",
      "Epoch 261/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.3188 - reconstruction_loss: 321.3188 - kl_loss: 14.3309\n",
      "Epoch 262/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.2920 - reconstruction_loss: 321.2920 - kl_loss: 14.3628\n",
      "Epoch 263/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.2394 - reconstruction_loss: 321.2394 - kl_loss: 14.3550\n",
      "Epoch 264/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.2473 - reconstruction_loss: 321.2473 - kl_loss: 14.3461\n",
      "Epoch 265/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.2904 - reconstruction_loss: 321.2904 - kl_loss: 14.3644\n",
      "Epoch 266/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.2628 - reconstruction_loss: 321.2628 - kl_loss: 14.3768\n",
      "Epoch 267/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.2941 - reconstruction_loss: 321.2941 - kl_loss: 14.3796\n",
      "Epoch 268/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.3020 - reconstruction_loss: 321.3020 - kl_loss: 14.3996\n",
      "Epoch 269/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.2274 - reconstruction_loss: 321.2274 - kl_loss: 14.4033\n",
      "Epoch 270/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.3395 - reconstruction_loss: 321.3395 - kl_loss: 14.4041\n",
      "Epoch 271/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 321.3381 - reconstruction_loss: 321.3381 - kl_loss: 14.4121\n",
      "Epoch 272/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.2402 - reconstruction_loss: 321.2402 - kl_loss: 14.4165\n",
      "Epoch 273/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.2199 - reconstruction_loss: 321.2199 - kl_loss: 14.4219\n",
      "Epoch 274/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.2294 - reconstruction_loss: 321.2294 - kl_loss: 14.4171\n",
      "Epoch 275/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.2634 - reconstruction_loss: 321.2634 - kl_loss: 14.4111\n",
      "Epoch 276/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.2167 - reconstruction_loss: 321.2167 - kl_loss: 14.4346\n",
      "Epoch 277/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.2676 - reconstruction_loss: 321.2676 - kl_loss: 14.4334\n",
      "Epoch 278/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.3154 - reconstruction_loss: 321.3154 - kl_loss: 14.4325\n",
      "Epoch 279/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.1797 - reconstruction_loss: 321.1797 - kl_loss: 14.4349\n",
      "Epoch 280/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.1878 - reconstruction_loss: 321.1878 - kl_loss: 14.4719\n",
      "Epoch 281/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.1847 - reconstruction_loss: 321.1847 - kl_loss: 14.4725\n",
      "Epoch 282/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.2820 - reconstruction_loss: 321.2820 - kl_loss: 14.4578\n",
      "Epoch 283/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.2698 - reconstruction_loss: 321.2698 - kl_loss: 14.4985\n",
      "Epoch 284/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.3461 - reconstruction_loss: 321.3461 - kl_loss: 14.5003\n",
      "Epoch 285/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.1867 - reconstruction_loss: 321.1867 - kl_loss: 14.4972\n",
      "Epoch 286/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.2219 - reconstruction_loss: 321.2219 - kl_loss: 14.4952\n",
      "Epoch 287/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.1350 - reconstruction_loss: 321.1350 - kl_loss: 14.5184\n",
      "Epoch 288/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.2165 - reconstruction_loss: 321.2165 - kl_loss: 14.5262\n",
      "Epoch 289/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.2569 - reconstruction_loss: 321.2569 - kl_loss: 14.4774\n",
      "Epoch 290/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.1804 - reconstruction_loss: 321.1804 - kl_loss: 14.5236\n",
      "Epoch 291/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.1112 - reconstruction_loss: 321.1112 - kl_loss: 14.5244\n",
      "Epoch 292/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.1484 - reconstruction_loss: 321.1484 - kl_loss: 14.5210\n",
      "Epoch 293/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.2859 - reconstruction_loss: 321.2859 - kl_loss: 14.5360\n",
      "Epoch 294/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.1218 - reconstruction_loss: 321.1218 - kl_loss: 14.5467\n",
      "Epoch 295/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.1784 - reconstruction_loss: 321.1784 - kl_loss: 14.5133\n",
      "Epoch 296/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.1378 - reconstruction_loss: 321.1378 - kl_loss: 14.5179\n",
      "Epoch 297/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.2668 - reconstruction_loss: 321.2668 - kl_loss: 14.5128\n",
      "Epoch 298/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.2302 - reconstruction_loss: 321.2302 - kl_loss: 14.5334\n",
      "Epoch 299/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.2060 - reconstruction_loss: 321.2060 - kl_loss: 14.5198\n",
      "Epoch 300/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.1955 - reconstruction_loss: 321.1955 - kl_loss: 14.5079\n",
      "Epoch 301/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.2159 - reconstruction_loss: 321.2159 - kl_loss: 14.5271\n",
      "Epoch 302/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.1571 - reconstruction_loss: 321.1571 - kl_loss: 14.5503\n",
      "Epoch 303/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.1738 - reconstruction_loss: 321.1738 - kl_loss: 14.5288\n",
      "Epoch 304/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.1578 - reconstruction_loss: 321.1578 - kl_loss: 14.5506\n",
      "Epoch 305/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.1957 - reconstruction_loss: 321.1957 - kl_loss: 14.5310\n",
      "Epoch 306/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0687 - reconstruction_loss: 321.0687 - kl_loss: 14.5717\n",
      "Epoch 307/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0551 - reconstruction_loss: 321.0551 - kl_loss: 14.5421\n",
      "Epoch 308/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0908 - reconstruction_loss: 321.0908 - kl_loss: 14.5440\n",
      "Epoch 309/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.1738 - reconstruction_loss: 321.1738 - kl_loss: 14.5845\n",
      "Epoch 310/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0584 - reconstruction_loss: 321.0584 - kl_loss: 14.5642\n",
      "Epoch 311/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0422 - reconstruction_loss: 321.0422 - kl_loss: 14.5776\n",
      "Epoch 312/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.1441 - reconstruction_loss: 321.1441 - kl_loss: 14.5567\n",
      "Epoch 313/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.1695 - reconstruction_loss: 321.1695 - kl_loss: 14.5396\n",
      "Epoch 314/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0989 - reconstruction_loss: 321.0989 - kl_loss: 14.5530\n",
      "Epoch 315/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0501 - reconstruction_loss: 321.0501 - kl_loss: 14.5592\n",
      "Epoch 316/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.1289 - reconstruction_loss: 321.1289 - kl_loss: 14.5605\n",
      "Epoch 317/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.1294 - reconstruction_loss: 321.1294 - kl_loss: 14.5494\n",
      "Epoch 318/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0801 - reconstruction_loss: 321.0801 - kl_loss: 14.5386\n",
      "Epoch 319/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.1196 - reconstruction_loss: 321.1196 - kl_loss: 14.5516\n",
      "Epoch 320/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0100 - reconstruction_loss: 321.0100 - kl_loss: 14.5645\n",
      "Epoch 321/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0384 - reconstruction_loss: 321.0384 - kl_loss: 14.5676\n",
      "Epoch 322/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.1130 - reconstruction_loss: 321.1130 - kl_loss: 14.5762\n",
      "Epoch 323/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.1136 - reconstruction_loss: 321.1136 - kl_loss: 14.5566\n",
      "Epoch 324/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0051 - reconstruction_loss: 321.0051 - kl_loss: 14.5736\n",
      "Epoch 325/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.9610 - reconstruction_loss: 320.9610 - kl_loss: 14.5845\n",
      "Epoch 326/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0268 - reconstruction_loss: 321.0268 - kl_loss: 14.5674\n",
      "Epoch 327/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0556 - reconstruction_loss: 321.0556 - kl_loss: 14.5767\n",
      "Epoch 328/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0429 - reconstruction_loss: 321.0429 - kl_loss: 14.5787\n",
      "Epoch 329/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0226 - reconstruction_loss: 321.0226 - kl_loss: 14.5620\n",
      "Epoch 330/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 321.1328 - reconstruction_loss: 321.1328 - kl_loss: 14.5617\n",
      "Epoch 331/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0803 - reconstruction_loss: 321.0803 - kl_loss: 14.5574\n",
      "Epoch 332/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0258 - reconstruction_loss: 321.0258 - kl_loss: 14.5637\n",
      "Epoch 333/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0757 - reconstruction_loss: 321.0757 - kl_loss: 14.5851\n",
      "Epoch 334/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0467 - reconstruction_loss: 321.0467 - kl_loss: 14.5399\n",
      "Epoch 335/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.9699 - reconstruction_loss: 320.9699 - kl_loss: 14.5898\n",
      "Epoch 336/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.1504 - reconstruction_loss: 321.1504 - kl_loss: 14.5759\n",
      "Epoch 337/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.9486 - reconstruction_loss: 320.9486 - kl_loss: 14.5836\n",
      "Epoch 338/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.9963 - reconstruction_loss: 320.9963 - kl_loss: 14.5539\n",
      "Epoch 339/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0907 - reconstruction_loss: 321.0907 - kl_loss: 14.5805\n",
      "Epoch 340/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0747 - reconstruction_loss: 321.0747 - kl_loss: 14.5698\n",
      "Epoch 341/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0081 - reconstruction_loss: 321.0081 - kl_loss: 14.5881\n",
      "Epoch 342/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0740 - reconstruction_loss: 321.0740 - kl_loss: 14.5862\n",
      "Epoch 343/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0028 - reconstruction_loss: 321.0028 - kl_loss: 14.5987\n",
      "Epoch 344/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.9942 - reconstruction_loss: 320.9942 - kl_loss: 14.5809\n",
      "Epoch 345/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.9978 - reconstruction_loss: 320.9978 - kl_loss: 14.5996\n",
      "Epoch 346/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0816 - reconstruction_loss: 321.0816 - kl_loss: 14.5852\n",
      "Epoch 347/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0843 - reconstruction_loss: 321.0843 - kl_loss: 14.5589\n",
      "Epoch 348/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.9633 - reconstruction_loss: 320.9633 - kl_loss: 14.5713\n",
      "Epoch 349/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0076 - reconstruction_loss: 321.0076 - kl_loss: 14.5631\n",
      "Epoch 350/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.9265 - reconstruction_loss: 320.9265 - kl_loss: 14.5719\n",
      "Epoch 351/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.8900 - reconstruction_loss: 320.8900 - kl_loss: 14.5801\n",
      "Epoch 352/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.9987 - reconstruction_loss: 320.9987 - kl_loss: 14.5810\n",
      "Epoch 353/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0200 - reconstruction_loss: 321.0200 - kl_loss: 14.5836\n",
      "Epoch 354/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.9724 - reconstruction_loss: 320.9724 - kl_loss: 14.5958\n",
      "Epoch 355/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0298 - reconstruction_loss: 321.0298 - kl_loss: 14.5830\n",
      "Epoch 356/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0431 - reconstruction_loss: 321.0431 - kl_loss: 14.5836\n",
      "Epoch 357/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.9315 - reconstruction_loss: 320.9315 - kl_loss: 14.5948\n",
      "Epoch 358/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0240 - reconstruction_loss: 321.0240 - kl_loss: 14.5740\n",
      "Epoch 359/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0161 - reconstruction_loss: 321.0161 - kl_loss: 14.5552\n",
      "Epoch 360/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.9829 - reconstruction_loss: 320.9829 - kl_loss: 14.5928\n",
      "Epoch 361/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0118 - reconstruction_loss: 321.0118 - kl_loss: 14.5830\n",
      "Epoch 362/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.9163 - reconstruction_loss: 320.9163 - kl_loss: 14.5839\n",
      "Epoch 363/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.9041 - reconstruction_loss: 320.9041 - kl_loss: 14.5739\n",
      "Epoch 364/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0505 - reconstruction_loss: 321.0505 - kl_loss: 14.5673\n",
      "Epoch 365/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.9549 - reconstruction_loss: 320.9549 - kl_loss: 14.5932\n",
      "Epoch 366/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.9038 - reconstruction_loss: 320.9038 - kl_loss: 14.5678\n",
      "Epoch 367/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.8669 - reconstruction_loss: 320.8669 - kl_loss: 14.5511\n",
      "Epoch 368/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.9476 - reconstruction_loss: 320.9476 - kl_loss: 14.5823\n",
      "Epoch 369/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.9263 - reconstruction_loss: 320.9263 - kl_loss: 14.5632\n",
      "Epoch 370/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.9265 - reconstruction_loss: 320.9265 - kl_loss: 14.5628\n",
      "Epoch 371/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.8425 - reconstruction_loss: 320.8425 - kl_loss: 14.5284\n",
      "Epoch 372/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.9430 - reconstruction_loss: 320.9430 - kl_loss: 14.5530\n",
      "Epoch 373/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.9588 - reconstruction_loss: 320.9588 - kl_loss: 14.5369\n",
      "Epoch 374/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.9711 - reconstruction_loss: 320.9711 - kl_loss: 14.5392\n",
      "Epoch 375/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.9404 - reconstruction_loss: 320.9404 - kl_loss: 14.5730\n",
      "Epoch 376/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.9451 - reconstruction_loss: 320.9451 - kl_loss: 14.5211\n",
      "Epoch 377/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.9548 - reconstruction_loss: 320.9548 - kl_loss: 14.5533\n",
      "Epoch 378/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 321.0565 - reconstruction_loss: 321.0565 - kl_loss: 14.5439\n",
      "Epoch 379/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.8822 - reconstruction_loss: 320.8822 - kl_loss: 14.5430\n",
      "Epoch 380/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.9526 - reconstruction_loss: 320.9526 - kl_loss: 14.5488\n",
      "Epoch 381/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.8657 - reconstruction_loss: 320.8657 - kl_loss: 14.5460\n",
      "Epoch 382/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.9365 - reconstruction_loss: 320.9365 - kl_loss: 14.5336\n",
      "Epoch 383/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.8937 - reconstruction_loss: 320.8937 - kl_loss: 14.5531\n",
      "Epoch 384/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.8947 - reconstruction_loss: 320.8947 - kl_loss: 14.5447\n",
      "Epoch 385/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.9172 - reconstruction_loss: 320.9172 - kl_loss: 14.5379\n",
      "Epoch 386/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.8071 - reconstruction_loss: 320.8071 - kl_loss: 14.5672\n",
      "Epoch 387/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.9329 - reconstruction_loss: 320.9329 - kl_loss: 14.5901\n",
      "Epoch 388/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 320.7893 - reconstruction_loss: 320.7893 - kl_loss: 14.6423\n",
      "Epoch 389/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 320.6772 - reconstruction_loss: 320.6772 - kl_loss: 14.7069\n",
      "Epoch 390/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 319.7203 - reconstruction_loss: 319.7203 - kl_loss: 14.5103\n",
      "Epoch 391/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 319.1641 - reconstruction_loss: 319.1641 - kl_loss: 14.1149\n",
      "Epoch 392/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 319.0294 - reconstruction_loss: 319.0294 - kl_loss: 13.9610\n",
      "Epoch 393/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 318.8779 - reconstruction_loss: 318.8779 - kl_loss: 13.8417\n",
      "Epoch 394/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 318.9251 - reconstruction_loss: 318.9251 - kl_loss: 13.7674\n",
      "Epoch 395/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 318.8450 - reconstruction_loss: 318.8450 - kl_loss: 13.7263\n",
      "Epoch 396/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 318.6848 - reconstruction_loss: 318.6848 - kl_loss: 13.7023\n",
      "Epoch 397/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 318.7002 - reconstruction_loss: 318.7002 - kl_loss: 13.6915\n",
      "Epoch 398/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 318.5972 - reconstruction_loss: 318.5972 - kl_loss: 13.7226\n",
      "Epoch 399/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 318.4987 - reconstruction_loss: 318.4987 - kl_loss: 13.7140\n",
      "Epoch 400/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 318.4448 - reconstruction_loss: 318.4448 - kl_loss: 13.7767\n",
      "Epoch 401/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 318.4142 - reconstruction_loss: 318.4142 - kl_loss: 13.7962\n",
      "Epoch 402/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 318.3890 - reconstruction_loss: 318.3890 - kl_loss: 13.8192\n",
      "Epoch 403/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 318.3206 - reconstruction_loss: 318.3206 - kl_loss: 13.8058\n",
      "Epoch 404/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 318.1640 - reconstruction_loss: 318.1640 - kl_loss: 13.8122\n",
      "Epoch 405/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 318.1593 - reconstruction_loss: 318.1593 - kl_loss: 13.8331\n",
      "Epoch 406/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 318.2599 - reconstruction_loss: 318.2599 - kl_loss: 13.8434\n",
      "Epoch 407/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 318.2152 - reconstruction_loss: 318.2152 - kl_loss: 13.8648\n",
      "Epoch 408/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.9926 - reconstruction_loss: 317.9926 - kl_loss: 13.8854\n",
      "Epoch 409/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 318.2002 - reconstruction_loss: 318.2002 - kl_loss: 13.8787\n",
      "Epoch 410/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 318.0528 - reconstruction_loss: 318.0528 - kl_loss: 13.8823\n",
      "Epoch 411/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 318.1276 - reconstruction_loss: 318.1276 - kl_loss: 13.9047\n",
      "Epoch 412/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 318.1637 - reconstruction_loss: 318.1637 - kl_loss: 13.8931\n",
      "Epoch 413/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 318.1545 - reconstruction_loss: 318.1545 - kl_loss: 13.9403\n",
      "Epoch 414/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.9967 - reconstruction_loss: 317.9967 - kl_loss: 13.9250\n",
      "Epoch 415/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 318.0244 - reconstruction_loss: 318.0244 - kl_loss: 13.9262\n",
      "Epoch 416/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 318.0173 - reconstruction_loss: 318.0173 - kl_loss: 13.9462\n",
      "Epoch 417/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.9224 - reconstruction_loss: 317.9224 - kl_loss: 13.9362\n",
      "Epoch 418/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.9223 - reconstruction_loss: 317.9223 - kl_loss: 13.9722\n",
      "Epoch 419/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.9402 - reconstruction_loss: 317.9402 - kl_loss: 14.0080\n",
      "Epoch 420/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.9293 - reconstruction_loss: 317.9293 - kl_loss: 14.0057\n",
      "Epoch 421/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.8919 - reconstruction_loss: 317.8919 - kl_loss: 14.0259\n",
      "Epoch 422/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.8643 - reconstruction_loss: 317.8643 - kl_loss: 14.0329\n",
      "Epoch 423/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 318.0302 - reconstruction_loss: 318.0302 - kl_loss: 14.0264\n",
      "Epoch 424/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.8772 - reconstruction_loss: 317.8772 - kl_loss: 14.0588\n",
      "Epoch 425/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.8810 - reconstruction_loss: 317.8810 - kl_loss: 14.0761\n",
      "Epoch 426/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.9782 - reconstruction_loss: 317.9782 - kl_loss: 14.0850\n",
      "Epoch 427/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.8297 - reconstruction_loss: 317.8297 - kl_loss: 14.1236\n",
      "Epoch 428/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.9376 - reconstruction_loss: 317.9376 - kl_loss: 14.1214\n",
      "Epoch 429/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.8813 - reconstruction_loss: 317.8813 - kl_loss: 14.1142\n",
      "Epoch 430/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.8590 - reconstruction_loss: 317.8590 - kl_loss: 14.1312\n",
      "Epoch 431/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.8653 - reconstruction_loss: 317.8653 - kl_loss: 14.1641\n",
      "Epoch 432/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.8475 - reconstruction_loss: 317.8475 - kl_loss: 14.1825\n",
      "Epoch 433/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.8047 - reconstruction_loss: 317.8047 - kl_loss: 14.1794\n",
      "Epoch 434/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.7437 - reconstruction_loss: 317.7437 - kl_loss: 14.1711\n",
      "Epoch 435/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.8004 - reconstruction_loss: 317.8004 - kl_loss: 14.2108\n",
      "Epoch 436/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.7913 - reconstruction_loss: 317.7913 - kl_loss: 14.2029\n",
      "Epoch 437/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.7921 - reconstruction_loss: 317.7921 - kl_loss: 14.2118\n",
      "Epoch 438/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.7610 - reconstruction_loss: 317.7610 - kl_loss: 14.2292\n",
      "Epoch 439/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.7636 - reconstruction_loss: 317.7636 - kl_loss: 14.2573\n",
      "Epoch 440/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.7788 - reconstruction_loss: 317.7788 - kl_loss: 14.2558\n",
      "Epoch 441/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.7281 - reconstruction_loss: 317.7281 - kl_loss: 14.2876\n",
      "Epoch 442/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.7563 - reconstruction_loss: 317.7563 - kl_loss: 14.2972\n",
      "Epoch 443/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.7982 - reconstruction_loss: 317.7982 - kl_loss: 14.2957\n",
      "Epoch 444/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.7183 - reconstruction_loss: 317.7183 - kl_loss: 14.3114\n",
      "Epoch 445/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.9356 - reconstruction_loss: 317.9356 - kl_loss: 14.3276\n",
      "Epoch 446/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.7630 - reconstruction_loss: 317.7630 - kl_loss: 14.3204\n",
      "Epoch 447/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.5679 - reconstruction_loss: 317.5679 - kl_loss: 14.3334\n",
      "Epoch 448/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 317.6425 - reconstruction_loss: 317.6425 - kl_loss: 14.3466\n",
      "Epoch 449/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.6493 - reconstruction_loss: 317.6493 - kl_loss: 14.3654\n",
      "Epoch 450/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.6846 - reconstruction_loss: 317.6846 - kl_loss: 14.3817\n",
      "Epoch 451/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.7086 - reconstruction_loss: 317.7086 - kl_loss: 14.3819\n",
      "Epoch 452/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.6579 - reconstruction_loss: 317.6579 - kl_loss: 14.4034\n",
      "Epoch 453/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.6015 - reconstruction_loss: 317.6015 - kl_loss: 14.4353\n",
      "Epoch 454/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.6980 - reconstruction_loss: 317.6980 - kl_loss: 14.4330\n",
      "Epoch 455/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.5709 - reconstruction_loss: 317.5709 - kl_loss: 14.4593\n",
      "Epoch 456/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.6304 - reconstruction_loss: 317.6304 - kl_loss: 14.4592\n",
      "Epoch 457/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.6051 - reconstruction_loss: 317.6051 - kl_loss: 14.4795\n",
      "Epoch 458/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.6400 - reconstruction_loss: 317.6400 - kl_loss: 14.4804\n",
      "Epoch 459/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.7672 - reconstruction_loss: 317.7672 - kl_loss: 14.4973\n",
      "Epoch 460/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.5221 - reconstruction_loss: 317.5221 - kl_loss: 14.5141\n",
      "Epoch 461/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.7580 - reconstruction_loss: 317.7580 - kl_loss: 14.5303\n",
      "Epoch 462/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.4833 - reconstruction_loss: 317.4833 - kl_loss: 14.5495\n",
      "Epoch 463/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.6161 - reconstruction_loss: 317.6161 - kl_loss: 14.5578\n",
      "Epoch 464/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.5184 - reconstruction_loss: 317.5184 - kl_loss: 14.5585\n",
      "Epoch 465/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.5768 - reconstruction_loss: 317.5768 - kl_loss: 14.5648\n",
      "Epoch 466/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.5453 - reconstruction_loss: 317.5453 - kl_loss: 14.5882\n",
      "Epoch 467/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.4977 - reconstruction_loss: 317.4977 - kl_loss: 14.5875\n",
      "Epoch 468/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.5705 - reconstruction_loss: 317.5705 - kl_loss: 14.6240\n",
      "Epoch 469/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.5680 - reconstruction_loss: 317.5680 - kl_loss: 14.6336\n",
      "Epoch 470/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.5661 - reconstruction_loss: 317.5661 - kl_loss: 14.6678\n",
      "Epoch 471/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.5152 - reconstruction_loss: 317.5152 - kl_loss: 14.6852\n",
      "Epoch 472/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.5541 - reconstruction_loss: 317.5541 - kl_loss: 14.6740\n",
      "Epoch 473/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.5211 - reconstruction_loss: 317.5211 - kl_loss: 14.7114\n",
      "Epoch 474/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.5778 - reconstruction_loss: 317.5778 - kl_loss: 14.7138\n",
      "Epoch 475/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.5420 - reconstruction_loss: 317.5420 - kl_loss: 14.7098\n",
      "Epoch 476/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.5880 - reconstruction_loss: 317.5880 - kl_loss: 14.7453\n",
      "Epoch 477/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.4108 - reconstruction_loss: 317.4108 - kl_loss: 14.7502\n",
      "Epoch 478/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.5602 - reconstruction_loss: 317.5602 - kl_loss: 14.7715\n",
      "Epoch 479/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.5872 - reconstruction_loss: 317.5872 - kl_loss: 14.7598\n",
      "Epoch 480/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.4904 - reconstruction_loss: 317.4904 - kl_loss: 14.8154\n",
      "Epoch 481/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.5203 - reconstruction_loss: 317.5203 - kl_loss: 14.8159\n",
      "Epoch 482/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.3874 - reconstruction_loss: 317.3874 - kl_loss: 14.8260\n",
      "Epoch 483/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.5762 - reconstruction_loss: 317.5762 - kl_loss: 14.8221\n",
      "Epoch 484/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.3767 - reconstruction_loss: 317.3767 - kl_loss: 14.8440\n",
      "Epoch 485/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.4210 - reconstruction_loss: 317.4210 - kl_loss: 14.8849\n",
      "Epoch 486/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.4606 - reconstruction_loss: 317.4606 - kl_loss: 14.8725\n",
      "Epoch 487/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.3489 - reconstruction_loss: 317.3489 - kl_loss: 14.9030\n",
      "Epoch 488/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.4284 - reconstruction_loss: 317.4284 - kl_loss: 14.9114\n",
      "Epoch 489/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.5222 - reconstruction_loss: 317.5222 - kl_loss: 14.9376\n",
      "Epoch 490/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.5177 - reconstruction_loss: 317.5177 - kl_loss: 14.9284\n",
      "Epoch 491/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.4487 - reconstruction_loss: 317.4487 - kl_loss: 14.9311\n",
      "Epoch 492/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.3824 - reconstruction_loss: 317.3824 - kl_loss: 14.9567\n",
      "Epoch 493/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.3764 - reconstruction_loss: 317.3764 - kl_loss: 14.9571\n",
      "Epoch 494/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.4140 - reconstruction_loss: 317.4140 - kl_loss: 14.9815\n",
      "Epoch 495/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.4796 - reconstruction_loss: 317.4796 - kl_loss: 14.9961\n",
      "Epoch 496/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.4581 - reconstruction_loss: 317.4581 - kl_loss: 15.0111\n",
      "Epoch 497/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.4160 - reconstruction_loss: 317.4160 - kl_loss: 14.9888\n",
      "Epoch 498/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.4374 - reconstruction_loss: 317.4374 - kl_loss: 15.0243\n",
      "Epoch 499/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.3610 - reconstruction_loss: 317.3610 - kl_loss: 15.0472\n",
      "Epoch 500/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.2673 - reconstruction_loss: 317.2673 - kl_loss: 15.0668\n",
      "Epoch 501/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.3576 - reconstruction_loss: 317.3576 - kl_loss: 15.0687\n",
      "Epoch 502/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.4437 - reconstruction_loss: 317.4437 - kl_loss: 15.0696\n",
      "Epoch 503/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.4664 - reconstruction_loss: 317.4664 - kl_loss: 15.0846\n",
      "Epoch 504/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.3826 - reconstruction_loss: 317.3826 - kl_loss: 15.1145\n",
      "Epoch 505/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.3354 - reconstruction_loss: 317.3354 - kl_loss: 15.1082\n",
      "Epoch 506/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.4315 - reconstruction_loss: 317.4315 - kl_loss: 15.0988\n",
      "Epoch 507/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 317.3138 - reconstruction_loss: 317.3138 - kl_loss: 15.1529\n",
      "Epoch 508/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.3392 - reconstruction_loss: 317.3392 - kl_loss: 15.1724\n",
      "Epoch 509/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.2966 - reconstruction_loss: 317.2966 - kl_loss: 15.1321\n",
      "Epoch 510/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.4174 - reconstruction_loss: 317.4174 - kl_loss: 15.1640\n",
      "Epoch 511/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.3822 - reconstruction_loss: 317.3822 - kl_loss: 15.1789\n",
      "Epoch 512/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.3647 - reconstruction_loss: 317.3647 - kl_loss: 15.2069\n",
      "Epoch 513/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.3294 - reconstruction_loss: 317.3294 - kl_loss: 15.2165\n",
      "Epoch 514/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.3700 - reconstruction_loss: 317.3700 - kl_loss: 15.2317\n",
      "Epoch 515/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.3668 - reconstruction_loss: 317.3668 - kl_loss: 15.2442\n",
      "Epoch 516/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.5089 - reconstruction_loss: 317.5089 - kl_loss: 15.2409\n",
      "Epoch 517/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.3242 - reconstruction_loss: 317.3242 - kl_loss: 15.2845\n",
      "Epoch 518/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.3717 - reconstruction_loss: 317.3717 - kl_loss: 15.2753\n",
      "Epoch 519/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.3279 - reconstruction_loss: 317.3279 - kl_loss: 15.3137\n",
      "Epoch 520/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.3015 - reconstruction_loss: 317.3015 - kl_loss: 15.3189\n",
      "Epoch 521/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.2535 - reconstruction_loss: 317.2535 - kl_loss: 15.3136\n",
      "Epoch 522/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.3488 - reconstruction_loss: 317.3488 - kl_loss: 15.3437\n",
      "Epoch 523/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.4458 - reconstruction_loss: 317.4458 - kl_loss: 15.3670\n",
      "Epoch 524/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.3711 - reconstruction_loss: 317.3711 - kl_loss: 15.3552\n",
      "Epoch 525/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1986 - reconstruction_loss: 317.1986 - kl_loss: 15.3938\n",
      "Epoch 526/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.2458 - reconstruction_loss: 317.2458 - kl_loss: 15.4108\n",
      "Epoch 527/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.3388 - reconstruction_loss: 317.3388 - kl_loss: 15.3929\n",
      "Epoch 528/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.2483 - reconstruction_loss: 317.2483 - kl_loss: 15.4067\n",
      "Epoch 529/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.3043 - reconstruction_loss: 317.3043 - kl_loss: 15.4118\n",
      "Epoch 530/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.2281 - reconstruction_loss: 317.2281 - kl_loss: 15.4137\n",
      "Epoch 531/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.3354 - reconstruction_loss: 317.3354 - kl_loss: 15.4256\n",
      "Epoch 532/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.2465 - reconstruction_loss: 317.2465 - kl_loss: 15.4597\n",
      "Epoch 533/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1497 - reconstruction_loss: 317.1497 - kl_loss: 15.4544\n",
      "Epoch 534/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.2299 - reconstruction_loss: 317.2299 - kl_loss: 15.4487\n",
      "Epoch 535/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.2969 - reconstruction_loss: 317.2969 - kl_loss: 15.4556\n",
      "Epoch 536/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.3778 - reconstruction_loss: 317.3778 - kl_loss: 15.4992\n",
      "Epoch 537/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.3154 - reconstruction_loss: 317.3154 - kl_loss: 15.5055\n",
      "Epoch 538/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.3599 - reconstruction_loss: 317.3599 - kl_loss: 15.5170\n",
      "Epoch 539/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.2206 - reconstruction_loss: 317.2206 - kl_loss: 15.5135\n",
      "Epoch 540/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1445 - reconstruction_loss: 317.1445 - kl_loss: 15.5265\n",
      "Epoch 541/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.2541 - reconstruction_loss: 317.2541 - kl_loss: 15.5447\n",
      "Epoch 542/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.3300 - reconstruction_loss: 317.3300 - kl_loss: 15.5692\n",
      "Epoch 543/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.2201 - reconstruction_loss: 317.2201 - kl_loss: 15.5823\n",
      "Epoch 544/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.3817 - reconstruction_loss: 317.3817 - kl_loss: 15.5541\n",
      "Epoch 545/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.2184 - reconstruction_loss: 317.2184 - kl_loss: 15.5952\n",
      "Epoch 546/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.2671 - reconstruction_loss: 317.2671 - kl_loss: 15.5797\n",
      "Epoch 547/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.3201 - reconstruction_loss: 317.3201 - kl_loss: 15.6382\n",
      "Epoch 548/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.2153 - reconstruction_loss: 317.2153 - kl_loss: 15.6198\n",
      "Epoch 549/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.2236 - reconstruction_loss: 317.2236 - kl_loss: 15.6028\n",
      "Epoch 550/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.2683 - reconstruction_loss: 317.2683 - kl_loss: 15.6440\n",
      "Epoch 551/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1867 - reconstruction_loss: 317.1867 - kl_loss: 15.6471\n",
      "Epoch 552/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.2695 - reconstruction_loss: 317.2695 - kl_loss: 15.6860\n",
      "Epoch 553/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1521 - reconstruction_loss: 317.1521 - kl_loss: 15.6634\n",
      "Epoch 554/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.2771 - reconstruction_loss: 317.2771 - kl_loss: 15.6976\n",
      "Epoch 555/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.2054 - reconstruction_loss: 317.2054 - kl_loss: 15.7037\n",
      "Epoch 556/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1916 - reconstruction_loss: 317.1916 - kl_loss: 15.6933\n",
      "Epoch 557/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.2490 - reconstruction_loss: 317.2490 - kl_loss: 15.7208\n",
      "Epoch 558/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1462 - reconstruction_loss: 317.1462 - kl_loss: 15.7209\n",
      "Epoch 559/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.2126 - reconstruction_loss: 317.2126 - kl_loss: 15.7525\n",
      "Epoch 560/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0744 - reconstruction_loss: 317.0744 - kl_loss: 15.7357\n",
      "Epoch 561/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.2203 - reconstruction_loss: 317.2203 - kl_loss: 15.7699\n",
      "Epoch 562/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.2657 - reconstruction_loss: 317.2657 - kl_loss: 15.7718\n",
      "Epoch 563/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.2601 - reconstruction_loss: 317.2601 - kl_loss: 15.7896\n",
      "Epoch 564/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1926 - reconstruction_loss: 317.1926 - kl_loss: 15.8070\n",
      "Epoch 565/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.2678 - reconstruction_loss: 317.2678 - kl_loss: 15.8048\n",
      "Epoch 566/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1605 - reconstruction_loss: 317.1605 - kl_loss: 15.7927\n",
      "Epoch 567/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.2095 - reconstruction_loss: 317.2095 - kl_loss: 15.8458\n",
      "Epoch 568/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0759 - reconstruction_loss: 317.0759 - kl_loss: 15.8522\n",
      "Epoch 569/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1645 - reconstruction_loss: 317.1645 - kl_loss: 15.8722\n",
      "Epoch 570/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1145 - reconstruction_loss: 317.1145 - kl_loss: 15.8945\n",
      "Epoch 571/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1943 - reconstruction_loss: 317.1943 - kl_loss: 15.8917\n",
      "Epoch 572/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.2670 - reconstruction_loss: 317.2670 - kl_loss: 15.9049\n",
      "Epoch 573/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0919 - reconstruction_loss: 317.0919 - kl_loss: 15.9320\n",
      "Epoch 574/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1963 - reconstruction_loss: 317.1963 - kl_loss: 15.9344\n",
      "Epoch 575/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1885 - reconstruction_loss: 317.1885 - kl_loss: 15.9411\n",
      "Epoch 576/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.2461 - reconstruction_loss: 317.2461 - kl_loss: 15.9411\n",
      "Epoch 577/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1142 - reconstruction_loss: 317.1142 - kl_loss: 15.9791\n",
      "Epoch 578/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0898 - reconstruction_loss: 317.0898 - kl_loss: 15.9789\n",
      "Epoch 579/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0976 - reconstruction_loss: 317.0976 - kl_loss: 16.0099\n",
      "Epoch 580/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1271 - reconstruction_loss: 317.1271 - kl_loss: 16.0078\n",
      "Epoch 581/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1905 - reconstruction_loss: 317.1905 - kl_loss: 16.0177\n",
      "Epoch 582/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1883 - reconstruction_loss: 317.1883 - kl_loss: 16.0435\n",
      "Epoch 583/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1688 - reconstruction_loss: 317.1688 - kl_loss: 16.0313\n",
      "Epoch 584/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0363 - reconstruction_loss: 317.0363 - kl_loss: 16.0702\n",
      "Epoch 585/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1159 - reconstruction_loss: 317.1159 - kl_loss: 16.0312\n",
      "Epoch 586/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0438 - reconstruction_loss: 317.0438 - kl_loss: 16.0605\n",
      "Epoch 587/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0511 - reconstruction_loss: 317.0511 - kl_loss: 16.1031\n",
      "Epoch 588/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1101 - reconstruction_loss: 317.1101 - kl_loss: 16.0983\n",
      "Epoch 589/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0162 - reconstruction_loss: 317.0162 - kl_loss: 16.1013\n",
      "Epoch 590/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1137 - reconstruction_loss: 317.1137 - kl_loss: 16.1102\n",
      "Epoch 591/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0516 - reconstruction_loss: 317.0516 - kl_loss: 16.1128\n",
      "Epoch 592/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.2044 - reconstruction_loss: 317.2044 - kl_loss: 16.1362\n",
      "Epoch 593/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1421 - reconstruction_loss: 317.1421 - kl_loss: 16.1516\n",
      "Epoch 594/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.2081 - reconstruction_loss: 317.2081 - kl_loss: 16.1543\n",
      "Epoch 595/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0363 - reconstruction_loss: 317.0363 - kl_loss: 16.1731\n",
      "Epoch 596/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1710 - reconstruction_loss: 317.1710 - kl_loss: 16.1897\n",
      "Epoch 597/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0508 - reconstruction_loss: 317.0508 - kl_loss: 16.2013\n",
      "Epoch 598/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1712 - reconstruction_loss: 317.1712 - kl_loss: 16.2114\n",
      "Epoch 599/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0778 - reconstruction_loss: 317.0778 - kl_loss: 16.2313\n",
      "Epoch 600/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0993 - reconstruction_loss: 317.0993 - kl_loss: 16.2318\n",
      "Epoch 601/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0491 - reconstruction_loss: 317.0491 - kl_loss: 16.2526\n",
      "Epoch 602/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0080 - reconstruction_loss: 317.0080 - kl_loss: 16.2545\n",
      "Epoch 603/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1568 - reconstruction_loss: 317.1568 - kl_loss: 16.2705\n",
      "Epoch 604/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1025 - reconstruction_loss: 317.1025 - kl_loss: 16.2937\n",
      "Epoch 605/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0690 - reconstruction_loss: 317.0690 - kl_loss: 16.2803\n",
      "Epoch 606/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1531 - reconstruction_loss: 317.1531 - kl_loss: 16.3092\n",
      "Epoch 607/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1296 - reconstruction_loss: 317.1296 - kl_loss: 16.3373\n",
      "Epoch 608/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0836 - reconstruction_loss: 317.0836 - kl_loss: 16.3265\n",
      "Epoch 609/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1211 - reconstruction_loss: 317.1211 - kl_loss: 16.3314\n",
      "Epoch 610/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0453 - reconstruction_loss: 317.0453 - kl_loss: 16.3539\n",
      "Epoch 611/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9203 - reconstruction_loss: 316.9203 - kl_loss: 16.3571\n",
      "Epoch 612/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1547 - reconstruction_loss: 317.1547 - kl_loss: 16.3548\n",
      "Epoch 613/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0565 - reconstruction_loss: 317.0565 - kl_loss: 16.3896\n",
      "Epoch 614/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1486 - reconstruction_loss: 317.1486 - kl_loss: 16.3817\n",
      "Epoch 615/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0341 - reconstruction_loss: 317.0341 - kl_loss: 16.4177\n",
      "Epoch 616/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0872 - reconstruction_loss: 317.0872 - kl_loss: 16.3997\n",
      "Epoch 617/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0755 - reconstruction_loss: 317.0755 - kl_loss: 16.4285\n",
      "Epoch 618/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9891 - reconstruction_loss: 316.9891 - kl_loss: 16.4013\n",
      "Epoch 619/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0696 - reconstruction_loss: 317.0696 - kl_loss: 16.4711\n",
      "Epoch 620/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9908 - reconstruction_loss: 316.9908 - kl_loss: 16.4706\n",
      "Epoch 621/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0631 - reconstruction_loss: 317.0631 - kl_loss: 16.4802\n",
      "Epoch 622/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0977 - reconstruction_loss: 317.0977 - kl_loss: 16.5037\n",
      "Epoch 623/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1530 - reconstruction_loss: 317.1530 - kl_loss: 16.5053\n",
      "Epoch 624/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0413 - reconstruction_loss: 317.0413 - kl_loss: 16.4978\n",
      "Epoch 625/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9605 - reconstruction_loss: 316.9605 - kl_loss: 16.5399\n",
      "Epoch 626/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0424 - reconstruction_loss: 317.0424 - kl_loss: 16.5378\n",
      "Epoch 627/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0525 - reconstruction_loss: 317.0525 - kl_loss: 16.5154\n",
      "Epoch 628/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1250 - reconstruction_loss: 317.1250 - kl_loss: 16.5395\n",
      "Epoch 629/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0497 - reconstruction_loss: 317.0497 - kl_loss: 16.5384\n",
      "Epoch 630/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9549 - reconstruction_loss: 316.9549 - kl_loss: 16.5447\n",
      "Epoch 631/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0034 - reconstruction_loss: 317.0034 - kl_loss: 16.5766\n",
      "Epoch 632/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8099 - reconstruction_loss: 316.8099 - kl_loss: 16.5885\n",
      "Epoch 633/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9554 - reconstruction_loss: 316.9554 - kl_loss: 16.5903\n",
      "Epoch 634/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1173 - reconstruction_loss: 317.1173 - kl_loss: 16.6131\n",
      "Epoch 635/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9313 - reconstruction_loss: 316.9313 - kl_loss: 16.6513\n",
      "Epoch 636/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0095 - reconstruction_loss: 317.0095 - kl_loss: 16.6182\n",
      "Epoch 637/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9423 - reconstruction_loss: 316.9423 - kl_loss: 16.6453\n",
      "Epoch 638/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0205 - reconstruction_loss: 317.0205 - kl_loss: 16.6747\n",
      "Epoch 639/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0280 - reconstruction_loss: 317.0280 - kl_loss: 16.6688\n",
      "Epoch 640/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9694 - reconstruction_loss: 316.9694 - kl_loss: 16.6728\n",
      "Epoch 641/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0085 - reconstruction_loss: 317.0085 - kl_loss: 16.7123\n",
      "Epoch 642/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9998 - reconstruction_loss: 316.9998 - kl_loss: 16.7178\n",
      "Epoch 643/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9062 - reconstruction_loss: 316.9062 - kl_loss: 16.7278\n",
      "Epoch 644/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0786 - reconstruction_loss: 317.0786 - kl_loss: 16.7224\n",
      "Epoch 645/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9902 - reconstruction_loss: 316.9902 - kl_loss: 16.7412\n",
      "Epoch 646/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9163 - reconstruction_loss: 316.9163 - kl_loss: 16.7220\n",
      "Epoch 647/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.1091 - reconstruction_loss: 317.1091 - kl_loss: 16.7454\n",
      "Epoch 648/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9939 - reconstruction_loss: 316.9939 - kl_loss: 16.7375\n",
      "Epoch 649/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0154 - reconstruction_loss: 317.0154 - kl_loss: 16.7520\n",
      "Epoch 650/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9790 - reconstruction_loss: 316.9790 - kl_loss: 16.8031\n",
      "Epoch 651/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0224 - reconstruction_loss: 317.0224 - kl_loss: 16.7850\n",
      "Epoch 652/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8949 - reconstruction_loss: 316.8949 - kl_loss: 16.8205\n",
      "Epoch 653/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9804 - reconstruction_loss: 316.9804 - kl_loss: 16.8108\n",
      "Epoch 654/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0161 - reconstruction_loss: 317.0161 - kl_loss: 16.8529\n",
      "Epoch 655/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0636 - reconstruction_loss: 317.0636 - kl_loss: 16.8206\n",
      "Epoch 656/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9787 - reconstruction_loss: 316.9787 - kl_loss: 16.8343\n",
      "Epoch 657/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0436 - reconstruction_loss: 317.0436 - kl_loss: 16.8568\n",
      "Epoch 658/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8629 - reconstruction_loss: 316.8629 - kl_loss: 16.8673\n",
      "Epoch 659/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9943 - reconstruction_loss: 316.9943 - kl_loss: 16.8568\n",
      "Epoch 660/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0577 - reconstruction_loss: 317.0577 - kl_loss: 16.8544\n",
      "Epoch 661/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9604 - reconstruction_loss: 316.9604 - kl_loss: 16.8949\n",
      "Epoch 662/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0261 - reconstruction_loss: 317.0261 - kl_loss: 16.8781\n",
      "Epoch 663/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0220 - reconstruction_loss: 317.0220 - kl_loss: 16.8836\n",
      "Epoch 664/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9976 - reconstruction_loss: 316.9976 - kl_loss: 16.8916\n",
      "Epoch 665/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0220 - reconstruction_loss: 317.0220 - kl_loss: 16.9061\n",
      "Epoch 666/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7793 - reconstruction_loss: 316.7793 - kl_loss: 16.9122\n",
      "Epoch 667/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9132 - reconstruction_loss: 316.9132 - kl_loss: 16.9051\n",
      "Epoch 668/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9264 - reconstruction_loss: 316.9264 - kl_loss: 16.9402\n",
      "Epoch 669/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9527 - reconstruction_loss: 316.9527 - kl_loss: 16.9486\n",
      "Epoch 670/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9496 - reconstruction_loss: 316.9496 - kl_loss: 16.9434\n",
      "Epoch 671/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9841 - reconstruction_loss: 316.9841 - kl_loss: 16.9589\n",
      "Epoch 672/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9804 - reconstruction_loss: 316.9804 - kl_loss: 16.9874\n",
      "Epoch 673/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8703 - reconstruction_loss: 316.8703 - kl_loss: 16.9578\n",
      "Epoch 674/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9762 - reconstruction_loss: 316.9762 - kl_loss: 16.9918\n",
      "Epoch 675/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8710 - reconstruction_loss: 316.8710 - kl_loss: 16.9904\n",
      "Epoch 676/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8936 - reconstruction_loss: 316.8936 - kl_loss: 16.9936\n",
      "Epoch 677/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9271 - reconstruction_loss: 316.9271 - kl_loss: 16.9954\n",
      "Epoch 678/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8446 - reconstruction_loss: 316.8446 - kl_loss: 17.0082\n",
      "Epoch 679/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9475 - reconstruction_loss: 316.9475 - kl_loss: 17.0152\n",
      "Epoch 680/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8815 - reconstruction_loss: 316.8815 - kl_loss: 17.0351\n",
      "Epoch 681/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8700 - reconstruction_loss: 316.8700 - kl_loss: 17.0404\n",
      "Epoch 682/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0912 - reconstruction_loss: 317.0912 - kl_loss: 17.0588\n",
      "Epoch 683/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8708 - reconstruction_loss: 316.8708 - kl_loss: 17.0590\n",
      "Epoch 684/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8728 - reconstruction_loss: 316.8728 - kl_loss: 17.0510\n",
      "Epoch 685/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8594 - reconstruction_loss: 316.8594 - kl_loss: 17.0782\n",
      "Epoch 686/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8674 - reconstruction_loss: 316.8674 - kl_loss: 17.0926\n",
      "Epoch 687/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9848 - reconstruction_loss: 316.9848 - kl_loss: 17.0988\n",
      "Epoch 688/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8768 - reconstruction_loss: 316.8768 - kl_loss: 17.1066\n",
      "Epoch 689/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8555 - reconstruction_loss: 316.8555 - kl_loss: 17.1217\n",
      "Epoch 690/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9077 - reconstruction_loss: 316.9077 - kl_loss: 17.1327\n",
      "Epoch 691/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9798 - reconstruction_loss: 316.9798 - kl_loss: 17.1383\n",
      "Epoch 692/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8619 - reconstruction_loss: 316.8619 - kl_loss: 17.1196\n",
      "Epoch 693/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9301 - reconstruction_loss: 316.9301 - kl_loss: 17.1589\n",
      "Epoch 694/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0287 - reconstruction_loss: 317.0287 - kl_loss: 17.1597\n",
      "Epoch 695/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8449 - reconstruction_loss: 316.8449 - kl_loss: 17.1551\n",
      "Epoch 696/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9126 - reconstruction_loss: 316.9126 - kl_loss: 17.1922\n",
      "Epoch 697/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9561 - reconstruction_loss: 316.9561 - kl_loss: 17.1760\n",
      "Epoch 698/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0510 - reconstruction_loss: 317.0510 - kl_loss: 17.2025\n",
      "Epoch 699/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9421 - reconstruction_loss: 316.9421 - kl_loss: 17.1901\n",
      "Epoch 700/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9318 - reconstruction_loss: 316.9318 - kl_loss: 17.2131\n",
      "Epoch 701/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9288 - reconstruction_loss: 316.9288 - kl_loss: 17.2270\n",
      "Epoch 702/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 317.0246 - reconstruction_loss: 317.0246 - kl_loss: 17.2478\n",
      "Epoch 703/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8722 - reconstruction_loss: 316.8722 - kl_loss: 17.2282\n",
      "Epoch 704/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8032 - reconstruction_loss: 316.8032 - kl_loss: 17.2303\n",
      "Epoch 705/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9029 - reconstruction_loss: 316.9029 - kl_loss: 17.2495\n",
      "Epoch 706/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8404 - reconstruction_loss: 316.8404 - kl_loss: 17.2577\n",
      "Epoch 707/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9127 - reconstruction_loss: 316.9127 - kl_loss: 17.2551\n",
      "Epoch 708/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8325 - reconstruction_loss: 316.8325 - kl_loss: 17.2862\n",
      "Epoch 709/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8803 - reconstruction_loss: 316.8803 - kl_loss: 17.2835\n",
      "Epoch 710/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8474 - reconstruction_loss: 316.8474 - kl_loss: 17.2982\n",
      "Epoch 711/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8446 - reconstruction_loss: 316.8446 - kl_loss: 17.3329\n",
      "Epoch 712/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8456 - reconstruction_loss: 316.8456 - kl_loss: 17.3023\n",
      "Epoch 713/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8562 - reconstruction_loss: 316.8562 - kl_loss: 17.3235\n",
      "Epoch 714/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8733 - reconstruction_loss: 316.8733 - kl_loss: 17.3345\n",
      "Epoch 715/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8688 - reconstruction_loss: 316.8688 - kl_loss: 17.3535\n",
      "Epoch 716/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9317 - reconstruction_loss: 316.9317 - kl_loss: 17.3613\n",
      "Epoch 717/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9007 - reconstruction_loss: 316.9007 - kl_loss: 17.3543\n",
      "Epoch 718/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6910 - reconstruction_loss: 316.6910 - kl_loss: 17.3725\n",
      "Epoch 719/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7310 - reconstruction_loss: 316.7310 - kl_loss: 17.3612\n",
      "Epoch 720/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9039 - reconstruction_loss: 316.9039 - kl_loss: 17.3857\n",
      "Epoch 721/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7830 - reconstruction_loss: 316.7830 - kl_loss: 17.3981\n",
      "Epoch 722/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8666 - reconstruction_loss: 316.8666 - kl_loss: 17.3971\n",
      "Epoch 723/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8215 - reconstruction_loss: 316.8215 - kl_loss: 17.3956\n",
      "Epoch 724/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6731 - reconstruction_loss: 316.6731 - kl_loss: 17.4285\n",
      "Epoch 725/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8180 - reconstruction_loss: 316.8180 - kl_loss: 17.4165\n",
      "Epoch 726/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7997 - reconstruction_loss: 316.7997 - kl_loss: 17.4344\n",
      "Epoch 727/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7976 - reconstruction_loss: 316.7976 - kl_loss: 17.4578\n",
      "Epoch 728/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7685 - reconstruction_loss: 316.7685 - kl_loss: 17.4347\n",
      "Epoch 729/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8720 - reconstruction_loss: 316.8720 - kl_loss: 17.4588\n",
      "Epoch 730/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8778 - reconstruction_loss: 316.8778 - kl_loss: 17.4796\n",
      "Epoch 731/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8459 - reconstruction_loss: 316.8459 - kl_loss: 17.4686\n",
      "Epoch 732/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8219 - reconstruction_loss: 316.8219 - kl_loss: 17.4698\n",
      "Epoch 733/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7788 - reconstruction_loss: 316.7788 - kl_loss: 17.5160\n",
      "Epoch 734/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8366 - reconstruction_loss: 316.8366 - kl_loss: 17.5032\n",
      "Epoch 735/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6815 - reconstruction_loss: 316.6815 - kl_loss: 17.5229\n",
      "Epoch 736/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8573 - reconstruction_loss: 316.8573 - kl_loss: 17.5143\n",
      "Epoch 737/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9487 - reconstruction_loss: 316.9487 - kl_loss: 17.5307\n",
      "Epoch 738/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9057 - reconstruction_loss: 316.9057 - kl_loss: 17.5339\n",
      "Epoch 739/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7811 - reconstruction_loss: 316.7811 - kl_loss: 17.5608\n",
      "Epoch 740/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8201 - reconstruction_loss: 316.8201 - kl_loss: 17.5564\n",
      "Epoch 741/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7776 - reconstruction_loss: 316.7776 - kl_loss: 17.5874\n",
      "Epoch 742/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.9423 - reconstruction_loss: 316.9423 - kl_loss: 17.5605\n",
      "Epoch 743/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8210 - reconstruction_loss: 316.8210 - kl_loss: 17.5861\n",
      "Epoch 744/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7344 - reconstruction_loss: 316.7344 - kl_loss: 17.5920\n",
      "Epoch 745/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8834 - reconstruction_loss: 316.8834 - kl_loss: 17.5778\n",
      "Epoch 746/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8283 - reconstruction_loss: 316.8283 - kl_loss: 17.6101\n",
      "Epoch 747/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8801 - reconstruction_loss: 316.8801 - kl_loss: 17.5739\n",
      "Epoch 748/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8396 - reconstruction_loss: 316.8396 - kl_loss: 17.6311\n",
      "Epoch 749/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8628 - reconstruction_loss: 316.8628 - kl_loss: 17.6350\n",
      "Epoch 750/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8026 - reconstruction_loss: 316.8026 - kl_loss: 17.6557\n",
      "Epoch 751/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8673 - reconstruction_loss: 316.8673 - kl_loss: 17.6480\n",
      "Epoch 752/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7484 - reconstruction_loss: 316.7484 - kl_loss: 17.6464\n",
      "Epoch 753/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8256 - reconstruction_loss: 316.8256 - kl_loss: 17.6699\n",
      "Epoch 754/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6986 - reconstruction_loss: 316.6986 - kl_loss: 17.6610\n",
      "Epoch 755/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8895 - reconstruction_loss: 316.8895 - kl_loss: 17.7051\n",
      "Epoch 756/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8033 - reconstruction_loss: 316.8033 - kl_loss: 17.6852\n",
      "Epoch 757/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8117 - reconstruction_loss: 316.8117 - kl_loss: 17.6794\n",
      "Epoch 758/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7921 - reconstruction_loss: 316.7921 - kl_loss: 17.6911\n",
      "Epoch 759/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7783 - reconstruction_loss: 316.7783 - kl_loss: 17.7204\n",
      "Epoch 760/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8192 - reconstruction_loss: 316.8192 - kl_loss: 17.7088\n",
      "Epoch 761/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7744 - reconstruction_loss: 316.7744 - kl_loss: 17.7247\n",
      "Epoch 762/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8535 - reconstruction_loss: 316.8535 - kl_loss: 17.7517\n",
      "Epoch 763/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7184 - reconstruction_loss: 316.7184 - kl_loss: 17.7392\n",
      "Epoch 764/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7582 - reconstruction_loss: 316.7582 - kl_loss: 17.7488\n",
      "Epoch 765/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7307 - reconstruction_loss: 316.7307 - kl_loss: 17.7843\n",
      "Epoch 766/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8016 - reconstruction_loss: 316.8016 - kl_loss: 17.7833\n",
      "Epoch 767/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7801 - reconstruction_loss: 316.7801 - kl_loss: 17.7883\n",
      "Epoch 768/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7772 - reconstruction_loss: 316.7772 - kl_loss: 17.7655\n",
      "Epoch 769/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8360 - reconstruction_loss: 316.8360 - kl_loss: 17.7862\n",
      "Epoch 770/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8647 - reconstruction_loss: 316.8647 - kl_loss: 17.7723\n",
      "Epoch 771/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8759 - reconstruction_loss: 316.8759 - kl_loss: 17.8151\n",
      "Epoch 772/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7320 - reconstruction_loss: 316.7320 - kl_loss: 17.8229\n",
      "Epoch 773/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8339 - reconstruction_loss: 316.8339 - kl_loss: 17.8039\n",
      "Epoch 774/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6986 - reconstruction_loss: 316.6986 - kl_loss: 17.8352\n",
      "Epoch 775/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7635 - reconstruction_loss: 316.7635 - kl_loss: 17.8585\n",
      "Epoch 776/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8032 - reconstruction_loss: 316.8032 - kl_loss: 17.8403\n",
      "Epoch 777/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7689 - reconstruction_loss: 316.7689 - kl_loss: 17.8650\n",
      "Epoch 778/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6850 - reconstruction_loss: 316.6850 - kl_loss: 17.8739\n",
      "Epoch 779/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8659 - reconstruction_loss: 316.8659 - kl_loss: 17.8711\n",
      "Epoch 780/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7115 - reconstruction_loss: 316.7115 - kl_loss: 17.8936\n",
      "Epoch 781/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8339 - reconstruction_loss: 316.8339 - kl_loss: 17.8784\n",
      "Epoch 782/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7203 - reconstruction_loss: 316.7203 - kl_loss: 17.9017\n",
      "Epoch 783/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7504 - reconstruction_loss: 316.7504 - kl_loss: 17.9029\n",
      "Epoch 784/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6253 - reconstruction_loss: 316.6253 - kl_loss: 17.9093\n",
      "Epoch 785/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7607 - reconstruction_loss: 316.7607 - kl_loss: 17.9261\n",
      "Epoch 786/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6678 - reconstruction_loss: 316.6678 - kl_loss: 17.9220\n",
      "Epoch 787/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8176 - reconstruction_loss: 316.8176 - kl_loss: 17.9337\n",
      "Epoch 788/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7074 - reconstruction_loss: 316.7074 - kl_loss: 17.9250\n",
      "Epoch 789/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7069 - reconstruction_loss: 316.7069 - kl_loss: 17.9702\n",
      "Epoch 790/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6186 - reconstruction_loss: 316.6186 - kl_loss: 17.9668\n",
      "Epoch 791/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8404 - reconstruction_loss: 316.8404 - kl_loss: 17.9499\n",
      "Epoch 792/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6501 - reconstruction_loss: 316.6501 - kl_loss: 17.9567\n",
      "Epoch 793/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7517 - reconstruction_loss: 316.7517 - kl_loss: 17.9713\n",
      "Epoch 794/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7735 - reconstruction_loss: 316.7735 - kl_loss: 17.9765\n",
      "Epoch 795/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7457 - reconstruction_loss: 316.7457 - kl_loss: 18.0061\n",
      "Epoch 796/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8260 - reconstruction_loss: 316.8260 - kl_loss: 17.9960\n",
      "Epoch 797/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6677 - reconstruction_loss: 316.6677 - kl_loss: 18.0287\n",
      "Epoch 798/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7597 - reconstruction_loss: 316.7597 - kl_loss: 18.0230\n",
      "Epoch 799/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7154 - reconstruction_loss: 316.7154 - kl_loss: 18.0454\n",
      "Epoch 800/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6309 - reconstruction_loss: 316.6309 - kl_loss: 18.0447\n",
      "Epoch 801/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6654 - reconstruction_loss: 316.6654 - kl_loss: 18.0305\n",
      "Epoch 802/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7985 - reconstruction_loss: 316.7985 - kl_loss: 18.0417\n",
      "Epoch 803/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7010 - reconstruction_loss: 316.7010 - kl_loss: 18.0389\n",
      "Epoch 804/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8547 - reconstruction_loss: 316.8547 - kl_loss: 18.0382\n",
      "Epoch 805/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7458 - reconstruction_loss: 316.7458 - kl_loss: 18.0435\n",
      "Epoch 806/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6624 - reconstruction_loss: 316.6624 - kl_loss: 18.0598\n",
      "Epoch 807/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7744 - reconstruction_loss: 316.7744 - kl_loss: 18.0803\n",
      "Epoch 808/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7258 - reconstruction_loss: 316.7258 - kl_loss: 18.0665\n",
      "Epoch 809/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7412 - reconstruction_loss: 316.7412 - kl_loss: 18.0665\n",
      "Epoch 810/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6669 - reconstruction_loss: 316.6669 - kl_loss: 18.0673\n",
      "Epoch 811/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5885 - reconstruction_loss: 316.5885 - kl_loss: 18.1085\n",
      "Epoch 812/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5921 - reconstruction_loss: 316.5921 - kl_loss: 18.1240\n",
      "Epoch 813/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7130 - reconstruction_loss: 316.7130 - kl_loss: 18.1200\n",
      "Epoch 814/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7587 - reconstruction_loss: 316.7587 - kl_loss: 18.0991\n",
      "Epoch 815/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6643 - reconstruction_loss: 316.6643 - kl_loss: 18.1150\n",
      "Epoch 816/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6565 - reconstruction_loss: 316.6565 - kl_loss: 18.1257\n",
      "Epoch 817/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7226 - reconstruction_loss: 316.7226 - kl_loss: 18.1405\n",
      "Epoch 818/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6179 - reconstruction_loss: 316.6179 - kl_loss: 18.1479\n",
      "Epoch 819/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4938 - reconstruction_loss: 316.4938 - kl_loss: 18.1718\n",
      "Epoch 820/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7541 - reconstruction_loss: 316.7541 - kl_loss: 18.1429\n",
      "Epoch 821/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7855 - reconstruction_loss: 316.7855 - kl_loss: 18.1630\n",
      "Epoch 822/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6652 - reconstruction_loss: 316.6652 - kl_loss: 18.2051\n",
      "Epoch 823/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8195 - reconstruction_loss: 316.8195 - kl_loss: 18.2158\n",
      "Epoch 824/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6335 - reconstruction_loss: 316.6335 - kl_loss: 18.1764\n",
      "Epoch 825/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6503 - reconstruction_loss: 316.6503 - kl_loss: 18.1967\n",
      "Epoch 826/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6722 - reconstruction_loss: 316.6722 - kl_loss: 18.1945\n",
      "Epoch 827/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6806 - reconstruction_loss: 316.6806 - kl_loss: 18.2161\n",
      "Epoch 828/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6667 - reconstruction_loss: 316.6667 - kl_loss: 18.2178\n",
      "Epoch 829/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5740 - reconstruction_loss: 316.5740 - kl_loss: 18.2099\n",
      "Epoch 830/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6950 - reconstruction_loss: 316.6950 - kl_loss: 18.2110\n",
      "Epoch 831/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6261 - reconstruction_loss: 316.6261 - kl_loss: 18.2337\n",
      "Epoch 832/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7548 - reconstruction_loss: 316.7548 - kl_loss: 18.2165\n",
      "Epoch 833/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7351 - reconstruction_loss: 316.7351 - kl_loss: 18.2269\n",
      "Epoch 834/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6959 - reconstruction_loss: 316.6959 - kl_loss: 18.2417\n",
      "Epoch 835/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7212 - reconstruction_loss: 316.7212 - kl_loss: 18.2401\n",
      "Epoch 836/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7031 - reconstruction_loss: 316.7031 - kl_loss: 18.2391\n",
      "Epoch 837/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7498 - reconstruction_loss: 316.7498 - kl_loss: 18.2661\n",
      "Epoch 838/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7325 - reconstruction_loss: 316.7325 - kl_loss: 18.2401\n",
      "Epoch 839/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7089 - reconstruction_loss: 316.7089 - kl_loss: 18.2607\n",
      "Epoch 840/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6326 - reconstruction_loss: 316.6326 - kl_loss: 18.2582\n",
      "Epoch 841/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5870 - reconstruction_loss: 316.5870 - kl_loss: 18.2457\n",
      "Epoch 842/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6980 - reconstruction_loss: 316.6980 - kl_loss: 18.2840\n",
      "Epoch 843/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7285 - reconstruction_loss: 316.7285 - kl_loss: 18.2842\n",
      "Epoch 844/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5928 - reconstruction_loss: 316.5928 - kl_loss: 18.2853\n",
      "Epoch 845/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7004 - reconstruction_loss: 316.7004 - kl_loss: 18.2690\n",
      "Epoch 846/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7224 - reconstruction_loss: 316.7224 - kl_loss: 18.2727\n",
      "Epoch 847/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7171 - reconstruction_loss: 316.7171 - kl_loss: 18.3219\n",
      "Epoch 848/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6283 - reconstruction_loss: 316.6283 - kl_loss: 18.2946\n",
      "Epoch 849/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6589 - reconstruction_loss: 316.6589 - kl_loss: 18.3405\n",
      "Epoch 850/3000\n",
      "166/166 [==============================] - 3s 20ms/step - loss: 316.6339 - reconstruction_loss: 316.6339 - kl_loss: 18.3045\n",
      "Epoch 851/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7092 - reconstruction_loss: 316.7092 - kl_loss: 18.3104\n",
      "Epoch 852/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5440 - reconstruction_loss: 316.5440 - kl_loss: 18.3376\n",
      "Epoch 853/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7177 - reconstruction_loss: 316.7177 - kl_loss: 18.3758\n",
      "Epoch 854/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5995 - reconstruction_loss: 316.5995 - kl_loss: 18.3333\n",
      "Epoch 855/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6002 - reconstruction_loss: 316.6002 - kl_loss: 18.3190\n",
      "Epoch 856/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6239 - reconstruction_loss: 316.6239 - kl_loss: 18.3454\n",
      "Epoch 857/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6125 - reconstruction_loss: 316.6125 - kl_loss: 18.3376\n",
      "Epoch 858/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6785 - reconstruction_loss: 316.6785 - kl_loss: 18.3764\n",
      "Epoch 859/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6855 - reconstruction_loss: 316.6855 - kl_loss: 18.3610\n",
      "Epoch 860/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6340 - reconstruction_loss: 316.6340 - kl_loss: 18.3501\n",
      "Epoch 861/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5519 - reconstruction_loss: 316.5519 - kl_loss: 18.3795\n",
      "Epoch 862/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6413 - reconstruction_loss: 316.6413 - kl_loss: 18.3643\n",
      "Epoch 863/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6109 - reconstruction_loss: 316.6109 - kl_loss: 18.3690\n",
      "Epoch 864/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6358 - reconstruction_loss: 316.6358 - kl_loss: 18.3389\n",
      "Epoch 865/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5404 - reconstruction_loss: 316.5404 - kl_loss: 18.4147\n",
      "Epoch 866/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5234 - reconstruction_loss: 316.5234 - kl_loss: 18.3863\n",
      "Epoch 867/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5909 - reconstruction_loss: 316.5909 - kl_loss: 18.4098\n",
      "Epoch 868/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6174 - reconstruction_loss: 316.6174 - kl_loss: 18.3946\n",
      "Epoch 869/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6666 - reconstruction_loss: 316.6666 - kl_loss: 18.4228\n",
      "Epoch 870/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6939 - reconstruction_loss: 316.6939 - kl_loss: 18.4058\n",
      "Epoch 871/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6385 - reconstruction_loss: 316.6385 - kl_loss: 18.4234\n",
      "Epoch 872/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5951 - reconstruction_loss: 316.5951 - kl_loss: 18.4255\n",
      "Epoch 873/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.7456 - reconstruction_loss: 316.7456 - kl_loss: 18.4477\n",
      "Epoch 874/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.8029 - reconstruction_loss: 316.8029 - kl_loss: 18.4537\n",
      "Epoch 875/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4906 - reconstruction_loss: 316.4906 - kl_loss: 18.4496\n",
      "Epoch 876/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5461 - reconstruction_loss: 316.5461 - kl_loss: 18.4427\n",
      "Epoch 877/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6268 - reconstruction_loss: 316.6268 - kl_loss: 18.4445\n",
      "Epoch 878/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5790 - reconstruction_loss: 316.5790 - kl_loss: 18.4553\n",
      "Epoch 879/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5557 - reconstruction_loss: 316.5557 - kl_loss: 18.4757\n",
      "Epoch 880/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6676 - reconstruction_loss: 316.6676 - kl_loss: 18.4924\n",
      "Epoch 881/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6717 - reconstruction_loss: 316.6717 - kl_loss: 18.4608\n",
      "Epoch 882/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6380 - reconstruction_loss: 316.6380 - kl_loss: 18.5100\n",
      "Epoch 883/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5417 - reconstruction_loss: 316.5417 - kl_loss: 18.4872\n",
      "Epoch 884/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5507 - reconstruction_loss: 316.5507 - kl_loss: 18.4828\n",
      "Epoch 885/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5479 - reconstruction_loss: 316.5479 - kl_loss: 18.4947\n",
      "Epoch 886/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5531 - reconstruction_loss: 316.5531 - kl_loss: 18.5050\n",
      "Epoch 887/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4357 - reconstruction_loss: 316.4357 - kl_loss: 18.5113\n",
      "Epoch 888/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6185 - reconstruction_loss: 316.6185 - kl_loss: 18.5080\n",
      "Epoch 889/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4974 - reconstruction_loss: 316.4974 - kl_loss: 18.5050\n",
      "Epoch 890/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5849 - reconstruction_loss: 316.5849 - kl_loss: 18.5321\n",
      "Epoch 891/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5386 - reconstruction_loss: 316.5386 - kl_loss: 18.5338\n",
      "Epoch 892/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5757 - reconstruction_loss: 316.5757 - kl_loss: 18.5036\n",
      "Epoch 893/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5649 - reconstruction_loss: 316.5649 - kl_loss: 18.5380\n",
      "Epoch 894/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5554 - reconstruction_loss: 316.5554 - kl_loss: 18.5271\n",
      "Epoch 895/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4791 - reconstruction_loss: 316.4791 - kl_loss: 18.5530\n",
      "Epoch 896/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5507 - reconstruction_loss: 316.5507 - kl_loss: 18.5552\n",
      "Epoch 897/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5089 - reconstruction_loss: 316.5089 - kl_loss: 18.5880\n",
      "Epoch 898/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5705 - reconstruction_loss: 316.5705 - kl_loss: 18.5552\n",
      "Epoch 899/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5307 - reconstruction_loss: 316.5307 - kl_loss: 18.5913\n",
      "Epoch 900/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6663 - reconstruction_loss: 316.6663 - kl_loss: 18.5870\n",
      "Epoch 901/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5575 - reconstruction_loss: 316.5575 - kl_loss: 18.5765\n",
      "Epoch 902/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6816 - reconstruction_loss: 316.6816 - kl_loss: 18.5818\n",
      "Epoch 903/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6700 - reconstruction_loss: 316.6700 - kl_loss: 18.5944\n",
      "Epoch 904/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6068 - reconstruction_loss: 316.6068 - kl_loss: 18.6020\n",
      "Epoch 905/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5662 - reconstruction_loss: 316.5662 - kl_loss: 18.6067\n",
      "Epoch 906/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5217 - reconstruction_loss: 316.5217 - kl_loss: 18.6166\n",
      "Epoch 907/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5818 - reconstruction_loss: 316.5818 - kl_loss: 18.6343\n",
      "Epoch 908/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5330 - reconstruction_loss: 316.5330 - kl_loss: 18.6316\n",
      "Epoch 909/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5346 - reconstruction_loss: 316.5346 - kl_loss: 18.6096\n",
      "Epoch 910/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4260 - reconstruction_loss: 316.4260 - kl_loss: 18.6282\n",
      "Epoch 911/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5537 - reconstruction_loss: 316.5537 - kl_loss: 18.6076\n",
      "Epoch 912/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3922 - reconstruction_loss: 316.3922 - kl_loss: 18.6532\n",
      "Epoch 913/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5702 - reconstruction_loss: 316.5702 - kl_loss: 18.6375\n",
      "Epoch 914/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5958 - reconstruction_loss: 316.5958 - kl_loss: 18.6637\n",
      "Epoch 915/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4757 - reconstruction_loss: 316.4757 - kl_loss: 18.6676\n",
      "Epoch 916/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5512 - reconstruction_loss: 316.5512 - kl_loss: 18.6491\n",
      "Epoch 917/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5027 - reconstruction_loss: 316.5027 - kl_loss: 18.6499\n",
      "Epoch 918/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6309 - reconstruction_loss: 316.6309 - kl_loss: 18.6807\n",
      "Epoch 919/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4978 - reconstruction_loss: 316.4978 - kl_loss: 18.6416\n",
      "Epoch 920/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5572 - reconstruction_loss: 316.5572 - kl_loss: 18.6562\n",
      "Epoch 921/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5913 - reconstruction_loss: 316.5913 - kl_loss: 18.6394\n",
      "Epoch 922/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6245 - reconstruction_loss: 316.6245 - kl_loss: 18.6658\n",
      "Epoch 923/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3455 - reconstruction_loss: 316.3455 - kl_loss: 18.6812\n",
      "Epoch 924/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4759 - reconstruction_loss: 316.4759 - kl_loss: 18.7003\n",
      "Epoch 925/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3874 - reconstruction_loss: 316.3874 - kl_loss: 18.6861\n",
      "Epoch 926/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4535 - reconstruction_loss: 316.4535 - kl_loss: 18.6990\n",
      "Epoch 927/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5548 - reconstruction_loss: 316.5548 - kl_loss: 18.7147\n",
      "Epoch 928/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5564 - reconstruction_loss: 316.5564 - kl_loss: 18.7212\n",
      "Epoch 929/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5504 - reconstruction_loss: 316.5504 - kl_loss: 18.7108\n",
      "Epoch 930/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6446 - reconstruction_loss: 316.6446 - kl_loss: 18.7121\n",
      "Epoch 931/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4703 - reconstruction_loss: 316.4703 - kl_loss: 18.7045\n",
      "Epoch 932/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5223 - reconstruction_loss: 316.5223 - kl_loss: 18.7117\n",
      "Epoch 933/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3975 - reconstruction_loss: 316.3975 - kl_loss: 18.7434\n",
      "Epoch 934/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4189 - reconstruction_loss: 316.4189 - kl_loss: 18.7399\n",
      "Epoch 935/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4778 - reconstruction_loss: 316.4778 - kl_loss: 18.7504\n",
      "Epoch 936/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4909 - reconstruction_loss: 316.4909 - kl_loss: 18.7941\n",
      "Epoch 937/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6137 - reconstruction_loss: 316.6137 - kl_loss: 18.7917\n",
      "Epoch 938/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5425 - reconstruction_loss: 316.5425 - kl_loss: 18.7878\n",
      "Epoch 939/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3393 - reconstruction_loss: 316.3393 - kl_loss: 18.7755\n",
      "Epoch 940/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4700 - reconstruction_loss: 316.4700 - kl_loss: 18.7626\n",
      "Epoch 941/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4008 - reconstruction_loss: 316.4008 - kl_loss: 18.7574\n",
      "Epoch 942/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5715 - reconstruction_loss: 316.5715 - kl_loss: 18.7787\n",
      "Epoch 943/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4340 - reconstruction_loss: 316.4340 - kl_loss: 18.7943\n",
      "Epoch 944/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4958 - reconstruction_loss: 316.4958 - kl_loss: 18.7881\n",
      "Epoch 945/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4405 - reconstruction_loss: 316.4405 - kl_loss: 18.7916\n",
      "Epoch 946/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5057 - reconstruction_loss: 316.5057 - kl_loss: 18.7934\n",
      "Epoch 947/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3906 - reconstruction_loss: 316.3906 - kl_loss: 18.7967\n",
      "Epoch 948/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.6100 - reconstruction_loss: 316.6100 - kl_loss: 18.8113\n",
      "Epoch 949/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5733 - reconstruction_loss: 316.5733 - kl_loss: 18.8254\n",
      "Epoch 950/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4186 - reconstruction_loss: 316.4186 - kl_loss: 18.8048\n",
      "Epoch 951/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3889 - reconstruction_loss: 316.3889 - kl_loss: 18.8403\n",
      "Epoch 952/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5483 - reconstruction_loss: 316.5483 - kl_loss: 18.8012\n",
      "Epoch 953/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3811 - reconstruction_loss: 316.3811 - kl_loss: 18.8362\n",
      "Epoch 954/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4288 - reconstruction_loss: 316.4288 - kl_loss: 18.8229\n",
      "Epoch 955/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5342 - reconstruction_loss: 316.5342 - kl_loss: 18.8761\n",
      "Epoch 956/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4589 - reconstruction_loss: 316.4589 - kl_loss: 18.8841\n",
      "Epoch 957/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4452 - reconstruction_loss: 316.4452 - kl_loss: 18.8732\n",
      "Epoch 958/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4864 - reconstruction_loss: 316.4864 - kl_loss: 18.8647\n",
      "Epoch 959/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3955 - reconstruction_loss: 316.3955 - kl_loss: 18.8740\n",
      "Epoch 960/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3956 - reconstruction_loss: 316.3956 - kl_loss: 18.8928\n",
      "Epoch 961/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5300 - reconstruction_loss: 316.5300 - kl_loss: 18.9067\n",
      "Epoch 962/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3962 - reconstruction_loss: 316.3962 - kl_loss: 18.8926\n",
      "Epoch 963/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4323 - reconstruction_loss: 316.4323 - kl_loss: 18.9076\n",
      "Epoch 964/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5551 - reconstruction_loss: 316.5551 - kl_loss: 18.9229\n",
      "Epoch 965/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4595 - reconstruction_loss: 316.4595 - kl_loss: 18.9208\n",
      "Epoch 966/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5084 - reconstruction_loss: 316.5084 - kl_loss: 18.9312\n",
      "Epoch 967/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4634 - reconstruction_loss: 316.4634 - kl_loss: 18.9287\n",
      "Epoch 968/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3776 - reconstruction_loss: 316.3776 - kl_loss: 18.9294\n",
      "Epoch 969/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3250 - reconstruction_loss: 316.3250 - kl_loss: 18.9350\n",
      "Epoch 970/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3872 - reconstruction_loss: 316.3872 - kl_loss: 18.9484\n",
      "Epoch 971/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3914 - reconstruction_loss: 316.3914 - kl_loss: 18.9177\n",
      "Epoch 972/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4362 - reconstruction_loss: 316.4362 - kl_loss: 18.9529\n",
      "Epoch 973/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5007 - reconstruction_loss: 316.5007 - kl_loss: 18.9661\n",
      "Epoch 974/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4400 - reconstruction_loss: 316.4400 - kl_loss: 18.9597\n",
      "Epoch 975/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5420 - reconstruction_loss: 316.5420 - kl_loss: 18.9689\n",
      "Epoch 976/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4805 - reconstruction_loss: 316.4805 - kl_loss: 18.9464\n",
      "Epoch 977/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4562 - reconstruction_loss: 316.4562 - kl_loss: 18.9623\n",
      "Epoch 978/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3784 - reconstruction_loss: 316.3784 - kl_loss: 18.9837\n",
      "Epoch 979/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3339 - reconstruction_loss: 316.3339 - kl_loss: 18.9775\n",
      "Epoch 980/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3851 - reconstruction_loss: 316.3851 - kl_loss: 18.9626\n",
      "Epoch 981/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4502 - reconstruction_loss: 316.4502 - kl_loss: 18.9659\n",
      "Epoch 982/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3183 - reconstruction_loss: 316.3183 - kl_loss: 19.0210\n",
      "Epoch 983/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4445 - reconstruction_loss: 316.4445 - kl_loss: 18.9930\n",
      "Epoch 984/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4305 - reconstruction_loss: 316.4305 - kl_loss: 19.0287\n",
      "Epoch 985/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4647 - reconstruction_loss: 316.4647 - kl_loss: 19.0144\n",
      "Epoch 986/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4550 - reconstruction_loss: 316.4550 - kl_loss: 19.0147\n",
      "Epoch 987/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4399 - reconstruction_loss: 316.4399 - kl_loss: 19.0179\n",
      "Epoch 988/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3962 - reconstruction_loss: 316.3962 - kl_loss: 19.0140\n",
      "Epoch 989/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3035 - reconstruction_loss: 316.3035 - kl_loss: 19.0356\n",
      "Epoch 990/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4818 - reconstruction_loss: 316.4818 - kl_loss: 19.0639\n",
      "Epoch 991/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4398 - reconstruction_loss: 316.4398 - kl_loss: 19.0598\n",
      "Epoch 992/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4176 - reconstruction_loss: 316.4176 - kl_loss: 19.0518\n",
      "Epoch 993/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5199 - reconstruction_loss: 316.5199 - kl_loss: 19.0656\n",
      "Epoch 994/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3232 - reconstruction_loss: 316.3232 - kl_loss: 19.0737\n",
      "Epoch 995/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3683 - reconstruction_loss: 316.3683 - kl_loss: 19.0775\n",
      "Epoch 996/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2541 - reconstruction_loss: 316.2541 - kl_loss: 19.1038\n",
      "Epoch 997/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3627 - reconstruction_loss: 316.3627 - kl_loss: 19.0887\n",
      "Epoch 998/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3198 - reconstruction_loss: 316.3198 - kl_loss: 19.0884\n",
      "Epoch 999/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3899 - reconstruction_loss: 316.3899 - kl_loss: 19.0910\n",
      "Epoch 1000/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3457 - reconstruction_loss: 316.3457 - kl_loss: 19.0955\n",
      "Epoch 1001/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3405 - reconstruction_loss: 316.3405 - kl_loss: 19.0874\n",
      "Epoch 1002/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3781 - reconstruction_loss: 316.3781 - kl_loss: 19.1231\n",
      "Epoch 1003/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4474 - reconstruction_loss: 316.4474 - kl_loss: 19.0903\n",
      "Epoch 1004/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3598 - reconstruction_loss: 316.3598 - kl_loss: 19.1129\n",
      "Epoch 1005/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.5452 - reconstruction_loss: 316.5452 - kl_loss: 19.1176\n",
      "Epoch 1006/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4112 - reconstruction_loss: 316.4112 - kl_loss: 19.1247\n",
      "Epoch 1007/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3626 - reconstruction_loss: 316.3626 - kl_loss: 19.1378\n",
      "Epoch 1008/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3813 - reconstruction_loss: 316.3813 - kl_loss: 19.1097\n",
      "Epoch 1009/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2652 - reconstruction_loss: 316.2652 - kl_loss: 19.1246\n",
      "Epoch 1010/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3290 - reconstruction_loss: 316.3290 - kl_loss: 19.1058\n",
      "Epoch 1011/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3773 - reconstruction_loss: 316.3773 - kl_loss: 19.1217\n",
      "Epoch 1012/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2913 - reconstruction_loss: 316.2913 - kl_loss: 19.1291\n",
      "Epoch 1013/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3258 - reconstruction_loss: 316.3258 - kl_loss: 19.1465\n",
      "Epoch 1014/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2327 - reconstruction_loss: 316.2327 - kl_loss: 19.1487\n",
      "Epoch 1015/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3086 - reconstruction_loss: 316.3086 - kl_loss: 19.1463\n",
      "Epoch 1016/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3608 - reconstruction_loss: 316.3608 - kl_loss: 19.1509\n",
      "Epoch 1017/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3091 - reconstruction_loss: 316.3091 - kl_loss: 19.1554\n",
      "Epoch 1018/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2232 - reconstruction_loss: 316.2232 - kl_loss: 19.1553\n",
      "Epoch 1019/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3383 - reconstruction_loss: 316.3383 - kl_loss: 19.1967\n",
      "Epoch 1020/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2790 - reconstruction_loss: 316.2790 - kl_loss: 19.2029\n",
      "Epoch 1021/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3787 - reconstruction_loss: 316.3787 - kl_loss: 19.1570\n",
      "Epoch 1022/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3887 - reconstruction_loss: 316.3887 - kl_loss: 19.1717\n",
      "Epoch 1023/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3307 - reconstruction_loss: 316.3307 - kl_loss: 19.1951\n",
      "Epoch 1024/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2734 - reconstruction_loss: 316.2734 - kl_loss: 19.1717\n",
      "Epoch 1025/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3641 - reconstruction_loss: 316.3641 - kl_loss: 19.1973\n",
      "Epoch 1026/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3411 - reconstruction_loss: 316.3411 - kl_loss: 19.1913\n",
      "Epoch 1027/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2836 - reconstruction_loss: 316.2836 - kl_loss: 19.1812\n",
      "Epoch 1028/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1689 - reconstruction_loss: 316.1689 - kl_loss: 19.2056\n",
      "Epoch 1029/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2841 - reconstruction_loss: 316.2841 - kl_loss: 19.2205\n",
      "Epoch 1030/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1807 - reconstruction_loss: 316.1807 - kl_loss: 19.2194\n",
      "Epoch 1031/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2564 - reconstruction_loss: 316.2564 - kl_loss: 19.2506\n",
      "Epoch 1032/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3203 - reconstruction_loss: 316.3203 - kl_loss: 19.2252\n",
      "Epoch 1033/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2491 - reconstruction_loss: 316.2491 - kl_loss: 19.2180\n",
      "Epoch 1034/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4299 - reconstruction_loss: 316.4299 - kl_loss: 19.2398\n",
      "Epoch 1035/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2713 - reconstruction_loss: 316.2713 - kl_loss: 19.2634\n",
      "Epoch 1036/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2892 - reconstruction_loss: 316.2892 - kl_loss: 19.2249\n",
      "Epoch 1037/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2905 - reconstruction_loss: 316.2905 - kl_loss: 19.2614\n",
      "Epoch 1038/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2124 - reconstruction_loss: 316.2124 - kl_loss: 19.2533\n",
      "Epoch 1039/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1828 - reconstruction_loss: 316.1828 - kl_loss: 19.2833\n",
      "Epoch 1040/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1560 - reconstruction_loss: 316.1560 - kl_loss: 19.2741\n",
      "Epoch 1041/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2870 - reconstruction_loss: 316.2870 - kl_loss: 19.2674\n",
      "Epoch 1042/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3797 - reconstruction_loss: 316.3797 - kl_loss: 19.2881\n",
      "Epoch 1043/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2138 - reconstruction_loss: 316.2138 - kl_loss: 19.2715\n",
      "Epoch 1044/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2544 - reconstruction_loss: 316.2544 - kl_loss: 19.3086\n",
      "Epoch 1045/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2507 - reconstruction_loss: 316.2507 - kl_loss: 19.2862\n",
      "Epoch 1046/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.4118 - reconstruction_loss: 316.4118 - kl_loss: 19.2916\n",
      "Epoch 1047/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3198 - reconstruction_loss: 316.3198 - kl_loss: 19.2794\n",
      "Epoch 1048/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1736 - reconstruction_loss: 316.1736 - kl_loss: 19.2876\n",
      "Epoch 1049/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3590 - reconstruction_loss: 316.3590 - kl_loss: 19.3060\n",
      "Epoch 1050/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3849 - reconstruction_loss: 316.3849 - kl_loss: 19.3200\n",
      "Epoch 1051/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2116 - reconstruction_loss: 316.2116 - kl_loss: 19.3287\n",
      "Epoch 1052/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2327 - reconstruction_loss: 316.2327 - kl_loss: 19.3086\n",
      "Epoch 1053/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3135 - reconstruction_loss: 316.3135 - kl_loss: 19.3106\n",
      "Epoch 1054/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2209 - reconstruction_loss: 316.2209 - kl_loss: 19.3286\n",
      "Epoch 1055/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1979 - reconstruction_loss: 316.1979 - kl_loss: 19.3188\n",
      "Epoch 1056/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2989 - reconstruction_loss: 316.2989 - kl_loss: 19.3352\n",
      "Epoch 1057/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1678 - reconstruction_loss: 316.1678 - kl_loss: 19.3546\n",
      "Epoch 1058/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1534 - reconstruction_loss: 316.1534 - kl_loss: 19.3605\n",
      "Epoch 1059/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2714 - reconstruction_loss: 316.2714 - kl_loss: 19.3401\n",
      "Epoch 1060/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1652 - reconstruction_loss: 316.1652 - kl_loss: 19.3636\n",
      "Epoch 1061/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3012 - reconstruction_loss: 316.3012 - kl_loss: 19.3477\n",
      "Epoch 1062/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.0853 - reconstruction_loss: 316.0853 - kl_loss: 19.3557\n",
      "Epoch 1063/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1346 - reconstruction_loss: 316.1346 - kl_loss: 19.3725\n",
      "Epoch 1064/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2131 - reconstruction_loss: 316.2131 - kl_loss: 19.3526\n",
      "Epoch 1065/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3549 - reconstruction_loss: 316.3549 - kl_loss: 19.3495\n",
      "Epoch 1066/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2025 - reconstruction_loss: 316.2025 - kl_loss: 19.3374\n",
      "Epoch 1067/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1636 - reconstruction_loss: 316.1636 - kl_loss: 19.3447\n",
      "Epoch 1068/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.3302 - reconstruction_loss: 316.3302 - kl_loss: 19.3393\n",
      "Epoch 1069/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1934 - reconstruction_loss: 316.1934 - kl_loss: 19.3700\n",
      "Epoch 1070/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1623 - reconstruction_loss: 316.1623 - kl_loss: 19.3581\n",
      "Epoch 1071/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1990 - reconstruction_loss: 316.1990 - kl_loss: 19.3643\n",
      "Epoch 1072/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2535 - reconstruction_loss: 316.2535 - kl_loss: 19.3656\n",
      "Epoch 1073/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1840 - reconstruction_loss: 316.1840 - kl_loss: 19.3787\n",
      "Epoch 1074/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1444 - reconstruction_loss: 316.1444 - kl_loss: 19.4054\n",
      "Epoch 1075/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2143 - reconstruction_loss: 316.2143 - kl_loss: 19.3632\n",
      "Epoch 1076/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2324 - reconstruction_loss: 316.2324 - kl_loss: 19.3730\n",
      "Epoch 1077/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2341 - reconstruction_loss: 316.2341 - kl_loss: 19.3917\n",
      "Epoch 1078/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1685 - reconstruction_loss: 316.1685 - kl_loss: 19.3835\n",
      "Epoch 1079/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1476 - reconstruction_loss: 316.1476 - kl_loss: 19.3764\n",
      "Epoch 1080/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2098 - reconstruction_loss: 316.2098 - kl_loss: 19.4098\n",
      "Epoch 1081/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2048 - reconstruction_loss: 316.2048 - kl_loss: 19.3823\n",
      "Epoch 1082/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2776 - reconstruction_loss: 316.2776 - kl_loss: 19.4169\n",
      "Epoch 1083/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1984 - reconstruction_loss: 316.1984 - kl_loss: 19.4116\n",
      "Epoch 1084/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2308 - reconstruction_loss: 316.2308 - kl_loss: 19.4139\n",
      "Epoch 1085/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1979 - reconstruction_loss: 316.1979 - kl_loss: 19.3944\n",
      "Epoch 1086/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2412 - reconstruction_loss: 316.2412 - kl_loss: 19.3826\n",
      "Epoch 1087/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1121 - reconstruction_loss: 316.1121 - kl_loss: 19.4447\n",
      "Epoch 1088/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2404 - reconstruction_loss: 316.2404 - kl_loss: 19.4095\n",
      "Epoch 1089/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1237 - reconstruction_loss: 316.1237 - kl_loss: 19.3971\n",
      "Epoch 1090/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1561 - reconstruction_loss: 316.1561 - kl_loss: 19.4234\n",
      "Epoch 1091/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1904 - reconstruction_loss: 316.1904 - kl_loss: 19.4466\n",
      "Epoch 1092/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.0511 - reconstruction_loss: 316.0511 - kl_loss: 19.4614\n",
      "Epoch 1093/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1814 - reconstruction_loss: 316.1814 - kl_loss: 19.4541\n",
      "Epoch 1094/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1740 - reconstruction_loss: 316.1740 - kl_loss: 19.4098\n",
      "Epoch 1095/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 316.0924 - reconstruction_loss: 316.0924 - kl_loss: 19.4425\n",
      "Epoch 1096/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1079 - reconstruction_loss: 316.1079 - kl_loss: 19.4501\n",
      "Epoch 1097/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1091 - reconstruction_loss: 316.1091 - kl_loss: 19.4885\n",
      "Epoch 1098/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1649 - reconstruction_loss: 316.1649 - kl_loss: 19.4696\n",
      "Epoch 1099/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1759 - reconstruction_loss: 316.1759 - kl_loss: 19.4903\n",
      "Epoch 1100/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1582 - reconstruction_loss: 316.1582 - kl_loss: 19.4833\n",
      "Epoch 1101/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.0613 - reconstruction_loss: 316.0613 - kl_loss: 19.4837\n",
      "Epoch 1102/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1652 - reconstruction_loss: 316.1652 - kl_loss: 19.4871\n",
      "Epoch 1103/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1273 - reconstruction_loss: 316.1273 - kl_loss: 19.4997\n",
      "Epoch 1104/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.2197 - reconstruction_loss: 316.2197 - kl_loss: 19.5019\n",
      "Epoch 1105/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.0643 - reconstruction_loss: 316.0643 - kl_loss: 19.5122\n",
      "Epoch 1106/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.0795 - reconstruction_loss: 316.0795 - kl_loss: 19.5497\n",
      "Epoch 1107/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1245 - reconstruction_loss: 316.1245 - kl_loss: 19.5037\n",
      "Epoch 1108/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1599 - reconstruction_loss: 316.1599 - kl_loss: 19.5242\n",
      "Epoch 1109/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1419 - reconstruction_loss: 316.1419 - kl_loss: 19.5198\n",
      "Epoch 1110/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.9271 - reconstruction_loss: 315.9271 - kl_loss: 19.5260\n",
      "Epoch 1111/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.0123 - reconstruction_loss: 316.0123 - kl_loss: 19.5131\n",
      "Epoch 1112/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.0381 - reconstruction_loss: 316.0381 - kl_loss: 19.5170\n",
      "Epoch 1113/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.0755 - reconstruction_loss: 316.0755 - kl_loss: 19.5689\n",
      "Epoch 1114/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1222 - reconstruction_loss: 316.1222 - kl_loss: 19.5399\n",
      "Epoch 1115/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.0741 - reconstruction_loss: 316.0741 - kl_loss: 19.5573\n",
      "Epoch 1116/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.0608 - reconstruction_loss: 316.0608 - kl_loss: 19.5492\n",
      "Epoch 1117/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.9635 - reconstruction_loss: 315.9635 - kl_loss: 19.5721\n",
      "Epoch 1118/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1144 - reconstruction_loss: 316.1144 - kl_loss: 19.5949\n",
      "Epoch 1119/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1968 - reconstruction_loss: 316.1968 - kl_loss: 19.5780\n",
      "Epoch 1120/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.0362 - reconstruction_loss: 316.0362 - kl_loss: 19.5948\n",
      "Epoch 1121/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.0516 - reconstruction_loss: 316.0516 - kl_loss: 19.5632\n",
      "Epoch 1122/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1571 - reconstruction_loss: 316.1571 - kl_loss: 19.5837\n",
      "Epoch 1123/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.0432 - reconstruction_loss: 316.0432 - kl_loss: 19.6133\n",
      "Epoch 1124/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.0952 - reconstruction_loss: 316.0952 - kl_loss: 19.6034\n",
      "Epoch 1125/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.0927 - reconstruction_loss: 316.0927 - kl_loss: 19.6256\n",
      "Epoch 1126/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.0296 - reconstruction_loss: 316.0296 - kl_loss: 19.5937\n",
      "Epoch 1127/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.9700 - reconstruction_loss: 315.9700 - kl_loss: 19.6045\n",
      "Epoch 1128/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.0239 - reconstruction_loss: 316.0239 - kl_loss: 19.6184\n",
      "Epoch 1129/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.0823 - reconstruction_loss: 316.0823 - kl_loss: 19.6262\n",
      "Epoch 1130/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.0013 - reconstruction_loss: 316.0013 - kl_loss: 19.6075\n",
      "Epoch 1131/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.9371 - reconstruction_loss: 315.9371 - kl_loss: 19.6161\n",
      "Epoch 1132/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.9753 - reconstruction_loss: 315.9753 - kl_loss: 19.6328\n",
      "Epoch 1133/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.0305 - reconstruction_loss: 316.0305 - kl_loss: 19.6248\n",
      "Epoch 1134/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.9529 - reconstruction_loss: 315.9529 - kl_loss: 19.6068\n",
      "Epoch 1135/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.9820 - reconstruction_loss: 315.9820 - kl_loss: 19.6521\n",
      "Epoch 1136/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.9362 - reconstruction_loss: 315.9362 - kl_loss: 19.6564\n",
      "Epoch 1137/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.1023 - reconstruction_loss: 316.1023 - kl_loss: 19.6471\n",
      "Epoch 1138/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.9053 - reconstruction_loss: 315.9053 - kl_loss: 19.6800\n",
      "Epoch 1139/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.0611 - reconstruction_loss: 316.0611 - kl_loss: 19.6721\n",
      "Epoch 1140/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.0760 - reconstruction_loss: 316.0760 - kl_loss: 19.6605\n",
      "Epoch 1141/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.0173 - reconstruction_loss: 316.0173 - kl_loss: 19.7144\n",
      "Epoch 1142/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.9108 - reconstruction_loss: 315.9108 - kl_loss: 19.7087\n",
      "Epoch 1143/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.0999 - reconstruction_loss: 316.0999 - kl_loss: 19.6889\n",
      "Epoch 1144/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.9786 - reconstruction_loss: 315.9786 - kl_loss: 19.6979\n",
      "Epoch 1145/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.9662 - reconstruction_loss: 315.9662 - kl_loss: 19.6912\n",
      "Epoch 1146/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.0174 - reconstruction_loss: 316.0174 - kl_loss: 19.7068\n",
      "Epoch 1147/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.0130 - reconstruction_loss: 316.0130 - kl_loss: 19.7406\n",
      "Epoch 1148/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.9636 - reconstruction_loss: 315.9636 - kl_loss: 19.7513\n",
      "Epoch 1149/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.9866 - reconstruction_loss: 315.9866 - kl_loss: 19.7620\n",
      "Epoch 1150/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.9059 - reconstruction_loss: 315.9059 - kl_loss: 19.7328\n",
      "Epoch 1151/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.8358 - reconstruction_loss: 315.8358 - kl_loss: 19.7779\n",
      "Epoch 1152/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.9934 - reconstruction_loss: 315.9934 - kl_loss: 19.7930\n",
      "Epoch 1153/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 315.9103 - reconstruction_loss: 315.9103 - kl_loss: 19.7775\n",
      "Epoch 1154/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.8893 - reconstruction_loss: 315.8893 - kl_loss: 19.7853\n",
      "Epoch 1155/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.9120 - reconstruction_loss: 315.9120 - kl_loss: 19.7727\n",
      "Epoch 1156/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.9038 - reconstruction_loss: 315.9038 - kl_loss: 19.8290\n",
      "Epoch 1157/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.9418 - reconstruction_loss: 315.9418 - kl_loss: 19.8266\n",
      "Epoch 1158/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.8762 - reconstruction_loss: 315.8762 - kl_loss: 19.7888\n",
      "Epoch 1159/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.0104 - reconstruction_loss: 316.0104 - kl_loss: 19.8187\n",
      "Epoch 1160/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.9124 - reconstruction_loss: 315.9124 - kl_loss: 19.8130\n",
      "Epoch 1161/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.9388 - reconstruction_loss: 315.9388 - kl_loss: 19.8249\n",
      "Epoch 1162/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.8277 - reconstruction_loss: 315.8277 - kl_loss: 19.8276\n",
      "Epoch 1163/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.8924 - reconstruction_loss: 315.8924 - kl_loss: 19.8522\n",
      "Epoch 1164/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.9565 - reconstruction_loss: 315.9565 - kl_loss: 19.8665\n",
      "Epoch 1165/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.9084 - reconstruction_loss: 315.9084 - kl_loss: 19.8676\n",
      "Epoch 1166/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.8784 - reconstruction_loss: 315.8784 - kl_loss: 19.8648\n",
      "Epoch 1167/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.9221 - reconstruction_loss: 315.9221 - kl_loss: 19.8669\n",
      "Epoch 1168/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.8230 - reconstruction_loss: 315.8230 - kl_loss: 19.8652\n",
      "Epoch 1169/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.9555 - reconstruction_loss: 315.9555 - kl_loss: 19.9054\n",
      "Epoch 1170/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.9261 - reconstruction_loss: 315.9261 - kl_loss: 19.8646\n",
      "Epoch 1171/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.8815 - reconstruction_loss: 315.8815 - kl_loss: 19.8752\n",
      "Epoch 1172/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 316.0016 - reconstruction_loss: 316.0016 - kl_loss: 19.8739\n",
      "Epoch 1173/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.8446 - reconstruction_loss: 315.8446 - kl_loss: 19.8935\n",
      "Epoch 1174/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.8766 - reconstruction_loss: 315.8766 - kl_loss: 19.9051\n",
      "Epoch 1175/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.7713 - reconstruction_loss: 315.7713 - kl_loss: 19.9226\n",
      "Epoch 1176/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.8273 - reconstruction_loss: 315.8273 - kl_loss: 19.9075\n",
      "Epoch 1177/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.9120 - reconstruction_loss: 315.9120 - kl_loss: 19.9354\n",
      "Epoch 1178/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.8850 - reconstruction_loss: 315.8850 - kl_loss: 19.9441\n",
      "Epoch 1179/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.9707 - reconstruction_loss: 315.9707 - kl_loss: 19.9472\n",
      "Epoch 1180/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.8384 - reconstruction_loss: 315.8384 - kl_loss: 19.9565\n",
      "Epoch 1181/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.8635 - reconstruction_loss: 315.8635 - kl_loss: 19.9569\n",
      "Epoch 1182/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.8761 - reconstruction_loss: 315.8761 - kl_loss: 19.9804\n",
      "Epoch 1183/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.7318 - reconstruction_loss: 315.7318 - kl_loss: 19.9855\n",
      "Epoch 1184/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.7516 - reconstruction_loss: 315.7516 - kl_loss: 20.0200\n",
      "Epoch 1185/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.7730 - reconstruction_loss: 315.7730 - kl_loss: 20.0354\n",
      "Epoch 1186/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.9316 - reconstruction_loss: 315.9316 - kl_loss: 20.0546\n",
      "Epoch 1187/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.8369 - reconstruction_loss: 315.8369 - kl_loss: 20.0456\n",
      "Epoch 1188/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.7319 - reconstruction_loss: 315.7319 - kl_loss: 20.0400\n",
      "Epoch 1189/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.7799 - reconstruction_loss: 315.7799 - kl_loss: 20.0404\n",
      "Epoch 1190/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.7862 - reconstruction_loss: 315.7862 - kl_loss: 20.0667\n",
      "Epoch 1191/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.7157 - reconstruction_loss: 315.7157 - kl_loss: 20.0834\n",
      "Epoch 1192/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.6890 - reconstruction_loss: 315.6890 - kl_loss: 20.0899\n",
      "Epoch 1193/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.8379 - reconstruction_loss: 315.8379 - kl_loss: 20.1244\n",
      "Epoch 1194/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.6687 - reconstruction_loss: 315.6687 - kl_loss: 20.1252\n",
      "Epoch 1195/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.7291 - reconstruction_loss: 315.7291 - kl_loss: 20.1070\n",
      "Epoch 1196/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.8822 - reconstruction_loss: 315.8822 - kl_loss: 20.1408\n",
      "Epoch 1197/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.7777 - reconstruction_loss: 315.7777 - kl_loss: 20.1386\n",
      "Epoch 1198/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.6126 - reconstruction_loss: 315.6126 - kl_loss: 20.1900\n",
      "Epoch 1199/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.7461 - reconstruction_loss: 315.7461 - kl_loss: 20.1605\n",
      "Epoch 1200/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.6893 - reconstruction_loss: 315.6893 - kl_loss: 20.1960\n",
      "Epoch 1201/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.7725 - reconstruction_loss: 315.7725 - kl_loss: 20.1796\n",
      "Epoch 1202/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.6639 - reconstruction_loss: 315.6639 - kl_loss: 20.2244\n",
      "Epoch 1203/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.6463 - reconstruction_loss: 315.6463 - kl_loss: 20.2102\n",
      "Epoch 1204/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.5767 - reconstruction_loss: 315.5767 - kl_loss: 20.1939\n",
      "Epoch 1205/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.7136 - reconstruction_loss: 315.7136 - kl_loss: 20.2315\n",
      "Epoch 1206/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.7209 - reconstruction_loss: 315.7209 - kl_loss: 20.2566\n",
      "Epoch 1207/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.7623 - reconstruction_loss: 315.7623 - kl_loss: 20.2385\n",
      "Epoch 1208/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.6721 - reconstruction_loss: 315.6721 - kl_loss: 20.2663\n",
      "Epoch 1209/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.7039 - reconstruction_loss: 315.7039 - kl_loss: 20.2650\n",
      "Epoch 1210/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.7197 - reconstruction_loss: 315.7197 - kl_loss: 20.3141\n",
      "Epoch 1211/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 315.6354 - reconstruction_loss: 315.6354 - kl_loss: 20.2962\n",
      "Epoch 1212/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.6159 - reconstruction_loss: 315.6159 - kl_loss: 20.2943\n",
      "Epoch 1213/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.5207 - reconstruction_loss: 315.5207 - kl_loss: 20.3141\n",
      "Epoch 1214/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.5149 - reconstruction_loss: 315.5149 - kl_loss: 20.3328\n",
      "Epoch 1215/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.5532 - reconstruction_loss: 315.5532 - kl_loss: 20.3565\n",
      "Epoch 1216/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.7802 - reconstruction_loss: 315.7802 - kl_loss: 20.3459\n",
      "Epoch 1217/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.7022 - reconstruction_loss: 315.7022 - kl_loss: 20.3434\n",
      "Epoch 1218/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.5275 - reconstruction_loss: 315.5275 - kl_loss: 20.3614\n",
      "Epoch 1219/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.6393 - reconstruction_loss: 315.6393 - kl_loss: 20.3484\n",
      "Epoch 1220/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.6260 - reconstruction_loss: 315.6260 - kl_loss: 20.3897\n",
      "Epoch 1221/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.6341 - reconstruction_loss: 315.6341 - kl_loss: 20.3725\n",
      "Epoch 1222/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.5799 - reconstruction_loss: 315.5799 - kl_loss: 20.3818\n",
      "Epoch 1223/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.5509 - reconstruction_loss: 315.5509 - kl_loss: 20.4004\n",
      "Epoch 1224/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.5755 - reconstruction_loss: 315.5755 - kl_loss: 20.4061\n",
      "Epoch 1225/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.5022 - reconstruction_loss: 315.5022 - kl_loss: 20.4033\n",
      "Epoch 1226/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.4294 - reconstruction_loss: 315.4294 - kl_loss: 20.4377\n",
      "Epoch 1227/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.5770 - reconstruction_loss: 315.5770 - kl_loss: 20.4165\n",
      "Epoch 1228/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.5181 - reconstruction_loss: 315.5181 - kl_loss: 20.4173\n",
      "Epoch 1229/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.4337 - reconstruction_loss: 315.4337 - kl_loss: 20.4341\n",
      "Epoch 1230/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.5303 - reconstruction_loss: 315.5303 - kl_loss: 20.4590\n",
      "Epoch 1231/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.5848 - reconstruction_loss: 315.5848 - kl_loss: 20.4763\n",
      "Epoch 1232/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.5438 - reconstruction_loss: 315.5438 - kl_loss: 20.4549\n",
      "Epoch 1233/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.4414 - reconstruction_loss: 315.4414 - kl_loss: 20.4602\n",
      "Epoch 1234/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.4948 - reconstruction_loss: 315.4948 - kl_loss: 20.5080\n",
      "Epoch 1235/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.5414 - reconstruction_loss: 315.5414 - kl_loss: 20.5079\n",
      "Epoch 1236/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.4610 - reconstruction_loss: 315.4610 - kl_loss: 20.4960\n",
      "Epoch 1237/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.3955 - reconstruction_loss: 315.3955 - kl_loss: 20.5031\n",
      "Epoch 1238/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.4901 - reconstruction_loss: 315.4901 - kl_loss: 20.5126\n",
      "Epoch 1239/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.3887 - reconstruction_loss: 315.3887 - kl_loss: 20.5367\n",
      "Epoch 1240/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.3689 - reconstruction_loss: 315.3689 - kl_loss: 20.5513\n",
      "Epoch 1241/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.5127 - reconstruction_loss: 315.5127 - kl_loss: 20.5721\n",
      "Epoch 1242/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.4938 - reconstruction_loss: 315.4938 - kl_loss: 20.5561\n",
      "Epoch 1243/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.5081 - reconstruction_loss: 315.5081 - kl_loss: 20.5383\n",
      "Epoch 1244/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.3898 - reconstruction_loss: 315.3898 - kl_loss: 20.6117\n",
      "Epoch 1245/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.4818 - reconstruction_loss: 315.4818 - kl_loss: 20.6092\n",
      "Epoch 1246/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.4340 - reconstruction_loss: 315.4340 - kl_loss: 20.5971\n",
      "Epoch 1247/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.2371 - reconstruction_loss: 315.2371 - kl_loss: 20.6057\n",
      "Epoch 1248/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.3989 - reconstruction_loss: 315.3989 - kl_loss: 20.6668\n",
      "Epoch 1249/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.5645 - reconstruction_loss: 315.5645 - kl_loss: 20.6135\n",
      "Epoch 1250/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.3716 - reconstruction_loss: 315.3716 - kl_loss: 20.6609\n",
      "Epoch 1251/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.4086 - reconstruction_loss: 315.4086 - kl_loss: 20.6514\n",
      "Epoch 1252/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.3539 - reconstruction_loss: 315.3539 - kl_loss: 20.6658\n",
      "Epoch 1253/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.4591 - reconstruction_loss: 315.4591 - kl_loss: 20.6920\n",
      "Epoch 1254/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.3233 - reconstruction_loss: 315.3233 - kl_loss: 20.6821\n",
      "Epoch 1255/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.3799 - reconstruction_loss: 315.3799 - kl_loss: 20.6956\n",
      "Epoch 1256/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.3832 - reconstruction_loss: 315.3832 - kl_loss: 20.7112\n",
      "Epoch 1257/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.3844 - reconstruction_loss: 315.3844 - kl_loss: 20.7461\n",
      "Epoch 1258/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.2786 - reconstruction_loss: 315.2786 - kl_loss: 20.7309\n",
      "Epoch 1259/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.3195 - reconstruction_loss: 315.3195 - kl_loss: 20.7538\n",
      "Epoch 1260/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.2360 - reconstruction_loss: 315.2360 - kl_loss: 20.7468\n",
      "Epoch 1261/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.3818 - reconstruction_loss: 315.3818 - kl_loss: 20.7687\n",
      "Epoch 1262/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.3406 - reconstruction_loss: 315.3406 - kl_loss: 20.7884\n",
      "Epoch 1263/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.2989 - reconstruction_loss: 315.2989 - kl_loss: 20.7784\n",
      "Epoch 1264/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.1824 - reconstruction_loss: 315.1824 - kl_loss: 20.8041\n",
      "Epoch 1265/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.3462 - reconstruction_loss: 315.3462 - kl_loss: 20.8081\n",
      "Epoch 1266/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.3416 - reconstruction_loss: 315.3416 - kl_loss: 20.8341\n",
      "Epoch 1267/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.1359 - reconstruction_loss: 315.1359 - kl_loss: 20.8123\n",
      "Epoch 1268/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.2450 - reconstruction_loss: 315.2450 - kl_loss: 20.8576\n",
      "Epoch 1269/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 315.1876 - reconstruction_loss: 315.1876 - kl_loss: 20.8838\n",
      "Epoch 1270/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.2691 - reconstruction_loss: 315.2691 - kl_loss: 20.8620\n",
      "Epoch 1271/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.1129 - reconstruction_loss: 315.1129 - kl_loss: 20.8610\n",
      "Epoch 1272/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.1987 - reconstruction_loss: 315.1987 - kl_loss: 20.8859\n",
      "Epoch 1273/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.2588 - reconstruction_loss: 315.2588 - kl_loss: 20.9187\n",
      "Epoch 1274/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.1561 - reconstruction_loss: 315.1561 - kl_loss: 20.9472\n",
      "Epoch 1275/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.1245 - reconstruction_loss: 315.1245 - kl_loss: 20.9561\n",
      "Epoch 1276/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.0928 - reconstruction_loss: 315.0928 - kl_loss: 20.9585\n",
      "Epoch 1277/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.0846 - reconstruction_loss: 315.0846 - kl_loss: 20.9630\n",
      "Epoch 1278/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.0673 - reconstruction_loss: 315.0673 - kl_loss: 21.0135\n",
      "Epoch 1279/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.1104 - reconstruction_loss: 315.1104 - kl_loss: 21.0490\n",
      "Epoch 1280/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.0633 - reconstruction_loss: 315.0633 - kl_loss: 21.0165\n",
      "Epoch 1281/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.1163 - reconstruction_loss: 315.1163 - kl_loss: 21.0394\n",
      "Epoch 1282/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.9716 - reconstruction_loss: 314.9716 - kl_loss: 21.0621\n",
      "Epoch 1283/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.0412 - reconstruction_loss: 315.0412 - kl_loss: 21.0807\n",
      "Epoch 1284/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.0812 - reconstruction_loss: 315.0812 - kl_loss: 21.0504\n",
      "Epoch 1285/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.0002 - reconstruction_loss: 315.0002 - kl_loss: 21.1178\n",
      "Epoch 1286/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.0200 - reconstruction_loss: 315.0200 - kl_loss: 21.1509\n",
      "Epoch 1287/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.1057 - reconstruction_loss: 315.1057 - kl_loss: 21.1714\n",
      "Epoch 1288/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.0181 - reconstruction_loss: 315.0181 - kl_loss: 21.1618\n",
      "Epoch 1289/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.9587 - reconstruction_loss: 314.9587 - kl_loss: 21.2000\n",
      "Epoch 1290/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.9495 - reconstruction_loss: 314.9495 - kl_loss: 21.2074\n",
      "Epoch 1291/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.8915 - reconstruction_loss: 314.8915 - kl_loss: 21.2185\n",
      "Epoch 1292/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 315.0340 - reconstruction_loss: 315.0340 - kl_loss: 21.2564\n",
      "Epoch 1293/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.9107 - reconstruction_loss: 314.9107 - kl_loss: 21.2545\n",
      "Epoch 1294/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.9919 - reconstruction_loss: 314.9919 - kl_loss: 21.2723\n",
      "Epoch 1295/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.8413 - reconstruction_loss: 314.8413 - kl_loss: 21.2925\n",
      "Epoch 1296/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.7812 - reconstruction_loss: 314.7812 - kl_loss: 21.3372\n",
      "Epoch 1297/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.8204 - reconstruction_loss: 314.8204 - kl_loss: 21.3619\n",
      "Epoch 1298/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.8334 - reconstruction_loss: 314.8334 - kl_loss: 21.3464\n",
      "Epoch 1299/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.8120 - reconstruction_loss: 314.8120 - kl_loss: 21.3801\n",
      "Epoch 1300/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.8785 - reconstruction_loss: 314.8785 - kl_loss: 21.4198\n",
      "Epoch 1301/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.8130 - reconstruction_loss: 314.8130 - kl_loss: 21.4079\n",
      "Epoch 1302/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.7647 - reconstruction_loss: 314.7647 - kl_loss: 21.4304\n",
      "Epoch 1303/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.7297 - reconstruction_loss: 314.7297 - kl_loss: 21.4308\n",
      "Epoch 1304/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.8452 - reconstruction_loss: 314.8452 - kl_loss: 21.4024\n",
      "Epoch 1305/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.7856 - reconstruction_loss: 314.7856 - kl_loss: 21.4553\n",
      "Epoch 1306/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.8112 - reconstruction_loss: 314.8112 - kl_loss: 21.4449\n",
      "Epoch 1307/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.7745 - reconstruction_loss: 314.7745 - kl_loss: 21.4746\n",
      "Epoch 1308/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.7946 - reconstruction_loss: 314.7946 - kl_loss: 21.4949\n",
      "Epoch 1309/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.7337 - reconstruction_loss: 314.7337 - kl_loss: 21.5045\n",
      "Epoch 1310/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.6610 - reconstruction_loss: 314.6610 - kl_loss: 21.5584\n",
      "Epoch 1311/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.7334 - reconstruction_loss: 314.7334 - kl_loss: 21.5533\n",
      "Epoch 1312/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.7220 - reconstruction_loss: 314.7220 - kl_loss: 21.5664\n",
      "Epoch 1313/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.6182 - reconstruction_loss: 314.6182 - kl_loss: 21.5521\n",
      "Epoch 1314/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.6165 - reconstruction_loss: 314.6165 - kl_loss: 21.5577\n",
      "Epoch 1315/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.6268 - reconstruction_loss: 314.6268 - kl_loss: 21.5678\n",
      "Epoch 1316/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.5850 - reconstruction_loss: 314.5850 - kl_loss: 21.6087\n",
      "Epoch 1317/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.6683 - reconstruction_loss: 314.6683 - kl_loss: 21.6175\n",
      "Epoch 1318/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.4978 - reconstruction_loss: 314.4978 - kl_loss: 21.6427\n",
      "Epoch 1319/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.6507 - reconstruction_loss: 314.6507 - kl_loss: 21.6250\n",
      "Epoch 1320/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.5610 - reconstruction_loss: 314.5610 - kl_loss: 21.6524\n",
      "Epoch 1321/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.5550 - reconstruction_loss: 314.5550 - kl_loss: 21.6520\n",
      "Epoch 1322/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.5546 - reconstruction_loss: 314.5546 - kl_loss: 21.6827\n",
      "Epoch 1323/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.6459 - reconstruction_loss: 314.6459 - kl_loss: 21.6926\n",
      "Epoch 1324/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.6427 - reconstruction_loss: 314.6427 - kl_loss: 21.6795\n",
      "Epoch 1325/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.3955 - reconstruction_loss: 314.3955 - kl_loss: 21.6949\n",
      "Epoch 1326/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.4925 - reconstruction_loss: 314.4925 - kl_loss: 21.7353\n",
      "Epoch 1327/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 314.4220 - reconstruction_loss: 314.4220 - kl_loss: 21.7399\n",
      "Epoch 1328/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.3947 - reconstruction_loss: 314.3947 - kl_loss: 21.7261\n",
      "Epoch 1329/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.3548 - reconstruction_loss: 314.3548 - kl_loss: 21.7584\n",
      "Epoch 1330/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.4491 - reconstruction_loss: 314.4491 - kl_loss: 21.7862\n",
      "Epoch 1331/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.2897 - reconstruction_loss: 314.2897 - kl_loss: 21.7783\n",
      "Epoch 1332/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.4920 - reconstruction_loss: 314.4920 - kl_loss: 21.8149\n",
      "Epoch 1333/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.3345 - reconstruction_loss: 314.3345 - kl_loss: 21.8484\n",
      "Epoch 1334/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.4149 - reconstruction_loss: 314.4149 - kl_loss: 21.8424\n",
      "Epoch 1335/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.3700 - reconstruction_loss: 314.3700 - kl_loss: 21.8484\n",
      "Epoch 1336/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.3299 - reconstruction_loss: 314.3299 - kl_loss: 21.8788\n",
      "Epoch 1337/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.4721 - reconstruction_loss: 314.4721 - kl_loss: 21.8856\n",
      "Epoch 1338/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.3137 - reconstruction_loss: 314.3137 - kl_loss: 21.9045\n",
      "Epoch 1339/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.3204 - reconstruction_loss: 314.3204 - kl_loss: 21.9173\n",
      "Epoch 1340/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.2995 - reconstruction_loss: 314.2995 - kl_loss: 21.9195\n",
      "Epoch 1341/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.2370 - reconstruction_loss: 314.2370 - kl_loss: 21.9387\n",
      "Epoch 1342/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.2942 - reconstruction_loss: 314.2942 - kl_loss: 21.9576\n",
      "Epoch 1343/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.3448 - reconstruction_loss: 314.3448 - kl_loss: 21.9613\n",
      "Epoch 1344/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.3196 - reconstruction_loss: 314.3196 - kl_loss: 21.9926\n",
      "Epoch 1345/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.1498 - reconstruction_loss: 314.1498 - kl_loss: 22.0237\n",
      "Epoch 1346/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.2014 - reconstruction_loss: 314.2014 - kl_loss: 22.0293\n",
      "Epoch 1347/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.2729 - reconstruction_loss: 314.2729 - kl_loss: 22.0146\n",
      "Epoch 1348/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.1457 - reconstruction_loss: 314.1457 - kl_loss: 22.0422\n",
      "Epoch 1349/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.1083 - reconstruction_loss: 314.1083 - kl_loss: 22.0739\n",
      "Epoch 1350/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.2005 - reconstruction_loss: 314.2005 - kl_loss: 22.1034\n",
      "Epoch 1351/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.0910 - reconstruction_loss: 314.0910 - kl_loss: 22.1066\n",
      "Epoch 1352/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.0681 - reconstruction_loss: 314.0681 - kl_loss: 22.1542\n",
      "Epoch 1353/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.2221 - reconstruction_loss: 314.2221 - kl_loss: 22.1007\n",
      "Epoch 1354/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.1463 - reconstruction_loss: 314.1463 - kl_loss: 22.1442\n",
      "Epoch 1355/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.0297 - reconstruction_loss: 314.0297 - kl_loss: 22.1654\n",
      "Epoch 1356/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.1310 - reconstruction_loss: 314.1310 - kl_loss: 22.1652\n",
      "Epoch 1357/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.0042 - reconstruction_loss: 314.0042 - kl_loss: 22.1850\n",
      "Epoch 1358/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.0246 - reconstruction_loss: 314.0246 - kl_loss: 22.1923\n",
      "Epoch 1359/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.0577 - reconstruction_loss: 314.0577 - kl_loss: 22.2152\n",
      "Epoch 1360/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.0246 - reconstruction_loss: 314.0246 - kl_loss: 22.1851\n",
      "Epoch 1361/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.9876 - reconstruction_loss: 313.9876 - kl_loss: 22.2295\n",
      "Epoch 1362/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.9002 - reconstruction_loss: 313.9002 - kl_loss: 22.2843\n",
      "Epoch 1363/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.9990 - reconstruction_loss: 313.9990 - kl_loss: 22.2836\n",
      "Epoch 1364/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.8868 - reconstruction_loss: 313.8868 - kl_loss: 22.2632\n",
      "Epoch 1365/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.9269 - reconstruction_loss: 313.9269 - kl_loss: 22.3145\n",
      "Epoch 1366/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.9265 - reconstruction_loss: 313.9265 - kl_loss: 22.2956\n",
      "Epoch 1367/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.9651 - reconstruction_loss: 313.9651 - kl_loss: 22.2969\n",
      "Epoch 1368/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.8447 - reconstruction_loss: 313.8447 - kl_loss: 22.3192\n",
      "Epoch 1369/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.9178 - reconstruction_loss: 313.9178 - kl_loss: 22.3504\n",
      "Epoch 1370/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 314.0157 - reconstruction_loss: 314.0157 - kl_loss: 22.3623\n",
      "Epoch 1371/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.8730 - reconstruction_loss: 313.8730 - kl_loss: 22.3768\n",
      "Epoch 1372/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.8940 - reconstruction_loss: 313.8940 - kl_loss: 22.3833\n",
      "Epoch 1373/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.7781 - reconstruction_loss: 313.7781 - kl_loss: 22.4141\n",
      "Epoch 1374/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.8249 - reconstruction_loss: 313.8249 - kl_loss: 22.4365\n",
      "Epoch 1375/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.7072 - reconstruction_loss: 313.7072 - kl_loss: 22.4295\n",
      "Epoch 1376/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.8544 - reconstruction_loss: 313.8544 - kl_loss: 22.4306\n",
      "Epoch 1377/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.8768 - reconstruction_loss: 313.8768 - kl_loss: 22.4739\n",
      "Epoch 1378/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.7896 - reconstruction_loss: 313.7896 - kl_loss: 22.5165\n",
      "Epoch 1379/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.7195 - reconstruction_loss: 313.7195 - kl_loss: 22.5080\n",
      "Epoch 1380/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.8071 - reconstruction_loss: 313.8071 - kl_loss: 22.5378\n",
      "Epoch 1381/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.7626 - reconstruction_loss: 313.7626 - kl_loss: 22.5465\n",
      "Epoch 1382/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.8842 - reconstruction_loss: 313.8842 - kl_loss: 22.5423\n",
      "Epoch 1383/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.8586 - reconstruction_loss: 313.8586 - kl_loss: 22.5460\n",
      "Epoch 1384/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.7266 - reconstruction_loss: 313.7266 - kl_loss: 22.5630\n",
      "Epoch 1385/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 313.8203 - reconstruction_loss: 313.8203 - kl_loss: 22.5610\n",
      "Epoch 1386/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.6854 - reconstruction_loss: 313.6854 - kl_loss: 22.5981\n",
      "Epoch 1387/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.7288 - reconstruction_loss: 313.7288 - kl_loss: 22.5800\n",
      "Epoch 1388/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.8393 - reconstruction_loss: 313.8393 - kl_loss: 22.6215\n",
      "Epoch 1389/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.6792 - reconstruction_loss: 313.6792 - kl_loss: 22.6556\n",
      "Epoch 1390/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.6609 - reconstruction_loss: 313.6609 - kl_loss: 22.6744\n",
      "Epoch 1391/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.7011 - reconstruction_loss: 313.7011 - kl_loss: 22.6958\n",
      "Epoch 1392/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.6311 - reconstruction_loss: 313.6311 - kl_loss: 22.7104\n",
      "Epoch 1393/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.7218 - reconstruction_loss: 313.7218 - kl_loss: 22.7174\n",
      "Epoch 1394/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.6279 - reconstruction_loss: 313.6279 - kl_loss: 22.6974\n",
      "Epoch 1395/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.7065 - reconstruction_loss: 313.7065 - kl_loss: 22.7374\n",
      "Epoch 1396/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.5685 - reconstruction_loss: 313.5685 - kl_loss: 22.7178\n",
      "Epoch 1397/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.6832 - reconstruction_loss: 313.6832 - kl_loss: 22.7856\n",
      "Epoch 1398/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.5856 - reconstruction_loss: 313.5856 - kl_loss: 22.7955\n",
      "Epoch 1399/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.5100 - reconstruction_loss: 313.5100 - kl_loss: 22.8244\n",
      "Epoch 1400/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.4879 - reconstruction_loss: 313.4879 - kl_loss: 22.8549\n",
      "Epoch 1401/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.5424 - reconstruction_loss: 313.5424 - kl_loss: 22.8546\n",
      "Epoch 1402/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.5388 - reconstruction_loss: 313.5388 - kl_loss: 22.8635\n",
      "Epoch 1403/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.4504 - reconstruction_loss: 313.4504 - kl_loss: 22.9119\n",
      "Epoch 1404/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.4417 - reconstruction_loss: 313.4417 - kl_loss: 22.8674\n",
      "Epoch 1405/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.4242 - reconstruction_loss: 313.4242 - kl_loss: 22.9357\n",
      "Epoch 1406/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.4192 - reconstruction_loss: 313.4192 - kl_loss: 22.9347\n",
      "Epoch 1407/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.4465 - reconstruction_loss: 313.4465 - kl_loss: 22.9237\n",
      "Epoch 1408/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.4524 - reconstruction_loss: 313.4524 - kl_loss: 22.9361\n",
      "Epoch 1409/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.5115 - reconstruction_loss: 313.5115 - kl_loss: 23.0093\n",
      "Epoch 1410/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.4054 - reconstruction_loss: 313.4054 - kl_loss: 22.9963\n",
      "Epoch 1411/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.4393 - reconstruction_loss: 313.4393 - kl_loss: 23.0316\n",
      "Epoch 1412/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.2802 - reconstruction_loss: 313.2802 - kl_loss: 23.0214\n",
      "Epoch 1413/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.3132 - reconstruction_loss: 313.3132 - kl_loss: 23.0788\n",
      "Epoch 1414/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.4050 - reconstruction_loss: 313.4050 - kl_loss: 23.0534\n",
      "Epoch 1415/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.3482 - reconstruction_loss: 313.3482 - kl_loss: 23.1165\n",
      "Epoch 1416/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.4072 - reconstruction_loss: 313.4072 - kl_loss: 23.0899\n",
      "Epoch 1417/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.3226 - reconstruction_loss: 313.3226 - kl_loss: 23.0960\n",
      "Epoch 1418/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.3356 - reconstruction_loss: 313.3356 - kl_loss: 23.0921\n",
      "Epoch 1419/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.3194 - reconstruction_loss: 313.3194 - kl_loss: 23.1598\n",
      "Epoch 1420/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.2993 - reconstruction_loss: 313.2993 - kl_loss: 23.1249\n",
      "Epoch 1421/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.3586 - reconstruction_loss: 313.3586 - kl_loss: 23.1689\n",
      "Epoch 1422/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.3823 - reconstruction_loss: 313.3823 - kl_loss: 23.1945\n",
      "Epoch 1423/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.2632 - reconstruction_loss: 313.2632 - kl_loss: 23.2026\n",
      "Epoch 1424/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.2838 - reconstruction_loss: 313.2838 - kl_loss: 23.2176\n",
      "Epoch 1425/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.2759 - reconstruction_loss: 313.2759 - kl_loss: 23.2645\n",
      "Epoch 1426/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.3509 - reconstruction_loss: 313.3509 - kl_loss: 23.2642\n",
      "Epoch 1427/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.2297 - reconstruction_loss: 313.2297 - kl_loss: 23.2663\n",
      "Epoch 1428/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.1824 - reconstruction_loss: 313.1824 - kl_loss: 23.3113\n",
      "Epoch 1429/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.1293 - reconstruction_loss: 313.1293 - kl_loss: 23.3412\n",
      "Epoch 1430/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.2572 - reconstruction_loss: 313.2572 - kl_loss: 23.3469\n",
      "Epoch 1431/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.1872 - reconstruction_loss: 313.1872 - kl_loss: 23.3503\n",
      "Epoch 1432/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.2833 - reconstruction_loss: 313.2833 - kl_loss: 23.3622\n",
      "Epoch 1433/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.0963 - reconstruction_loss: 313.0963 - kl_loss: 23.3806\n",
      "Epoch 1434/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.0991 - reconstruction_loss: 313.0991 - kl_loss: 23.3992\n",
      "Epoch 1435/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.1383 - reconstruction_loss: 313.1383 - kl_loss: 23.4122\n",
      "Epoch 1436/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.0917 - reconstruction_loss: 313.0917 - kl_loss: 23.4674\n",
      "Epoch 1437/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.1308 - reconstruction_loss: 313.1308 - kl_loss: 23.4655\n",
      "Epoch 1438/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.1266 - reconstruction_loss: 313.1266 - kl_loss: 23.4900\n",
      "Epoch 1439/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.1978 - reconstruction_loss: 313.1978 - kl_loss: 23.4626\n",
      "Epoch 1440/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.9789 - reconstruction_loss: 312.9789 - kl_loss: 23.5204\n",
      "Epoch 1441/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.1385 - reconstruction_loss: 313.1385 - kl_loss: 23.5347\n",
      "Epoch 1442/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.1613 - reconstruction_loss: 313.1613 - kl_loss: 23.5631\n",
      "Epoch 1443/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 313.1118 - reconstruction_loss: 313.1118 - kl_loss: 23.5829\n",
      "Epoch 1444/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.1074 - reconstruction_loss: 313.1074 - kl_loss: 23.5940\n",
      "Epoch 1445/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.0059 - reconstruction_loss: 313.0059 - kl_loss: 23.6093\n",
      "Epoch 1446/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.9849 - reconstruction_loss: 312.9849 - kl_loss: 23.6260\n",
      "Epoch 1447/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.0657 - reconstruction_loss: 313.0657 - kl_loss: 23.6244\n",
      "Epoch 1448/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.9685 - reconstruction_loss: 312.9685 - kl_loss: 23.6327\n",
      "Epoch 1449/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.0665 - reconstruction_loss: 313.0665 - kl_loss: 23.6693\n",
      "Epoch 1450/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.9986 - reconstruction_loss: 312.9986 - kl_loss: 23.6832\n",
      "Epoch 1451/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.9240 - reconstruction_loss: 312.9240 - kl_loss: 23.6948\n",
      "Epoch 1452/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.9487 - reconstruction_loss: 312.9487 - kl_loss: 23.7020\n",
      "Epoch 1453/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.9828 - reconstruction_loss: 312.9828 - kl_loss: 23.7406\n",
      "Epoch 1454/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 313.0819 - reconstruction_loss: 313.0819 - kl_loss: 23.7320\n",
      "Epoch 1455/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.9364 - reconstruction_loss: 312.9364 - kl_loss: 23.7659\n",
      "Epoch 1456/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.9305 - reconstruction_loss: 312.9305 - kl_loss: 23.8239\n",
      "Epoch 1457/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.8355 - reconstruction_loss: 312.8355 - kl_loss: 23.8007\n",
      "Epoch 1458/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.8962 - reconstruction_loss: 312.8962 - kl_loss: 23.8526\n",
      "Epoch 1459/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.9113 - reconstruction_loss: 312.9113 - kl_loss: 23.8047\n",
      "Epoch 1460/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.9996 - reconstruction_loss: 312.9996 - kl_loss: 23.8192\n",
      "Epoch 1461/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.8691 - reconstruction_loss: 312.8691 - kl_loss: 23.8908\n",
      "Epoch 1462/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.8992 - reconstruction_loss: 312.8992 - kl_loss: 23.8632\n",
      "Epoch 1463/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.8961 - reconstruction_loss: 312.8961 - kl_loss: 23.9228\n",
      "Epoch 1464/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.7740 - reconstruction_loss: 312.7740 - kl_loss: 23.9143\n",
      "Epoch 1465/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.8337 - reconstruction_loss: 312.8337 - kl_loss: 23.9171\n",
      "Epoch 1466/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.8164 - reconstruction_loss: 312.8164 - kl_loss: 23.9065\n",
      "Epoch 1467/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.6662 - reconstruction_loss: 312.6662 - kl_loss: 23.9467\n",
      "Epoch 1468/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.8981 - reconstruction_loss: 312.8981 - kl_loss: 23.9884\n",
      "Epoch 1469/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.7085 - reconstruction_loss: 312.7085 - kl_loss: 24.0065\n",
      "Epoch 1470/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.7572 - reconstruction_loss: 312.7572 - kl_loss: 24.0194\n",
      "Epoch 1471/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.8149 - reconstruction_loss: 312.8149 - kl_loss: 23.9773\n",
      "Epoch 1472/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.6392 - reconstruction_loss: 312.6392 - kl_loss: 24.0126\n",
      "Epoch 1473/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.7514 - reconstruction_loss: 312.7514 - kl_loss: 24.0345\n",
      "Epoch 1474/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.6672 - reconstruction_loss: 312.6672 - kl_loss: 24.1010\n",
      "Epoch 1475/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.6174 - reconstruction_loss: 312.6174 - kl_loss: 24.0474\n",
      "Epoch 1476/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.6193 - reconstruction_loss: 312.6193 - kl_loss: 24.0776\n",
      "Epoch 1477/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.8353 - reconstruction_loss: 312.8353 - kl_loss: 24.0771\n",
      "Epoch 1478/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.5520 - reconstruction_loss: 312.5520 - kl_loss: 24.1034\n",
      "Epoch 1479/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.5726 - reconstruction_loss: 312.5726 - kl_loss: 24.1421\n",
      "Epoch 1480/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.6125 - reconstruction_loss: 312.6125 - kl_loss: 24.1548\n",
      "Epoch 1481/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.5314 - reconstruction_loss: 312.5314 - kl_loss: 24.1618\n",
      "Epoch 1482/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.6291 - reconstruction_loss: 312.6291 - kl_loss: 24.1467\n",
      "Epoch 1483/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.4219 - reconstruction_loss: 312.4219 - kl_loss: 24.2000\n",
      "Epoch 1484/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.6383 - reconstruction_loss: 312.6383 - kl_loss: 24.1993\n",
      "Epoch 1485/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.5640 - reconstruction_loss: 312.5640 - kl_loss: 24.1860\n",
      "Epoch 1486/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.6165 - reconstruction_loss: 312.6165 - kl_loss: 24.1762\n",
      "Epoch 1487/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.5858 - reconstruction_loss: 312.5858 - kl_loss: 24.2425\n",
      "Epoch 1488/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.6009 - reconstruction_loss: 312.6009 - kl_loss: 24.2457\n",
      "Epoch 1489/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.5574 - reconstruction_loss: 312.5574 - kl_loss: 24.2677\n",
      "Epoch 1490/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.4339 - reconstruction_loss: 312.4339 - kl_loss: 24.2635\n",
      "Epoch 1491/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.6088 - reconstruction_loss: 312.6088 - kl_loss: 24.2733\n",
      "Epoch 1492/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.5381 - reconstruction_loss: 312.5381 - kl_loss: 24.2901\n",
      "Epoch 1493/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.5527 - reconstruction_loss: 312.5527 - kl_loss: 24.2808\n",
      "Epoch 1494/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.3656 - reconstruction_loss: 312.3656 - kl_loss: 24.3199\n",
      "Epoch 1495/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.6267 - reconstruction_loss: 312.6267 - kl_loss: 24.3366\n",
      "Epoch 1496/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.5650 - reconstruction_loss: 312.5650 - kl_loss: 24.3099\n",
      "Epoch 1497/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.5739 - reconstruction_loss: 312.5739 - kl_loss: 24.3358\n",
      "Epoch 1498/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.4517 - reconstruction_loss: 312.4517 - kl_loss: 24.3656\n",
      "Epoch 1499/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.5500 - reconstruction_loss: 312.5500 - kl_loss: 24.3450\n",
      "Epoch 1500/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.3595 - reconstruction_loss: 312.3595 - kl_loss: 24.3676\n",
      "Epoch 1501/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 312.3212 - reconstruction_loss: 312.3212 - kl_loss: 24.3875\n",
      "Epoch 1502/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.4060 - reconstruction_loss: 312.4060 - kl_loss: 24.4064\n",
      "Epoch 1503/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.3943 - reconstruction_loss: 312.3943 - kl_loss: 24.3332\n",
      "Epoch 1504/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.3526 - reconstruction_loss: 312.3526 - kl_loss: 24.4114\n",
      "Epoch 1505/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.3709 - reconstruction_loss: 312.3709 - kl_loss: 24.4138\n",
      "Epoch 1506/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.3185 - reconstruction_loss: 312.3185 - kl_loss: 24.4183\n",
      "Epoch 1507/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.2805 - reconstruction_loss: 312.2805 - kl_loss: 24.4437\n",
      "Epoch 1508/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.2797 - reconstruction_loss: 312.2797 - kl_loss: 24.4733\n",
      "Epoch 1509/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.3733 - reconstruction_loss: 312.3733 - kl_loss: 24.4404\n",
      "Epoch 1510/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.2984 - reconstruction_loss: 312.2984 - kl_loss: 24.4668\n",
      "Epoch 1511/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.4349 - reconstruction_loss: 312.4349 - kl_loss: 24.4879\n",
      "Epoch 1512/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.4444 - reconstruction_loss: 312.4444 - kl_loss: 24.4767\n",
      "Epoch 1513/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.2964 - reconstruction_loss: 312.2964 - kl_loss: 24.4403\n",
      "Epoch 1514/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.3352 - reconstruction_loss: 312.3352 - kl_loss: 24.5099\n",
      "Epoch 1515/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.3295 - reconstruction_loss: 312.3295 - kl_loss: 24.4705\n",
      "Epoch 1516/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.3069 - reconstruction_loss: 312.3069 - kl_loss: 24.5183\n",
      "Epoch 1517/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.3026 - reconstruction_loss: 312.3026 - kl_loss: 24.5366\n",
      "Epoch 1518/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.3404 - reconstruction_loss: 312.3404 - kl_loss: 24.5370\n",
      "Epoch 1519/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.2866 - reconstruction_loss: 312.2866 - kl_loss: 24.5894\n",
      "Epoch 1520/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.2240 - reconstruction_loss: 312.2240 - kl_loss: 24.5440\n",
      "Epoch 1521/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.2236 - reconstruction_loss: 312.2236 - kl_loss: 24.5427\n",
      "Epoch 1522/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.2913 - reconstruction_loss: 312.2913 - kl_loss: 24.5548\n",
      "Epoch 1523/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.1018 - reconstruction_loss: 312.1018 - kl_loss: 24.5701\n",
      "Epoch 1524/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.3135 - reconstruction_loss: 312.3135 - kl_loss: 24.5943\n",
      "Epoch 1525/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.1974 - reconstruction_loss: 312.1974 - kl_loss: 24.6028\n",
      "Epoch 1526/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.1821 - reconstruction_loss: 312.1821 - kl_loss: 24.6300\n",
      "Epoch 1527/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.1802 - reconstruction_loss: 312.1802 - kl_loss: 24.6547\n",
      "Epoch 1528/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.1411 - reconstruction_loss: 312.1411 - kl_loss: 24.6059\n",
      "Epoch 1529/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.0462 - reconstruction_loss: 312.0462 - kl_loss: 24.5895\n",
      "Epoch 1530/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.1486 - reconstruction_loss: 312.1486 - kl_loss: 24.6562\n",
      "Epoch 1531/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.0696 - reconstruction_loss: 312.0696 - kl_loss: 24.6442\n",
      "Epoch 1532/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.2556 - reconstruction_loss: 312.2556 - kl_loss: 24.6094\n",
      "Epoch 1533/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.0752 - reconstruction_loss: 312.0752 - kl_loss: 24.6933\n",
      "Epoch 1534/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.0636 - reconstruction_loss: 312.0636 - kl_loss: 24.6760\n",
      "Epoch 1535/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.0747 - reconstruction_loss: 312.0747 - kl_loss: 24.7028\n",
      "Epoch 1536/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.1190 - reconstruction_loss: 312.1190 - kl_loss: 24.6830\n",
      "Epoch 1537/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.1622 - reconstruction_loss: 312.1622 - kl_loss: 24.7151\n",
      "Epoch 1538/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.0647 - reconstruction_loss: 312.0647 - kl_loss: 24.7131\n",
      "Epoch 1539/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.0040 - reconstruction_loss: 312.0040 - kl_loss: 24.7675\n",
      "Epoch 1540/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.0631 - reconstruction_loss: 312.0631 - kl_loss: 24.7277\n",
      "Epoch 1541/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.0400 - reconstruction_loss: 312.0400 - kl_loss: 24.7389\n",
      "Epoch 1542/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.1774 - reconstruction_loss: 312.1774 - kl_loss: 24.7689\n",
      "Epoch 1543/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.9207 - reconstruction_loss: 311.9207 - kl_loss: 24.7744\n",
      "Epoch 1544/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.0729 - reconstruction_loss: 312.0729 - kl_loss: 24.7983\n",
      "Epoch 1545/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.0543 - reconstruction_loss: 312.0543 - kl_loss: 24.8090\n",
      "Epoch 1546/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.8343 - reconstruction_loss: 311.8343 - kl_loss: 24.8033\n",
      "Epoch 1547/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.9995 - reconstruction_loss: 311.9995 - kl_loss: 24.8281\n",
      "Epoch 1548/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.0206 - reconstruction_loss: 312.0206 - kl_loss: 24.7989\n",
      "Epoch 1549/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.9849 - reconstruction_loss: 311.9849 - kl_loss: 24.8496\n",
      "Epoch 1550/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.8741 - reconstruction_loss: 311.8741 - kl_loss: 24.8663\n",
      "Epoch 1551/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.0056 - reconstruction_loss: 312.0056 - kl_loss: 24.8505\n",
      "Epoch 1552/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.8170 - reconstruction_loss: 311.8170 - kl_loss: 24.8778\n",
      "Epoch 1553/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 312.0634 - reconstruction_loss: 312.0634 - kl_loss: 24.8550\n",
      "Epoch 1554/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.9215 - reconstruction_loss: 311.9215 - kl_loss: 24.9292\n",
      "Epoch 1555/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.8515 - reconstruction_loss: 311.8515 - kl_loss: 24.9051\n",
      "Epoch 1556/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.8797 - reconstruction_loss: 311.8797 - kl_loss: 24.9048\n",
      "Epoch 1557/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.9967 - reconstruction_loss: 311.9967 - kl_loss: 24.8919\n",
      "Epoch 1558/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.9076 - reconstruction_loss: 311.9076 - kl_loss: 24.9003\n",
      "Epoch 1559/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 311.9344 - reconstruction_loss: 311.9344 - kl_loss: 24.9457\n",
      "Epoch 1560/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.9740 - reconstruction_loss: 311.9740 - kl_loss: 24.9305\n",
      "Epoch 1561/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.9313 - reconstruction_loss: 311.9313 - kl_loss: 24.9987\n",
      "Epoch 1562/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.8415 - reconstruction_loss: 311.8415 - kl_loss: 25.0127\n",
      "Epoch 1563/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.9140 - reconstruction_loss: 311.9140 - kl_loss: 25.0148\n",
      "Epoch 1564/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.7984 - reconstruction_loss: 311.7984 - kl_loss: 24.9911\n",
      "Epoch 1565/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.7409 - reconstruction_loss: 311.7409 - kl_loss: 24.9881\n",
      "Epoch 1566/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.8629 - reconstruction_loss: 311.8629 - kl_loss: 24.9972\n",
      "Epoch 1567/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.8124 - reconstruction_loss: 311.8124 - kl_loss: 24.9883\n",
      "Epoch 1568/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.8591 - reconstruction_loss: 311.8591 - kl_loss: 25.0496\n",
      "Epoch 1569/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.8795 - reconstruction_loss: 311.8795 - kl_loss: 25.0923\n",
      "Epoch 1570/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.9023 - reconstruction_loss: 311.9023 - kl_loss: 25.0800\n",
      "Epoch 1571/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.8957 - reconstruction_loss: 311.8957 - kl_loss: 25.0409\n",
      "Epoch 1572/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.7644 - reconstruction_loss: 311.7644 - kl_loss: 25.0493\n",
      "Epoch 1573/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.7769 - reconstruction_loss: 311.7769 - kl_loss: 25.0635\n",
      "Epoch 1574/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.8155 - reconstruction_loss: 311.8155 - kl_loss: 25.0702\n",
      "Epoch 1575/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.8041 - reconstruction_loss: 311.8041 - kl_loss: 25.0806\n",
      "Epoch 1576/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.7755 - reconstruction_loss: 311.7755 - kl_loss: 25.1122\n",
      "Epoch 1577/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.8320 - reconstruction_loss: 311.8320 - kl_loss: 25.1150\n",
      "Epoch 1578/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.7007 - reconstruction_loss: 311.7007 - kl_loss: 25.1340\n",
      "Epoch 1579/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.6697 - reconstruction_loss: 311.6697 - kl_loss: 25.1694\n",
      "Epoch 1580/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.7884 - reconstruction_loss: 311.7884 - kl_loss: 25.1687\n",
      "Epoch 1581/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.6173 - reconstruction_loss: 311.6173 - kl_loss: 25.1403\n",
      "Epoch 1582/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.6384 - reconstruction_loss: 311.6384 - kl_loss: 25.1583\n",
      "Epoch 1583/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.6944 - reconstruction_loss: 311.6944 - kl_loss: 25.1973\n",
      "Epoch 1584/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.6649 - reconstruction_loss: 311.6649 - kl_loss: 25.2041\n",
      "Epoch 1585/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.8086 - reconstruction_loss: 311.8086 - kl_loss: 25.1760\n",
      "Epoch 1586/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.7130 - reconstruction_loss: 311.7130 - kl_loss: 25.1973\n",
      "Epoch 1587/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.7218 - reconstruction_loss: 311.7218 - kl_loss: 25.2347\n",
      "Epoch 1588/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.6348 - reconstruction_loss: 311.6348 - kl_loss: 25.2456\n",
      "Epoch 1589/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.5759 - reconstruction_loss: 311.5759 - kl_loss: 25.2041\n",
      "Epoch 1590/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.7191 - reconstruction_loss: 311.7191 - kl_loss: 25.2643\n",
      "Epoch 1591/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.6028 - reconstruction_loss: 311.6028 - kl_loss: 25.2224\n",
      "Epoch 1592/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.6944 - reconstruction_loss: 311.6944 - kl_loss: 25.2399\n",
      "Epoch 1593/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.5232 - reconstruction_loss: 311.5232 - kl_loss: 25.2642\n",
      "Epoch 1594/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.6133 - reconstruction_loss: 311.6133 - kl_loss: 25.2792\n",
      "Epoch 1595/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.5215 - reconstruction_loss: 311.5215 - kl_loss: 25.2801\n",
      "Epoch 1596/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.6305 - reconstruction_loss: 311.6305 - kl_loss: 25.2767\n",
      "Epoch 1597/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.6730 - reconstruction_loss: 311.6730 - kl_loss: 25.3289\n",
      "Epoch 1598/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.6562 - reconstruction_loss: 311.6562 - kl_loss: 25.3180\n",
      "Epoch 1599/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.5692 - reconstruction_loss: 311.5692 - kl_loss: 25.3265\n",
      "Epoch 1600/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.5845 - reconstruction_loss: 311.5845 - kl_loss: 25.3194\n",
      "Epoch 1601/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.6208 - reconstruction_loss: 311.6208 - kl_loss: 25.3413\n",
      "Epoch 1602/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.4837 - reconstruction_loss: 311.4837 - kl_loss: 25.3726\n",
      "Epoch 1603/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.5082 - reconstruction_loss: 311.5082 - kl_loss: 25.3695\n",
      "Epoch 1604/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.5152 - reconstruction_loss: 311.5152 - kl_loss: 25.3351\n",
      "Epoch 1605/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.4712 - reconstruction_loss: 311.4712 - kl_loss: 25.3875\n",
      "Epoch 1606/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.5278 - reconstruction_loss: 311.5278 - kl_loss: 25.4396\n",
      "Epoch 1607/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.6109 - reconstruction_loss: 311.6109 - kl_loss: 25.4098\n",
      "Epoch 1608/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.4940 - reconstruction_loss: 311.4940 - kl_loss: 25.3929\n",
      "Epoch 1609/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.4908 - reconstruction_loss: 311.4908 - kl_loss: 25.4507\n",
      "Epoch 1610/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.4490 - reconstruction_loss: 311.4490 - kl_loss: 25.4639\n",
      "Epoch 1611/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.4835 - reconstruction_loss: 311.4835 - kl_loss: 25.4199\n",
      "Epoch 1612/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.5231 - reconstruction_loss: 311.5231 - kl_loss: 25.4434\n",
      "Epoch 1613/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.5692 - reconstruction_loss: 311.5692 - kl_loss: 25.4740\n",
      "Epoch 1614/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.4917 - reconstruction_loss: 311.4917 - kl_loss: 25.4500\n",
      "Epoch 1615/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.5383 - reconstruction_loss: 311.5383 - kl_loss: 25.5052\n",
      "Epoch 1616/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.5367 - reconstruction_loss: 311.5367 - kl_loss: 25.4745\n",
      "Epoch 1617/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 311.5570 - reconstruction_loss: 311.5570 - kl_loss: 25.5243\n",
      "Epoch 1618/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.4796 - reconstruction_loss: 311.4796 - kl_loss: 25.4993\n",
      "Epoch 1619/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.5065 - reconstruction_loss: 311.5065 - kl_loss: 25.5277\n",
      "Epoch 1620/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.4882 - reconstruction_loss: 311.4882 - kl_loss: 25.5265\n",
      "Epoch 1621/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.4017 - reconstruction_loss: 311.4017 - kl_loss: 25.5222\n",
      "Epoch 1622/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.4345 - reconstruction_loss: 311.4345 - kl_loss: 25.4880\n",
      "Epoch 1623/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.3635 - reconstruction_loss: 311.3635 - kl_loss: 25.5654\n",
      "Epoch 1624/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.5247 - reconstruction_loss: 311.5247 - kl_loss: 25.5526\n",
      "Epoch 1625/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.3802 - reconstruction_loss: 311.3802 - kl_loss: 25.5682\n",
      "Epoch 1626/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.3860 - reconstruction_loss: 311.3860 - kl_loss: 25.6482\n",
      "Epoch 1627/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.3313 - reconstruction_loss: 311.3313 - kl_loss: 25.5857\n",
      "Epoch 1628/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.3799 - reconstruction_loss: 311.3799 - kl_loss: 25.6183\n",
      "Epoch 1629/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.3564 - reconstruction_loss: 311.3564 - kl_loss: 25.6135\n",
      "Epoch 1630/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.2574 - reconstruction_loss: 311.2574 - kl_loss: 25.6246\n",
      "Epoch 1631/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.5079 - reconstruction_loss: 311.5079 - kl_loss: 25.6121\n",
      "Epoch 1632/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.3338 - reconstruction_loss: 311.3338 - kl_loss: 25.6336\n",
      "Epoch 1633/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.3550 - reconstruction_loss: 311.3550 - kl_loss: 25.6751\n",
      "Epoch 1634/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.3492 - reconstruction_loss: 311.3492 - kl_loss: 25.6217\n",
      "Epoch 1635/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.3804 - reconstruction_loss: 311.3804 - kl_loss: 25.6914\n",
      "Epoch 1636/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.3478 - reconstruction_loss: 311.3478 - kl_loss: 25.6772\n",
      "Epoch 1637/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.4585 - reconstruction_loss: 311.4585 - kl_loss: 25.7483\n",
      "Epoch 1638/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.3678 - reconstruction_loss: 311.3678 - kl_loss: 25.7137\n",
      "Epoch 1639/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.3114 - reconstruction_loss: 311.3114 - kl_loss: 25.7014\n",
      "Epoch 1640/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.3395 - reconstruction_loss: 311.3395 - kl_loss: 25.6871\n",
      "Epoch 1641/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.3722 - reconstruction_loss: 311.3722 - kl_loss: 25.7362\n",
      "Epoch 1642/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.3011 - reconstruction_loss: 311.3011 - kl_loss: 25.7278\n",
      "Epoch 1643/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.2960 - reconstruction_loss: 311.2960 - kl_loss: 25.7388\n",
      "Epoch 1644/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.2192 - reconstruction_loss: 311.2192 - kl_loss: 25.7610\n",
      "Epoch 1645/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.3419 - reconstruction_loss: 311.3419 - kl_loss: 25.7563\n",
      "Epoch 1646/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.3653 - reconstruction_loss: 311.3653 - kl_loss: 25.7259\n",
      "Epoch 1647/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.1680 - reconstruction_loss: 311.1680 - kl_loss: 25.7646\n",
      "Epoch 1648/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.1790 - reconstruction_loss: 311.1790 - kl_loss: 25.7653\n",
      "Epoch 1649/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.3187 - reconstruction_loss: 311.3187 - kl_loss: 25.7591\n",
      "Epoch 1650/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.3111 - reconstruction_loss: 311.3111 - kl_loss: 25.8075\n",
      "Epoch 1651/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.2748 - reconstruction_loss: 311.2748 - kl_loss: 25.7824\n",
      "Epoch 1652/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.2153 - reconstruction_loss: 311.2153 - kl_loss: 25.8373\n",
      "Epoch 1653/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.3603 - reconstruction_loss: 311.3603 - kl_loss: 25.8385\n",
      "Epoch 1654/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.3267 - reconstruction_loss: 311.3267 - kl_loss: 25.8062\n",
      "Epoch 1655/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.2710 - reconstruction_loss: 311.2710 - kl_loss: 25.8175\n",
      "Epoch 1656/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.2984 - reconstruction_loss: 311.2984 - kl_loss: 25.7912\n",
      "Epoch 1657/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.1748 - reconstruction_loss: 311.1748 - kl_loss: 25.8672\n",
      "Epoch 1658/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.2176 - reconstruction_loss: 311.2176 - kl_loss: 25.8604\n",
      "Epoch 1659/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.1024 - reconstruction_loss: 311.1024 - kl_loss: 25.8628\n",
      "Epoch 1660/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.1523 - reconstruction_loss: 311.1523 - kl_loss: 25.8765\n",
      "Epoch 1661/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.1929 - reconstruction_loss: 311.1929 - kl_loss: 25.8914\n",
      "Epoch 1662/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.1749 - reconstruction_loss: 311.1749 - kl_loss: 25.8713\n",
      "Epoch 1663/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.1706 - reconstruction_loss: 311.1706 - kl_loss: 25.9071\n",
      "Epoch 1664/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.1868 - reconstruction_loss: 311.1868 - kl_loss: 25.8818\n",
      "Epoch 1665/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.1139 - reconstruction_loss: 311.1139 - kl_loss: 25.9354\n",
      "Epoch 1666/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.0669 - reconstruction_loss: 311.0669 - kl_loss: 25.9110\n",
      "Epoch 1667/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.1651 - reconstruction_loss: 311.1651 - kl_loss: 25.9403\n",
      "Epoch 1668/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.2053 - reconstruction_loss: 311.2053 - kl_loss: 25.9733\n",
      "Epoch 1669/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.0646 - reconstruction_loss: 311.0646 - kl_loss: 25.9574\n",
      "Epoch 1670/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.1902 - reconstruction_loss: 311.1902 - kl_loss: 25.9685\n",
      "Epoch 1671/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.1249 - reconstruction_loss: 311.1249 - kl_loss: 25.9965\n",
      "Epoch 1672/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.1220 - reconstruction_loss: 311.1220 - kl_loss: 25.9900\n",
      "Epoch 1673/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.1401 - reconstruction_loss: 311.1401 - kl_loss: 26.0051\n",
      "Epoch 1674/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.1861 - reconstruction_loss: 311.1861 - kl_loss: 26.0083\n",
      "Epoch 1675/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 311.2151 - reconstruction_loss: 311.2151 - kl_loss: 26.0456\n",
      "Epoch 1676/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.0920 - reconstruction_loss: 311.0920 - kl_loss: 26.0365\n",
      "Epoch 1677/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.1638 - reconstruction_loss: 311.1638 - kl_loss: 26.0025\n",
      "Epoch 1678/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.0728 - reconstruction_loss: 311.0728 - kl_loss: 26.0144\n",
      "Epoch 1679/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.0951 - reconstruction_loss: 311.0951 - kl_loss: 26.0562\n",
      "Epoch 1680/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.1088 - reconstruction_loss: 311.1088 - kl_loss: 26.0560\n",
      "Epoch 1681/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.1808 - reconstruction_loss: 311.1808 - kl_loss: 26.0875\n",
      "Epoch 1682/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.0428 - reconstruction_loss: 311.0428 - kl_loss: 26.0506\n",
      "Epoch 1683/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.1823 - reconstruction_loss: 311.1823 - kl_loss: 26.0880\n",
      "Epoch 1684/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.0229 - reconstruction_loss: 311.0229 - kl_loss: 26.0631\n",
      "Epoch 1685/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.0528 - reconstruction_loss: 311.0528 - kl_loss: 26.0738\n",
      "Epoch 1686/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.0993 - reconstruction_loss: 311.0993 - kl_loss: 26.0820\n",
      "Epoch 1687/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.0995 - reconstruction_loss: 311.0995 - kl_loss: 26.0982\n",
      "Epoch 1688/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.1052 - reconstruction_loss: 311.1052 - kl_loss: 26.1327\n",
      "Epoch 1689/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.1033 - reconstruction_loss: 311.1033 - kl_loss: 26.1194\n",
      "Epoch 1690/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.0754 - reconstruction_loss: 311.0754 - kl_loss: 26.1401\n",
      "Epoch 1691/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.9842 - reconstruction_loss: 310.9842 - kl_loss: 26.1326\n",
      "Epoch 1692/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.0363 - reconstruction_loss: 311.0363 - kl_loss: 26.1582\n",
      "Epoch 1693/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.0387 - reconstruction_loss: 311.0387 - kl_loss: 26.1389\n",
      "Epoch 1694/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.0711 - reconstruction_loss: 311.0711 - kl_loss: 26.2443\n",
      "Epoch 1695/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.9298 - reconstruction_loss: 310.9298 - kl_loss: 26.1842\n",
      "Epoch 1696/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.0337 - reconstruction_loss: 311.0337 - kl_loss: 26.1889\n",
      "Epoch 1697/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.9483 - reconstruction_loss: 310.9483 - kl_loss: 26.1875\n",
      "Epoch 1698/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.9558 - reconstruction_loss: 310.9558 - kl_loss: 26.2142\n",
      "Epoch 1699/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.0571 - reconstruction_loss: 311.0571 - kl_loss: 26.2385\n",
      "Epoch 1700/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.0191 - reconstruction_loss: 311.0191 - kl_loss: 26.2225\n",
      "Epoch 1701/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.9187 - reconstruction_loss: 310.9187 - kl_loss: 26.2368\n",
      "Epoch 1702/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.0462 - reconstruction_loss: 311.0462 - kl_loss: 26.2441\n",
      "Epoch 1703/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.9179 - reconstruction_loss: 310.9179 - kl_loss: 26.2574\n",
      "Epoch 1704/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.0365 - reconstruction_loss: 311.0365 - kl_loss: 26.2744\n",
      "Epoch 1705/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.8719 - reconstruction_loss: 310.8719 - kl_loss: 26.2532\n",
      "Epoch 1706/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.9414 - reconstruction_loss: 310.9414 - kl_loss: 26.2789\n",
      "Epoch 1707/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.9391 - reconstruction_loss: 310.9391 - kl_loss: 26.2640\n",
      "Epoch 1708/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.0042 - reconstruction_loss: 311.0042 - kl_loss: 26.2953\n",
      "Epoch 1709/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.9178 - reconstruction_loss: 310.9178 - kl_loss: 26.2932\n",
      "Epoch 1710/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.8632 - reconstruction_loss: 310.8632 - kl_loss: 26.3229\n",
      "Epoch 1711/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.9922 - reconstruction_loss: 310.9922 - kl_loss: 26.3060\n",
      "Epoch 1712/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.0050 - reconstruction_loss: 311.0050 - kl_loss: 26.2791\n",
      "Epoch 1713/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.0413 - reconstruction_loss: 311.0413 - kl_loss: 26.3075\n",
      "Epoch 1714/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.9866 - reconstruction_loss: 310.9866 - kl_loss: 26.3563\n",
      "Epoch 1715/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.9913 - reconstruction_loss: 310.9913 - kl_loss: 26.3447\n",
      "Epoch 1716/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.9816 - reconstruction_loss: 310.9816 - kl_loss: 26.3255\n",
      "Epoch 1717/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.0067 - reconstruction_loss: 311.0067 - kl_loss: 26.3939\n",
      "Epoch 1718/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.9413 - reconstruction_loss: 310.9413 - kl_loss: 26.3707\n",
      "Epoch 1719/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.0377 - reconstruction_loss: 311.0377 - kl_loss: 26.3871\n",
      "Epoch 1720/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.8879 - reconstruction_loss: 310.8879 - kl_loss: 26.3917\n",
      "Epoch 1721/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.8972 - reconstruction_loss: 310.8972 - kl_loss: 26.3958\n",
      "Epoch 1722/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.9629 - reconstruction_loss: 310.9629 - kl_loss: 26.4016\n",
      "Epoch 1723/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.9124 - reconstruction_loss: 310.9124 - kl_loss: 26.3953\n",
      "Epoch 1724/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.9435 - reconstruction_loss: 310.9435 - kl_loss: 26.4119\n",
      "Epoch 1725/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.9344 - reconstruction_loss: 310.9344 - kl_loss: 26.4141\n",
      "Epoch 1726/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.8979 - reconstruction_loss: 310.8979 - kl_loss: 26.4380\n",
      "Epoch 1727/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.8495 - reconstruction_loss: 310.8495 - kl_loss: 26.4508\n",
      "Epoch 1728/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.8026 - reconstruction_loss: 310.8026 - kl_loss: 26.4440\n",
      "Epoch 1729/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.8726 - reconstruction_loss: 310.8726 - kl_loss: 26.4921\n",
      "Epoch 1730/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.9195 - reconstruction_loss: 310.9195 - kl_loss: 26.4839\n",
      "Epoch 1731/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.9407 - reconstruction_loss: 310.9407 - kl_loss: 26.4831\n",
      "Epoch 1732/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.8320 - reconstruction_loss: 310.8320 - kl_loss: 26.4682\n",
      "Epoch 1733/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 310.9275 - reconstruction_loss: 310.9275 - kl_loss: 26.5388\n",
      "Epoch 1734/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 311.0023 - reconstruction_loss: 311.0023 - kl_loss: 26.5169\n",
      "Epoch 1735/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.9053 - reconstruction_loss: 310.9053 - kl_loss: 26.5341\n",
      "Epoch 1736/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.8830 - reconstruction_loss: 310.8830 - kl_loss: 26.5466\n",
      "Epoch 1737/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.9011 - reconstruction_loss: 310.9011 - kl_loss: 26.5521\n",
      "Epoch 1738/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.8113 - reconstruction_loss: 310.8113 - kl_loss: 26.5750\n",
      "Epoch 1739/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.8390 - reconstruction_loss: 310.8390 - kl_loss: 26.5644\n",
      "Epoch 1740/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.9066 - reconstruction_loss: 310.9066 - kl_loss: 26.6052\n",
      "Epoch 1741/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.7645 - reconstruction_loss: 310.7645 - kl_loss: 26.6211\n",
      "Epoch 1742/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.8891 - reconstruction_loss: 310.8891 - kl_loss: 26.6127\n",
      "Epoch 1743/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.8273 - reconstruction_loss: 310.8273 - kl_loss: 26.5688\n",
      "Epoch 1744/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.8381 - reconstruction_loss: 310.8381 - kl_loss: 26.6167\n",
      "Epoch 1745/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.8434 - reconstruction_loss: 310.8434 - kl_loss: 26.6131\n",
      "Epoch 1746/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.8132 - reconstruction_loss: 310.8132 - kl_loss: 26.5919\n",
      "Epoch 1747/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.7570 - reconstruction_loss: 310.7570 - kl_loss: 26.6067\n",
      "Epoch 1748/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.8371 - reconstruction_loss: 310.8371 - kl_loss: 26.6686\n",
      "Epoch 1749/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.9785 - reconstruction_loss: 310.9785 - kl_loss: 26.6600\n",
      "Epoch 1750/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.7999 - reconstruction_loss: 310.7999 - kl_loss: 26.6658\n",
      "Epoch 1751/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.9135 - reconstruction_loss: 310.9135 - kl_loss: 26.6380\n",
      "Epoch 1752/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.7550 - reconstruction_loss: 310.7550 - kl_loss: 26.6741\n",
      "Epoch 1753/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.7853 - reconstruction_loss: 310.7853 - kl_loss: 26.6639\n",
      "Epoch 1754/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.7957 - reconstruction_loss: 310.7957 - kl_loss: 26.7021\n",
      "Epoch 1755/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.7437 - reconstruction_loss: 310.7437 - kl_loss: 26.7010\n",
      "Epoch 1756/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.7577 - reconstruction_loss: 310.7577 - kl_loss: 26.7506\n",
      "Epoch 1757/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.8481 - reconstruction_loss: 310.8481 - kl_loss: 26.7452\n",
      "Epoch 1758/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.8154 - reconstruction_loss: 310.8154 - kl_loss: 26.7371\n",
      "Epoch 1759/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.7820 - reconstruction_loss: 310.7820 - kl_loss: 26.7369\n",
      "Epoch 1760/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6977 - reconstruction_loss: 310.6977 - kl_loss: 26.7322\n",
      "Epoch 1761/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.7706 - reconstruction_loss: 310.7706 - kl_loss: 26.7406\n",
      "Epoch 1762/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.7118 - reconstruction_loss: 310.7118 - kl_loss: 26.7270\n",
      "Epoch 1763/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.7403 - reconstruction_loss: 310.7403 - kl_loss: 26.7628\n",
      "Epoch 1764/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.7995 - reconstruction_loss: 310.7995 - kl_loss: 26.7417\n",
      "Epoch 1765/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.7889 - reconstruction_loss: 310.7889 - kl_loss: 26.8030\n",
      "Epoch 1766/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6465 - reconstruction_loss: 310.6465 - kl_loss: 26.7817\n",
      "Epoch 1767/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.7338 - reconstruction_loss: 310.7338 - kl_loss: 26.7836\n",
      "Epoch 1768/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6454 - reconstruction_loss: 310.6454 - kl_loss: 26.8130\n",
      "Epoch 1769/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.7280 - reconstruction_loss: 310.7280 - kl_loss: 26.8045\n",
      "Epoch 1770/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6947 - reconstruction_loss: 310.6947 - kl_loss: 26.8143\n",
      "Epoch 1771/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.8686 - reconstruction_loss: 310.8686 - kl_loss: 26.8907\n",
      "Epoch 1772/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6911 - reconstruction_loss: 310.6911 - kl_loss: 26.8144\n",
      "Epoch 1773/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.8376 - reconstruction_loss: 310.8376 - kl_loss: 26.8460\n",
      "Epoch 1774/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.5788 - reconstruction_loss: 310.5788 - kl_loss: 26.8549\n",
      "Epoch 1775/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6318 - reconstruction_loss: 310.6318 - kl_loss: 26.8882\n",
      "Epoch 1776/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.7252 - reconstruction_loss: 310.7252 - kl_loss: 26.9232\n",
      "Epoch 1777/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.7557 - reconstruction_loss: 310.7557 - kl_loss: 26.8991\n",
      "Epoch 1778/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6345 - reconstruction_loss: 310.6345 - kl_loss: 26.9004\n",
      "Epoch 1779/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.8692 - reconstruction_loss: 310.8692 - kl_loss: 26.8996\n",
      "Epoch 1780/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6193 - reconstruction_loss: 310.6193 - kl_loss: 26.8994\n",
      "Epoch 1781/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6864 - reconstruction_loss: 310.6864 - kl_loss: 26.9005\n",
      "Epoch 1782/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6818 - reconstruction_loss: 310.6818 - kl_loss: 26.8996\n",
      "Epoch 1783/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.7039 - reconstruction_loss: 310.7039 - kl_loss: 26.9360\n",
      "Epoch 1784/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6198 - reconstruction_loss: 310.6198 - kl_loss: 26.9460\n",
      "Epoch 1785/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6819 - reconstruction_loss: 310.6819 - kl_loss: 26.9736\n",
      "Epoch 1786/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6038 - reconstruction_loss: 310.6038 - kl_loss: 26.9468\n",
      "Epoch 1787/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6396 - reconstruction_loss: 310.6396 - kl_loss: 27.0005\n",
      "Epoch 1788/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.7370 - reconstruction_loss: 310.7370 - kl_loss: 27.0400\n",
      "Epoch 1789/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.7492 - reconstruction_loss: 310.7492 - kl_loss: 27.0143\n",
      "Epoch 1790/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6916 - reconstruction_loss: 310.6916 - kl_loss: 27.0161\n",
      "Epoch 1791/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6469 - reconstruction_loss: 310.6469 - kl_loss: 27.0223\n",
      "Epoch 1792/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6796 - reconstruction_loss: 310.6796 - kl_loss: 27.0524\n",
      "Epoch 1793/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6615 - reconstruction_loss: 310.6615 - kl_loss: 27.0517\n",
      "Epoch 1794/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.7354 - reconstruction_loss: 310.7354 - kl_loss: 27.0404\n",
      "Epoch 1795/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6844 - reconstruction_loss: 310.6844 - kl_loss: 27.0557\n",
      "Epoch 1796/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.7490 - reconstruction_loss: 310.7490 - kl_loss: 27.0654\n",
      "Epoch 1797/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6274 - reconstruction_loss: 310.6274 - kl_loss: 27.0531\n",
      "Epoch 1798/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6379 - reconstruction_loss: 310.6379 - kl_loss: 27.0880\n",
      "Epoch 1799/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6458 - reconstruction_loss: 310.6458 - kl_loss: 27.0894\n",
      "Epoch 1800/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6964 - reconstruction_loss: 310.6964 - kl_loss: 27.1293\n",
      "Epoch 1801/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6198 - reconstruction_loss: 310.6198 - kl_loss: 27.0982\n",
      "Epoch 1802/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6879 - reconstruction_loss: 310.6879 - kl_loss: 27.0774\n",
      "Epoch 1803/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.5341 - reconstruction_loss: 310.5341 - kl_loss: 27.1172\n",
      "Epoch 1804/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.5852 - reconstruction_loss: 310.5852 - kl_loss: 27.1799\n",
      "Epoch 1805/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.5902 - reconstruction_loss: 310.5902 - kl_loss: 27.1800\n",
      "Epoch 1806/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6242 - reconstruction_loss: 310.6242 - kl_loss: 27.1494\n",
      "Epoch 1807/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6081 - reconstruction_loss: 310.6081 - kl_loss: 27.1757\n",
      "Epoch 1808/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6478 - reconstruction_loss: 310.6478 - kl_loss: 27.1939\n",
      "Epoch 1809/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.8020 - reconstruction_loss: 310.8020 - kl_loss: 27.1891\n",
      "Epoch 1810/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.5078 - reconstruction_loss: 310.5078 - kl_loss: 27.1936\n",
      "Epoch 1811/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.5884 - reconstruction_loss: 310.5884 - kl_loss: 27.1779\n",
      "Epoch 1812/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.5855 - reconstruction_loss: 310.5855 - kl_loss: 27.2138\n",
      "Epoch 1813/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6735 - reconstruction_loss: 310.6735 - kl_loss: 27.1885\n",
      "Epoch 1814/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.5166 - reconstruction_loss: 310.5166 - kl_loss: 27.2002\n",
      "Epoch 1815/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.5691 - reconstruction_loss: 310.5691 - kl_loss: 27.2428\n",
      "Epoch 1816/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.5802 - reconstruction_loss: 310.5802 - kl_loss: 27.2067\n",
      "Epoch 1817/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.5929 - reconstruction_loss: 310.5929 - kl_loss: 27.2506\n",
      "Epoch 1818/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6163 - reconstruction_loss: 310.6163 - kl_loss: 27.2082\n",
      "Epoch 1819/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6824 - reconstruction_loss: 310.6824 - kl_loss: 27.2457\n",
      "Epoch 1820/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6121 - reconstruction_loss: 310.6121 - kl_loss: 27.2548\n",
      "Epoch 1821/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6166 - reconstruction_loss: 310.6166 - kl_loss: 27.2565\n",
      "Epoch 1822/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4965 - reconstruction_loss: 310.4965 - kl_loss: 27.2706\n",
      "Epoch 1823/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.5486 - reconstruction_loss: 310.5486 - kl_loss: 27.2637\n",
      "Epoch 1824/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.5245 - reconstruction_loss: 310.5245 - kl_loss: 27.2790\n",
      "Epoch 1825/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4064 - reconstruction_loss: 310.4064 - kl_loss: 27.3082\n",
      "Epoch 1826/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.5471 - reconstruction_loss: 310.5471 - kl_loss: 27.2835\n",
      "Epoch 1827/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.5881 - reconstruction_loss: 310.5881 - kl_loss: 27.2933\n",
      "Epoch 1828/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.5065 - reconstruction_loss: 310.5065 - kl_loss: 27.3300\n",
      "Epoch 1829/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.5210 - reconstruction_loss: 310.5210 - kl_loss: 27.3805\n",
      "Epoch 1830/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6431 - reconstruction_loss: 310.6431 - kl_loss: 27.3626\n",
      "Epoch 1831/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.6643 - reconstruction_loss: 310.6643 - kl_loss: 27.3555\n",
      "Epoch 1832/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.5323 - reconstruction_loss: 310.5323 - kl_loss: 27.3889\n",
      "Epoch 1833/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.5323 - reconstruction_loss: 310.5323 - kl_loss: 27.3671\n",
      "Epoch 1834/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4792 - reconstruction_loss: 310.4792 - kl_loss: 27.3788\n",
      "Epoch 1835/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4736 - reconstruction_loss: 310.4736 - kl_loss: 27.3636\n",
      "Epoch 1836/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.5167 - reconstruction_loss: 310.5167 - kl_loss: 27.4204\n",
      "Epoch 1837/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3908 - reconstruction_loss: 310.3908 - kl_loss: 27.4133\n",
      "Epoch 1838/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4359 - reconstruction_loss: 310.4359 - kl_loss: 27.3950\n",
      "Epoch 1839/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4577 - reconstruction_loss: 310.4577 - kl_loss: 27.4338\n",
      "Epoch 1840/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.5043 - reconstruction_loss: 310.5043 - kl_loss: 27.4156\n",
      "Epoch 1841/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.5806 - reconstruction_loss: 310.5806 - kl_loss: 27.4514\n",
      "Epoch 1842/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.5346 - reconstruction_loss: 310.5346 - kl_loss: 27.4555\n",
      "Epoch 1843/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4823 - reconstruction_loss: 310.4823 - kl_loss: 27.4766\n",
      "Epoch 1844/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.5221 - reconstruction_loss: 310.5221 - kl_loss: 27.4495\n",
      "Epoch 1845/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4314 - reconstruction_loss: 310.4314 - kl_loss: 27.4754\n",
      "Epoch 1846/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4844 - reconstruction_loss: 310.4844 - kl_loss: 27.4588\n",
      "Epoch 1847/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4380 - reconstruction_loss: 310.4380 - kl_loss: 27.4923\n",
      "Epoch 1848/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.5322 - reconstruction_loss: 310.5322 - kl_loss: 27.4940\n",
      "Epoch 1849/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4258 - reconstruction_loss: 310.4258 - kl_loss: 27.5465\n",
      "Epoch 1850/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4707 - reconstruction_loss: 310.4707 - kl_loss: 27.5327\n",
      "Epoch 1851/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4688 - reconstruction_loss: 310.4688 - kl_loss: 27.5736\n",
      "Epoch 1852/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4715 - reconstruction_loss: 310.4715 - kl_loss: 27.4851\n",
      "Epoch 1853/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4695 - reconstruction_loss: 310.4695 - kl_loss: 27.5437\n",
      "Epoch 1854/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4555 - reconstruction_loss: 310.4555 - kl_loss: 27.5554\n",
      "Epoch 1855/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4201 - reconstruction_loss: 310.4201 - kl_loss: 27.5597\n",
      "Epoch 1856/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4150 - reconstruction_loss: 310.4150 - kl_loss: 27.5776\n",
      "Epoch 1857/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.5195 - reconstruction_loss: 310.5195 - kl_loss: 27.5969\n",
      "Epoch 1858/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.5183 - reconstruction_loss: 310.5183 - kl_loss: 27.6127\n",
      "Epoch 1859/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4545 - reconstruction_loss: 310.4545 - kl_loss: 27.5534\n",
      "Epoch 1860/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.5397 - reconstruction_loss: 310.5397 - kl_loss: 27.5949\n",
      "Epoch 1861/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4994 - reconstruction_loss: 310.4994 - kl_loss: 27.5923\n",
      "Epoch 1862/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2783 - reconstruction_loss: 310.2783 - kl_loss: 27.6136\n",
      "Epoch 1863/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.5033 - reconstruction_loss: 310.5033 - kl_loss: 27.6664\n",
      "Epoch 1864/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3821 - reconstruction_loss: 310.3821 - kl_loss: 27.6328\n",
      "Epoch 1865/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3656 - reconstruction_loss: 310.3656 - kl_loss: 27.6439\n",
      "Epoch 1866/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3794 - reconstruction_loss: 310.3794 - kl_loss: 27.6179\n",
      "Epoch 1867/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4329 - reconstruction_loss: 310.4329 - kl_loss: 27.6570\n",
      "Epoch 1868/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4445 - reconstruction_loss: 310.4445 - kl_loss: 27.6520\n",
      "Epoch 1869/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.5955 - reconstruction_loss: 310.5955 - kl_loss: 27.6124\n",
      "Epoch 1870/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4607 - reconstruction_loss: 310.4607 - kl_loss: 27.6688\n",
      "Epoch 1871/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4565 - reconstruction_loss: 310.4565 - kl_loss: 27.6578\n",
      "Epoch 1872/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4336 - reconstruction_loss: 310.4336 - kl_loss: 27.6853\n",
      "Epoch 1873/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4790 - reconstruction_loss: 310.4790 - kl_loss: 27.7109\n",
      "Epoch 1874/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3194 - reconstruction_loss: 310.3194 - kl_loss: 27.6820\n",
      "Epoch 1875/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3734 - reconstruction_loss: 310.3734 - kl_loss: 27.7034\n",
      "Epoch 1876/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3310 - reconstruction_loss: 310.3310 - kl_loss: 27.7144\n",
      "Epoch 1877/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4784 - reconstruction_loss: 310.4784 - kl_loss: 27.6429\n",
      "Epoch 1878/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4240 - reconstruction_loss: 310.4240 - kl_loss: 27.7140\n",
      "Epoch 1879/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3031 - reconstruction_loss: 310.3031 - kl_loss: 27.7219\n",
      "Epoch 1880/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4337 - reconstruction_loss: 310.4337 - kl_loss: 27.7569\n",
      "Epoch 1881/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3970 - reconstruction_loss: 310.3970 - kl_loss: 27.7128\n",
      "Epoch 1882/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.5421 - reconstruction_loss: 310.5421 - kl_loss: 27.7347\n",
      "Epoch 1883/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4910 - reconstruction_loss: 310.4910 - kl_loss: 27.7467\n",
      "Epoch 1884/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3655 - reconstruction_loss: 310.3655 - kl_loss: 27.6836\n",
      "Epoch 1885/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3899 - reconstruction_loss: 310.3899 - kl_loss: 27.7527\n",
      "Epoch 1886/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4020 - reconstruction_loss: 310.4020 - kl_loss: 27.7284\n",
      "Epoch 1887/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2841 - reconstruction_loss: 310.2841 - kl_loss: 27.8044\n",
      "Epoch 1888/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2737 - reconstruction_loss: 310.2737 - kl_loss: 27.7574\n",
      "Epoch 1889/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3629 - reconstruction_loss: 310.3629 - kl_loss: 27.7985\n",
      "Epoch 1890/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4252 - reconstruction_loss: 310.4252 - kl_loss: 27.8059\n",
      "Epoch 1891/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3611 - reconstruction_loss: 310.3611 - kl_loss: 27.8002\n",
      "Epoch 1892/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3297 - reconstruction_loss: 310.3297 - kl_loss: 27.7785\n",
      "Epoch 1893/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3263 - reconstruction_loss: 310.3263 - kl_loss: 27.8339\n",
      "Epoch 1894/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3792 - reconstruction_loss: 310.3792 - kl_loss: 27.8203\n",
      "Epoch 1895/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2215 - reconstruction_loss: 310.2215 - kl_loss: 27.8228\n",
      "Epoch 1896/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4412 - reconstruction_loss: 310.4412 - kl_loss: 27.7744\n",
      "Epoch 1897/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3820 - reconstruction_loss: 310.3820 - kl_loss: 27.8369\n",
      "Epoch 1898/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2713 - reconstruction_loss: 310.2713 - kl_loss: 27.8371\n",
      "Epoch 1899/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4036 - reconstruction_loss: 310.4036 - kl_loss: 27.8432\n",
      "Epoch 1900/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3442 - reconstruction_loss: 310.3442 - kl_loss: 27.8296\n",
      "Epoch 1901/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4593 - reconstruction_loss: 310.4593 - kl_loss: 27.8572\n",
      "Epoch 1902/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2628 - reconstruction_loss: 310.2628 - kl_loss: 27.8782\n",
      "Epoch 1903/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2392 - reconstruction_loss: 310.2392 - kl_loss: 27.8596\n",
      "Epoch 1904/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3751 - reconstruction_loss: 310.3751 - kl_loss: 27.8885\n",
      "Epoch 1905/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3894 - reconstruction_loss: 310.3894 - kl_loss: 27.9041\n",
      "Epoch 1906/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3300 - reconstruction_loss: 310.3300 - kl_loss: 27.9090\n",
      "Epoch 1907/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3146 - reconstruction_loss: 310.3146 - kl_loss: 27.8827\n",
      "Epoch 1908/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2092 - reconstruction_loss: 310.2092 - kl_loss: 27.8714\n",
      "Epoch 1909/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2766 - reconstruction_loss: 310.2766 - kl_loss: 27.8640\n",
      "Epoch 1910/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3681 - reconstruction_loss: 310.3681 - kl_loss: 27.9349\n",
      "Epoch 1911/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4547 - reconstruction_loss: 310.4547 - kl_loss: 27.9232\n",
      "Epoch 1912/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1908 - reconstruction_loss: 310.1908 - kl_loss: 27.9204\n",
      "Epoch 1913/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2715 - reconstruction_loss: 310.2715 - kl_loss: 27.9398\n",
      "Epoch 1914/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2978 - reconstruction_loss: 310.2978 - kl_loss: 27.9374\n",
      "Epoch 1915/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3344 - reconstruction_loss: 310.3344 - kl_loss: 27.9190\n",
      "Epoch 1916/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3272 - reconstruction_loss: 310.3272 - kl_loss: 27.9829\n",
      "Epoch 1917/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3664 - reconstruction_loss: 310.3664 - kl_loss: 27.9606\n",
      "Epoch 1918/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2530 - reconstruction_loss: 310.2530 - kl_loss: 27.9506\n",
      "Epoch 1919/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.4034 - reconstruction_loss: 310.4034 - kl_loss: 27.9742\n",
      "Epoch 1920/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2408 - reconstruction_loss: 310.2408 - kl_loss: 27.9813\n",
      "Epoch 1921/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1746 - reconstruction_loss: 310.1746 - kl_loss: 27.9726\n",
      "Epoch 1922/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3473 - reconstruction_loss: 310.3473 - kl_loss: 28.0184\n",
      "Epoch 1923/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3298 - reconstruction_loss: 310.3298 - kl_loss: 27.9334\n",
      "Epoch 1924/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3044 - reconstruction_loss: 310.3044 - kl_loss: 28.0315\n",
      "Epoch 1925/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1641 - reconstruction_loss: 310.1641 - kl_loss: 28.0093\n",
      "Epoch 1926/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3078 - reconstruction_loss: 310.3078 - kl_loss: 28.0052\n",
      "Epoch 1927/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2903 - reconstruction_loss: 310.2903 - kl_loss: 27.9874\n",
      "Epoch 1928/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3374 - reconstruction_loss: 310.3374 - kl_loss: 28.0195\n",
      "Epoch 1929/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2692 - reconstruction_loss: 310.2692 - kl_loss: 28.0301\n",
      "Epoch 1930/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2135 - reconstruction_loss: 310.2135 - kl_loss: 27.9952\n",
      "Epoch 1931/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3555 - reconstruction_loss: 310.3555 - kl_loss: 28.0466\n",
      "Epoch 1932/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2706 - reconstruction_loss: 310.2706 - kl_loss: 28.0851\n",
      "Epoch 1933/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2306 - reconstruction_loss: 310.2306 - kl_loss: 28.0442\n",
      "Epoch 1934/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3267 - reconstruction_loss: 310.3267 - kl_loss: 28.0623\n",
      "Epoch 1935/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3064 - reconstruction_loss: 310.3064 - kl_loss: 28.0624\n",
      "Epoch 1936/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2215 - reconstruction_loss: 310.2215 - kl_loss: 28.0242\n",
      "Epoch 1937/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2862 - reconstruction_loss: 310.2862 - kl_loss: 28.0853\n",
      "Epoch 1938/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2636 - reconstruction_loss: 310.2636 - kl_loss: 28.0980\n",
      "Epoch 1939/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2696 - reconstruction_loss: 310.2696 - kl_loss: 28.0838\n",
      "Epoch 1940/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1978 - reconstruction_loss: 310.1978 - kl_loss: 28.0775\n",
      "Epoch 1941/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2891 - reconstruction_loss: 310.2891 - kl_loss: 28.1103\n",
      "Epoch 1942/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2782 - reconstruction_loss: 310.2782 - kl_loss: 28.0924\n",
      "Epoch 1943/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3524 - reconstruction_loss: 310.3524 - kl_loss: 28.1059\n",
      "Epoch 1944/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2048 - reconstruction_loss: 310.2048 - kl_loss: 28.0671\n",
      "Epoch 1945/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1778 - reconstruction_loss: 310.1778 - kl_loss: 28.1286\n",
      "Epoch 1946/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2407 - reconstruction_loss: 310.2407 - kl_loss: 28.1394\n",
      "Epoch 1947/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3011 - reconstruction_loss: 310.3011 - kl_loss: 28.1195\n",
      "Epoch 1948/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2462 - reconstruction_loss: 310.2462 - kl_loss: 28.1121\n",
      "Epoch 1949/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2497 - reconstruction_loss: 310.2497 - kl_loss: 28.1835\n",
      "Epoch 1950/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2241 - reconstruction_loss: 310.2241 - kl_loss: 28.1145\n",
      "Epoch 1951/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3125 - reconstruction_loss: 310.3125 - kl_loss: 28.1838\n",
      "Epoch 1952/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1500 - reconstruction_loss: 310.1500 - kl_loss: 28.1900\n",
      "Epoch 1953/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1358 - reconstruction_loss: 310.1358 - kl_loss: 28.1753\n",
      "Epoch 1954/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2847 - reconstruction_loss: 310.2847 - kl_loss: 28.2449\n",
      "Epoch 1955/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1784 - reconstruction_loss: 310.1784 - kl_loss: 28.2094\n",
      "Epoch 1956/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1346 - reconstruction_loss: 310.1346 - kl_loss: 28.1817\n",
      "Epoch 1957/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2397 - reconstruction_loss: 310.2397 - kl_loss: 28.1731\n",
      "Epoch 1958/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1765 - reconstruction_loss: 310.1765 - kl_loss: 28.1949\n",
      "Epoch 1959/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1209 - reconstruction_loss: 310.1209 - kl_loss: 28.2298\n",
      "Epoch 1960/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2198 - reconstruction_loss: 310.2198 - kl_loss: 28.2034\n",
      "Epoch 1961/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1363 - reconstruction_loss: 310.1363 - kl_loss: 28.2467\n",
      "Epoch 1962/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1863 - reconstruction_loss: 310.1863 - kl_loss: 28.2365\n",
      "Epoch 1963/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1427 - reconstruction_loss: 310.1427 - kl_loss: 28.2407\n",
      "Epoch 1964/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1490 - reconstruction_loss: 310.1490 - kl_loss: 28.2218\n",
      "Epoch 1965/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2733 - reconstruction_loss: 310.2733 - kl_loss: 28.2525\n",
      "Epoch 1966/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1885 - reconstruction_loss: 310.1885 - kl_loss: 28.2258\n",
      "Epoch 1967/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3077 - reconstruction_loss: 310.3077 - kl_loss: 28.2666\n",
      "Epoch 1968/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1059 - reconstruction_loss: 310.1059 - kl_loss: 28.2687\n",
      "Epoch 1969/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2212 - reconstruction_loss: 310.2212 - kl_loss: 28.2655\n",
      "Epoch 1970/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1532 - reconstruction_loss: 310.1532 - kl_loss: 28.3182\n",
      "Epoch 1971/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2289 - reconstruction_loss: 310.2289 - kl_loss: 28.2602\n",
      "Epoch 1972/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1614 - reconstruction_loss: 310.1614 - kl_loss: 28.2745\n",
      "Epoch 1973/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1814 - reconstruction_loss: 310.1814 - kl_loss: 28.2903\n",
      "Epoch 1974/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2037 - reconstruction_loss: 310.2037 - kl_loss: 28.3121\n",
      "Epoch 1975/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1900 - reconstruction_loss: 310.1900 - kl_loss: 28.3178\n",
      "Epoch 1976/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1688 - reconstruction_loss: 310.1688 - kl_loss: 28.3242\n",
      "Epoch 1977/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0831 - reconstruction_loss: 310.0831 - kl_loss: 28.2853\n",
      "Epoch 1978/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1155 - reconstruction_loss: 310.1155 - kl_loss: 28.3593\n",
      "Epoch 1979/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1642 - reconstruction_loss: 310.1642 - kl_loss: 28.3433\n",
      "Epoch 1980/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9829 - reconstruction_loss: 309.9829 - kl_loss: 28.3901\n",
      "Epoch 1981/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0684 - reconstruction_loss: 310.0684 - kl_loss: 28.3657\n",
      "Epoch 1982/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0156 - reconstruction_loss: 310.0156 - kl_loss: 28.3794\n",
      "Epoch 1983/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0202 - reconstruction_loss: 310.0202 - kl_loss: 28.3927\n",
      "Epoch 1984/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0592 - reconstruction_loss: 310.0592 - kl_loss: 28.4174\n",
      "Epoch 1985/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1111 - reconstruction_loss: 310.1111 - kl_loss: 28.4195\n",
      "Epoch 1986/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1818 - reconstruction_loss: 310.1818 - kl_loss: 28.4104\n",
      "Epoch 1987/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2282 - reconstruction_loss: 310.2282 - kl_loss: 28.4498\n",
      "Epoch 1988/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0664 - reconstruction_loss: 310.0664 - kl_loss: 28.3428\n",
      "Epoch 1989/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1483 - reconstruction_loss: 310.1483 - kl_loss: 28.4154\n",
      "Epoch 1990/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1272 - reconstruction_loss: 310.1272 - kl_loss: 28.4179\n",
      "Epoch 1991/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0497 - reconstruction_loss: 310.0497 - kl_loss: 28.4410\n",
      "Epoch 1992/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.3876 - reconstruction_loss: 310.3876 - kl_loss: 28.4315\n",
      "Epoch 1993/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2458 - reconstruction_loss: 310.2458 - kl_loss: 28.3924\n",
      "Epoch 1994/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1557 - reconstruction_loss: 310.1557 - kl_loss: 28.4198\n",
      "Epoch 1995/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0790 - reconstruction_loss: 310.0790 - kl_loss: 28.4423\n",
      "Epoch 1996/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0175 - reconstruction_loss: 310.0175 - kl_loss: 28.4769\n",
      "Epoch 1997/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0771 - reconstruction_loss: 310.0771 - kl_loss: 28.4342\n",
      "Epoch 1998/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1449 - reconstruction_loss: 310.1449 - kl_loss: 28.4813\n",
      "Epoch 1999/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1962 - reconstruction_loss: 310.1962 - kl_loss: 28.4566\n",
      "Epoch 2000/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.2031 - reconstruction_loss: 310.2031 - kl_loss: 28.4649\n",
      "Epoch 2001/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0969 - reconstruction_loss: 310.0969 - kl_loss: 28.4846\n",
      "Epoch 2002/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1067 - reconstruction_loss: 310.1067 - kl_loss: 28.4672\n",
      "Epoch 2003/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1874 - reconstruction_loss: 310.1874 - kl_loss: 28.4807\n",
      "Epoch 2004/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0794 - reconstruction_loss: 310.0794 - kl_loss: 28.4701\n",
      "Epoch 2005/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0596 - reconstruction_loss: 310.0596 - kl_loss: 28.5189\n",
      "Epoch 2006/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0804 - reconstruction_loss: 310.0804 - kl_loss: 28.4496\n",
      "Epoch 2007/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0588 - reconstruction_loss: 310.0588 - kl_loss: 28.5020\n",
      "Epoch 2008/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0986 - reconstruction_loss: 310.0986 - kl_loss: 28.5181\n",
      "Epoch 2009/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0963 - reconstruction_loss: 310.0963 - kl_loss: 28.5152\n",
      "Epoch 2010/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1291 - reconstruction_loss: 310.1291 - kl_loss: 28.4924\n",
      "Epoch 2011/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0642 - reconstruction_loss: 310.0642 - kl_loss: 28.4843\n",
      "Epoch 2012/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1776 - reconstruction_loss: 310.1776 - kl_loss: 28.5459\n",
      "Epoch 2013/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0883 - reconstruction_loss: 310.0883 - kl_loss: 28.5205\n",
      "Epoch 2014/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0299 - reconstruction_loss: 310.0299 - kl_loss: 28.5095\n",
      "Epoch 2015/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1706 - reconstruction_loss: 310.1706 - kl_loss: 28.5277\n",
      "Epoch 2016/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1135 - reconstruction_loss: 310.1135 - kl_loss: 28.5509\n",
      "Epoch 2017/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0935 - reconstruction_loss: 310.0935 - kl_loss: 28.5557\n",
      "Epoch 2018/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0329 - reconstruction_loss: 310.0329 - kl_loss: 28.5556\n",
      "Epoch 2019/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0803 - reconstruction_loss: 310.0803 - kl_loss: 28.5606\n",
      "Epoch 2020/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1023 - reconstruction_loss: 310.1023 - kl_loss: 28.5909\n",
      "Epoch 2021/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0464 - reconstruction_loss: 310.0464 - kl_loss: 28.5714\n",
      "Epoch 2022/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0440 - reconstruction_loss: 310.0440 - kl_loss: 28.6081\n",
      "Epoch 2023/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1186 - reconstruction_loss: 310.1186 - kl_loss: 28.5936\n",
      "Epoch 2024/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9147 - reconstruction_loss: 309.9147 - kl_loss: 28.6780\n",
      "Epoch 2025/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9928 - reconstruction_loss: 309.9928 - kl_loss: 28.6209\n",
      "Epoch 2026/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9330 - reconstruction_loss: 309.9330 - kl_loss: 28.6197\n",
      "Epoch 2027/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9658 - reconstruction_loss: 309.9658 - kl_loss: 28.6008\n",
      "Epoch 2028/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0639 - reconstruction_loss: 310.0639 - kl_loss: 28.6326\n",
      "Epoch 2029/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9343 - reconstruction_loss: 309.9343 - kl_loss: 28.6618\n",
      "Epoch 2030/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0264 - reconstruction_loss: 310.0264 - kl_loss: 28.6120\n",
      "Epoch 2031/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9969 - reconstruction_loss: 309.9969 - kl_loss: 28.6287\n",
      "Epoch 2032/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0445 - reconstruction_loss: 310.0445 - kl_loss: 28.6450\n",
      "Epoch 2033/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0417 - reconstruction_loss: 310.0417 - kl_loss: 28.7075\n",
      "Epoch 2034/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0865 - reconstruction_loss: 310.0865 - kl_loss: 28.6274\n",
      "Epoch 2035/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1319 - reconstruction_loss: 310.1319 - kl_loss: 28.6762\n",
      "Epoch 2036/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0917 - reconstruction_loss: 310.0917 - kl_loss: 28.6853\n",
      "Epoch 2037/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9762 - reconstruction_loss: 309.9762 - kl_loss: 28.6797\n",
      "Epoch 2038/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9194 - reconstruction_loss: 309.9194 - kl_loss: 28.6913\n",
      "Epoch 2039/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0068 - reconstruction_loss: 310.0068 - kl_loss: 28.7030\n",
      "Epoch 2040/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0218 - reconstruction_loss: 310.0218 - kl_loss: 28.7193\n",
      "Epoch 2041/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0521 - reconstruction_loss: 310.0521 - kl_loss: 28.7136\n",
      "Epoch 2042/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0934 - reconstruction_loss: 310.0934 - kl_loss: 28.7288\n",
      "Epoch 2043/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1447 - reconstruction_loss: 310.1447 - kl_loss: 28.7113\n",
      "Epoch 2044/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0523 - reconstruction_loss: 310.0523 - kl_loss: 28.7322\n",
      "Epoch 2045/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1346 - reconstruction_loss: 310.1346 - kl_loss: 28.7823\n",
      "Epoch 2046/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0202 - reconstruction_loss: 310.0202 - kl_loss: 28.7885\n",
      "Epoch 2047/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9919 - reconstruction_loss: 309.9919 - kl_loss: 28.7446\n",
      "Epoch 2048/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0161 - reconstruction_loss: 310.0161 - kl_loss: 28.7721\n",
      "Epoch 2049/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9054 - reconstruction_loss: 309.9054 - kl_loss: 28.7864\n",
      "Epoch 2050/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0318 - reconstruction_loss: 310.0318 - kl_loss: 28.7592\n",
      "Epoch 2051/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9170 - reconstruction_loss: 309.9170 - kl_loss: 28.7623\n",
      "Epoch 2052/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0351 - reconstruction_loss: 310.0351 - kl_loss: 28.7785\n",
      "Epoch 2053/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0020 - reconstruction_loss: 310.0020 - kl_loss: 28.7810\n",
      "Epoch 2054/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0459 - reconstruction_loss: 310.0459 - kl_loss: 28.7977\n",
      "Epoch 2055/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9223 - reconstruction_loss: 309.9223 - kl_loss: 28.7681\n",
      "Epoch 2056/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9213 - reconstruction_loss: 309.9213 - kl_loss: 28.7953\n",
      "Epoch 2057/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0483 - reconstruction_loss: 310.0483 - kl_loss: 28.7978\n",
      "Epoch 2058/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0862 - reconstruction_loss: 310.0862 - kl_loss: 28.7917\n",
      "Epoch 2059/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0931 - reconstruction_loss: 310.0931 - kl_loss: 28.8366\n",
      "Epoch 2060/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9624 - reconstruction_loss: 309.9624 - kl_loss: 28.7718\n",
      "Epoch 2061/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9670 - reconstruction_loss: 309.9670 - kl_loss: 28.8364\n",
      "Epoch 2062/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0189 - reconstruction_loss: 310.0189 - kl_loss: 28.8604\n",
      "Epoch 2063/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9423 - reconstruction_loss: 309.9423 - kl_loss: 28.8483\n",
      "Epoch 2064/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9839 - reconstruction_loss: 309.9839 - kl_loss: 28.8310\n",
      "Epoch 2065/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9917 - reconstruction_loss: 309.9917 - kl_loss: 28.8652\n",
      "Epoch 2066/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9191 - reconstruction_loss: 309.9191 - kl_loss: 28.8353\n",
      "Epoch 2067/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8703 - reconstruction_loss: 309.8703 - kl_loss: 28.8198\n",
      "Epoch 2068/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9685 - reconstruction_loss: 309.9685 - kl_loss: 28.8376\n",
      "Epoch 2069/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9665 - reconstruction_loss: 309.9665 - kl_loss: 28.8689\n",
      "Epoch 2070/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9362 - reconstruction_loss: 309.9362 - kl_loss: 28.8342\n",
      "Epoch 2071/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8650 - reconstruction_loss: 309.8650 - kl_loss: 28.9088\n",
      "Epoch 2072/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8959 - reconstruction_loss: 309.8959 - kl_loss: 28.8455\n",
      "Epoch 2073/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8949 - reconstruction_loss: 309.8949 - kl_loss: 28.8738\n",
      "Epoch 2074/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9200 - reconstruction_loss: 309.9200 - kl_loss: 28.8827\n",
      "Epoch 2075/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9476 - reconstruction_loss: 309.9476 - kl_loss: 28.9190\n",
      "Epoch 2076/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0103 - reconstruction_loss: 310.0103 - kl_loss: 28.9129\n",
      "Epoch 2077/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8740 - reconstruction_loss: 309.8740 - kl_loss: 28.9051\n",
      "Epoch 2078/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8675 - reconstruction_loss: 309.8675 - kl_loss: 28.8950\n",
      "Epoch 2079/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1024 - reconstruction_loss: 310.1024 - kl_loss: 28.9586\n",
      "Epoch 2080/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8860 - reconstruction_loss: 309.8860 - kl_loss: 28.9524\n",
      "Epoch 2081/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9047 - reconstruction_loss: 309.9047 - kl_loss: 28.9414\n",
      "Epoch 2082/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9189 - reconstruction_loss: 309.9189 - kl_loss: 28.9216\n",
      "Epoch 2083/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9906 - reconstruction_loss: 309.9906 - kl_loss: 28.9841\n",
      "Epoch 2084/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9291 - reconstruction_loss: 309.9291 - kl_loss: 28.9465\n",
      "Epoch 2085/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9459 - reconstruction_loss: 309.9459 - kl_loss: 28.9671\n",
      "Epoch 2086/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0236 - reconstruction_loss: 310.0236 - kl_loss: 28.9494\n",
      "Epoch 2087/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8598 - reconstruction_loss: 309.8598 - kl_loss: 28.9885\n",
      "Epoch 2088/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9867 - reconstruction_loss: 309.9867 - kl_loss: 28.9876\n",
      "Epoch 2089/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8689 - reconstruction_loss: 309.8689 - kl_loss: 29.0015\n",
      "Epoch 2090/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.1163 - reconstruction_loss: 310.1163 - kl_loss: 28.9862\n",
      "Epoch 2091/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9781 - reconstruction_loss: 309.9781 - kl_loss: 28.9781\n",
      "Epoch 2092/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9636 - reconstruction_loss: 309.9636 - kl_loss: 29.0365\n",
      "Epoch 2093/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8591 - reconstruction_loss: 309.8591 - kl_loss: 29.0034\n",
      "Epoch 2094/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9831 - reconstruction_loss: 309.9831 - kl_loss: 28.9890\n",
      "Epoch 2095/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9571 - reconstruction_loss: 309.9571 - kl_loss: 29.0391\n",
      "Epoch 2096/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9782 - reconstruction_loss: 309.9782 - kl_loss: 29.0019\n",
      "Epoch 2097/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9153 - reconstruction_loss: 309.9153 - kl_loss: 29.0401\n",
      "Epoch 2098/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8340 - reconstruction_loss: 309.8340 - kl_loss: 29.0280\n",
      "Epoch 2099/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8517 - reconstruction_loss: 309.8517 - kl_loss: 29.0125\n",
      "Epoch 2100/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9208 - reconstruction_loss: 309.9208 - kl_loss: 29.0660\n",
      "Epoch 2101/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9221 - reconstruction_loss: 309.9221 - kl_loss: 29.0403\n",
      "Epoch 2102/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9894 - reconstruction_loss: 309.9894 - kl_loss: 29.0284\n",
      "Epoch 2103/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8607 - reconstruction_loss: 309.8607 - kl_loss: 29.0534\n",
      "Epoch 2104/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9193 - reconstruction_loss: 309.9193 - kl_loss: 29.0776\n",
      "Epoch 2105/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8867 - reconstruction_loss: 309.8867 - kl_loss: 29.0785\n",
      "Epoch 2106/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9181 - reconstruction_loss: 309.9181 - kl_loss: 29.0835\n",
      "Epoch 2107/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8954 - reconstruction_loss: 309.8954 - kl_loss: 29.0746\n",
      "Epoch 2108/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8914 - reconstruction_loss: 309.8914 - kl_loss: 29.0931\n",
      "Epoch 2109/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7987 - reconstruction_loss: 309.7987 - kl_loss: 29.1380\n",
      "Epoch 2110/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9269 - reconstruction_loss: 309.9269 - kl_loss: 29.1424\n",
      "Epoch 2111/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9138 - reconstruction_loss: 309.9138 - kl_loss: 29.0725\n",
      "Epoch 2112/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8495 - reconstruction_loss: 309.8495 - kl_loss: 29.1465\n",
      "Epoch 2113/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8534 - reconstruction_loss: 309.8534 - kl_loss: 29.1673\n",
      "Epoch 2114/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0126 - reconstruction_loss: 310.0126 - kl_loss: 29.1193\n",
      "Epoch 2115/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8871 - reconstruction_loss: 309.8871 - kl_loss: 29.1057\n",
      "Epoch 2116/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8882 - reconstruction_loss: 309.8882 - kl_loss: 29.1447\n",
      "Epoch 2117/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8076 - reconstruction_loss: 309.8076 - kl_loss: 29.1365\n",
      "Epoch 2118/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9678 - reconstruction_loss: 309.9678 - kl_loss: 29.1480\n",
      "Epoch 2119/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8735 - reconstruction_loss: 309.8735 - kl_loss: 29.1482\n",
      "Epoch 2120/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9315 - reconstruction_loss: 309.9315 - kl_loss: 29.1234\n",
      "Epoch 2121/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9338 - reconstruction_loss: 309.9338 - kl_loss: 29.1570\n",
      "Epoch 2122/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8255 - reconstruction_loss: 309.8255 - kl_loss: 29.2323\n",
      "Epoch 2123/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8836 - reconstruction_loss: 309.8836 - kl_loss: 29.1954\n",
      "Epoch 2124/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7865 - reconstruction_loss: 309.7865 - kl_loss: 29.1760\n",
      "Epoch 2125/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0006 - reconstruction_loss: 310.0006 - kl_loss: 29.1904\n",
      "Epoch 2126/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9036 - reconstruction_loss: 309.9036 - kl_loss: 29.1870\n",
      "Epoch 2127/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8857 - reconstruction_loss: 309.8857 - kl_loss: 29.2472\n",
      "Epoch 2128/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9157 - reconstruction_loss: 309.9157 - kl_loss: 29.1832\n",
      "Epoch 2129/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8498 - reconstruction_loss: 309.8498 - kl_loss: 29.1956\n",
      "Epoch 2130/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8165 - reconstruction_loss: 309.8165 - kl_loss: 29.2650\n",
      "Epoch 2131/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 310.0165 - reconstruction_loss: 310.0165 - kl_loss: 29.2283\n",
      "Epoch 2132/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8140 - reconstruction_loss: 309.8140 - kl_loss: 29.2331\n",
      "Epoch 2133/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9005 - reconstruction_loss: 309.9005 - kl_loss: 29.2240\n",
      "Epoch 2134/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9248 - reconstruction_loss: 309.9248 - kl_loss: 29.1900\n",
      "Epoch 2135/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7909 - reconstruction_loss: 309.7909 - kl_loss: 29.2945\n",
      "Epoch 2136/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9903 - reconstruction_loss: 309.9903 - kl_loss: 29.2879\n",
      "Epoch 2137/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8141 - reconstruction_loss: 309.8141 - kl_loss: 29.2400\n",
      "Epoch 2138/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9324 - reconstruction_loss: 309.9324 - kl_loss: 29.2104\n",
      "Epoch 2139/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8283 - reconstruction_loss: 309.8283 - kl_loss: 29.2799\n",
      "Epoch 2140/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8748 - reconstruction_loss: 309.8748 - kl_loss: 29.2421\n",
      "Epoch 2141/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8184 - reconstruction_loss: 309.8184 - kl_loss: 29.2820\n",
      "Epoch 2142/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8879 - reconstruction_loss: 309.8879 - kl_loss: 29.2267\n",
      "Epoch 2143/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7622 - reconstruction_loss: 309.7622 - kl_loss: 29.2813\n",
      "Epoch 2144/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8822 - reconstruction_loss: 309.8822 - kl_loss: 29.3080\n",
      "Epoch 2145/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9159 - reconstruction_loss: 309.9159 - kl_loss: 29.2951\n",
      "Epoch 2146/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8714 - reconstruction_loss: 309.8714 - kl_loss: 29.2955\n",
      "Epoch 2147/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7687 - reconstruction_loss: 309.7687 - kl_loss: 29.3024\n",
      "Epoch 2148/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8301 - reconstruction_loss: 309.8301 - kl_loss: 29.3523\n",
      "Epoch 2149/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7594 - reconstruction_loss: 309.7594 - kl_loss: 29.3280\n",
      "Epoch 2150/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8319 - reconstruction_loss: 309.8319 - kl_loss: 29.3557\n",
      "Epoch 2151/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7302 - reconstruction_loss: 309.7302 - kl_loss: 29.3457\n",
      "Epoch 2152/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7570 - reconstruction_loss: 309.7570 - kl_loss: 29.3689\n",
      "Epoch 2153/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8323 - reconstruction_loss: 309.8323 - kl_loss: 29.3412\n",
      "Epoch 2154/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9276 - reconstruction_loss: 309.9276 - kl_loss: 29.3281\n",
      "Epoch 2155/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9012 - reconstruction_loss: 309.9012 - kl_loss: 29.3657\n",
      "Epoch 2156/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7330 - reconstruction_loss: 309.7330 - kl_loss: 29.3520\n",
      "Epoch 2157/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8424 - reconstruction_loss: 309.8424 - kl_loss: 29.3370\n",
      "Epoch 2158/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9011 - reconstruction_loss: 309.9011 - kl_loss: 29.3908\n",
      "Epoch 2159/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9677 - reconstruction_loss: 309.9677 - kl_loss: 29.3520\n",
      "Epoch 2160/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7404 - reconstruction_loss: 309.7404 - kl_loss: 29.3904\n",
      "Epoch 2161/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8016 - reconstruction_loss: 309.8016 - kl_loss: 29.3644\n",
      "Epoch 2162/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8058 - reconstruction_loss: 309.8058 - kl_loss: 29.3922\n",
      "Epoch 2163/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.9523 - reconstruction_loss: 309.9523 - kl_loss: 29.3987\n",
      "Epoch 2164/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7302 - reconstruction_loss: 309.7302 - kl_loss: 29.3703\n",
      "Epoch 2165/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8046 - reconstruction_loss: 309.8046 - kl_loss: 29.3801\n",
      "Epoch 2166/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8231 - reconstruction_loss: 309.8231 - kl_loss: 29.4155\n",
      "Epoch 2167/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6973 - reconstruction_loss: 309.6973 - kl_loss: 29.3972\n",
      "Epoch 2168/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8345 - reconstruction_loss: 309.8345 - kl_loss: 29.3670\n",
      "Epoch 2169/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7704 - reconstruction_loss: 309.7704 - kl_loss: 29.4448\n",
      "Epoch 2170/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8278 - reconstruction_loss: 309.8278 - kl_loss: 29.4137\n",
      "Epoch 2171/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7425 - reconstruction_loss: 309.7425 - kl_loss: 29.4656\n",
      "Epoch 2172/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7991 - reconstruction_loss: 309.7991 - kl_loss: 29.4644\n",
      "Epoch 2173/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8352 - reconstruction_loss: 309.8352 - kl_loss: 29.4362\n",
      "Epoch 2174/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7742 - reconstruction_loss: 309.7742 - kl_loss: 29.4256\n",
      "Epoch 2175/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8491 - reconstruction_loss: 309.8491 - kl_loss: 29.4152\n",
      "Epoch 2176/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8049 - reconstruction_loss: 309.8049 - kl_loss: 29.4694\n",
      "Epoch 2177/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7247 - reconstruction_loss: 309.7247 - kl_loss: 29.4570\n",
      "Epoch 2178/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8112 - reconstruction_loss: 309.8112 - kl_loss: 29.4574\n",
      "Epoch 2179/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7745 - reconstruction_loss: 309.7745 - kl_loss: 29.4612\n",
      "Epoch 2180/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8003 - reconstruction_loss: 309.8003 - kl_loss: 29.4595\n",
      "Epoch 2181/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7623 - reconstruction_loss: 309.7623 - kl_loss: 29.5085\n",
      "Epoch 2182/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6894 - reconstruction_loss: 309.6894 - kl_loss: 29.4728\n",
      "Epoch 2183/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7123 - reconstruction_loss: 309.7123 - kl_loss: 29.5163\n",
      "Epoch 2184/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8466 - reconstruction_loss: 309.8466 - kl_loss: 29.5280\n",
      "Epoch 2185/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7971 - reconstruction_loss: 309.7971 - kl_loss: 29.5175\n",
      "Epoch 2186/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8617 - reconstruction_loss: 309.8617 - kl_loss: 29.5112\n",
      "Epoch 2187/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7936 - reconstruction_loss: 309.7936 - kl_loss: 29.5264\n",
      "Epoch 2188/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7067 - reconstruction_loss: 309.7067 - kl_loss: 29.5312\n",
      "Epoch 2189/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8542 - reconstruction_loss: 309.8542 - kl_loss: 29.4978\n",
      "Epoch 2190/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6775 - reconstruction_loss: 309.6775 - kl_loss: 29.5169\n",
      "Epoch 2191/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8379 - reconstruction_loss: 309.8379 - kl_loss: 29.5195\n",
      "Epoch 2192/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7659 - reconstruction_loss: 309.7659 - kl_loss: 29.4927\n",
      "Epoch 2193/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8022 - reconstruction_loss: 309.8022 - kl_loss: 29.4874\n",
      "Epoch 2194/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6884 - reconstruction_loss: 309.6884 - kl_loss: 29.5240\n",
      "Epoch 2195/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6800 - reconstruction_loss: 309.6800 - kl_loss: 29.5583\n",
      "Epoch 2196/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8369 - reconstruction_loss: 309.8369 - kl_loss: 29.5414\n",
      "Epoch 2197/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7714 - reconstruction_loss: 309.7714 - kl_loss: 29.5519\n",
      "Epoch 2198/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6197 - reconstruction_loss: 309.6197 - kl_loss: 29.5477\n",
      "Epoch 2199/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6899 - reconstruction_loss: 309.6899 - kl_loss: 29.5404\n",
      "Epoch 2200/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7823 - reconstruction_loss: 309.7823 - kl_loss: 29.5312\n",
      "Epoch 2201/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7757 - reconstruction_loss: 309.7757 - kl_loss: 29.5960\n",
      "Epoch 2202/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7384 - reconstruction_loss: 309.7384 - kl_loss: 29.5922\n",
      "Epoch 2203/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8103 - reconstruction_loss: 309.8103 - kl_loss: 29.5666\n",
      "Epoch 2204/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7250 - reconstruction_loss: 309.7250 - kl_loss: 29.6173\n",
      "Epoch 2205/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8220 - reconstruction_loss: 309.8220 - kl_loss: 29.6380\n",
      "Epoch 2206/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7646 - reconstruction_loss: 309.7646 - kl_loss: 29.5850\n",
      "Epoch 2207/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5660 - reconstruction_loss: 309.5660 - kl_loss: 29.6708\n",
      "Epoch 2208/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5946 - reconstruction_loss: 309.5946 - kl_loss: 29.6160\n",
      "Epoch 2209/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7381 - reconstruction_loss: 309.7381 - kl_loss: 29.6126\n",
      "Epoch 2210/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7050 - reconstruction_loss: 309.7050 - kl_loss: 29.6146\n",
      "Epoch 2211/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6399 - reconstruction_loss: 309.6399 - kl_loss: 29.6247\n",
      "Epoch 2212/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7400 - reconstruction_loss: 309.7400 - kl_loss: 29.6515\n",
      "Epoch 2213/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7250 - reconstruction_loss: 309.7250 - kl_loss: 29.6002\n",
      "Epoch 2214/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7521 - reconstruction_loss: 309.7521 - kl_loss: 29.6383\n",
      "Epoch 2215/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7446 - reconstruction_loss: 309.7446 - kl_loss: 29.6650\n",
      "Epoch 2216/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7777 - reconstruction_loss: 309.7777 - kl_loss: 29.6394\n",
      "Epoch 2217/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7115 - reconstruction_loss: 309.7115 - kl_loss: 29.6581\n",
      "Epoch 2218/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7667 - reconstruction_loss: 309.7667 - kl_loss: 29.6767\n",
      "Epoch 2219/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5792 - reconstruction_loss: 309.5792 - kl_loss: 29.6980\n",
      "Epoch 2220/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8499 - reconstruction_loss: 309.8499 - kl_loss: 29.6639\n",
      "Epoch 2221/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6757 - reconstruction_loss: 309.6757 - kl_loss: 29.6946\n",
      "Epoch 2222/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7607 - reconstruction_loss: 309.7607 - kl_loss: 29.6915\n",
      "Epoch 2223/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6191 - reconstruction_loss: 309.6191 - kl_loss: 29.6935\n",
      "Epoch 2224/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7888 - reconstruction_loss: 309.7888 - kl_loss: 29.6958\n",
      "Epoch 2225/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6818 - reconstruction_loss: 309.6818 - kl_loss: 29.7294\n",
      "Epoch 2226/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6719 - reconstruction_loss: 309.6719 - kl_loss: 29.6669\n",
      "Epoch 2227/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7394 - reconstruction_loss: 309.7394 - kl_loss: 29.7325\n",
      "Epoch 2228/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6875 - reconstruction_loss: 309.6875 - kl_loss: 29.6604\n",
      "Epoch 2229/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6178 - reconstruction_loss: 309.6178 - kl_loss: 29.6738\n",
      "Epoch 2230/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6761 - reconstruction_loss: 309.6761 - kl_loss: 29.6973\n",
      "Epoch 2231/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7176 - reconstruction_loss: 309.7176 - kl_loss: 29.7543\n",
      "Epoch 2232/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.8212 - reconstruction_loss: 309.8212 - kl_loss: 29.7453\n",
      "Epoch 2233/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7362 - reconstruction_loss: 309.7362 - kl_loss: 29.7419\n",
      "Epoch 2234/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7648 - reconstruction_loss: 309.7648 - kl_loss: 29.7366\n",
      "Epoch 2235/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7083 - reconstruction_loss: 309.7083 - kl_loss: 29.7645\n",
      "Epoch 2236/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7232 - reconstruction_loss: 309.7232 - kl_loss: 29.7494\n",
      "Epoch 2237/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6603 - reconstruction_loss: 309.6603 - kl_loss: 29.7105\n",
      "Epoch 2238/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6703 - reconstruction_loss: 309.6703 - kl_loss: 29.7353\n",
      "Epoch 2239/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6151 - reconstruction_loss: 309.6151 - kl_loss: 29.7865\n",
      "Epoch 2240/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6717 - reconstruction_loss: 309.6717 - kl_loss: 29.7506\n",
      "Epoch 2241/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6753 - reconstruction_loss: 309.6753 - kl_loss: 29.7870\n",
      "Epoch 2242/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6219 - reconstruction_loss: 309.6219 - kl_loss: 29.7870\n",
      "Epoch 2243/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7412 - reconstruction_loss: 309.7412 - kl_loss: 29.7838\n",
      "Epoch 2244/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6135 - reconstruction_loss: 309.6135 - kl_loss: 29.7507\n",
      "Epoch 2245/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6579 - reconstruction_loss: 309.6579 - kl_loss: 29.8047\n",
      "Epoch 2246/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7303 - reconstruction_loss: 309.7303 - kl_loss: 29.7850\n",
      "Epoch 2247/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6332 - reconstruction_loss: 309.6332 - kl_loss: 29.7847\n",
      "Epoch 2248/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6932 - reconstruction_loss: 309.6932 - kl_loss: 29.8128\n",
      "Epoch 2249/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6392 - reconstruction_loss: 309.6392 - kl_loss: 29.8133\n",
      "Epoch 2250/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6118 - reconstruction_loss: 309.6118 - kl_loss: 29.8562\n",
      "Epoch 2251/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6284 - reconstruction_loss: 309.6284 - kl_loss: 29.7941\n",
      "Epoch 2252/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5306 - reconstruction_loss: 309.5306 - kl_loss: 29.8506\n",
      "Epoch 2253/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6612 - reconstruction_loss: 309.6612 - kl_loss: 29.8057\n",
      "Epoch 2254/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6459 - reconstruction_loss: 309.6459 - kl_loss: 29.8274\n",
      "Epoch 2255/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6241 - reconstruction_loss: 309.6241 - kl_loss: 29.7929\n",
      "Epoch 2256/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6659 - reconstruction_loss: 309.6659 - kl_loss: 29.8781\n",
      "Epoch 2257/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5949 - reconstruction_loss: 309.5949 - kl_loss: 29.9167\n",
      "Epoch 2258/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7565 - reconstruction_loss: 309.7565 - kl_loss: 29.8304\n",
      "Epoch 2259/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7356 - reconstruction_loss: 309.7356 - kl_loss: 29.8536\n",
      "Epoch 2260/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6939 - reconstruction_loss: 309.6939 - kl_loss: 29.8667\n",
      "Epoch 2261/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6466 - reconstruction_loss: 309.6466 - kl_loss: 29.8566\n",
      "Epoch 2262/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7005 - reconstruction_loss: 309.7005 - kl_loss: 29.8665\n",
      "Epoch 2263/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6570 - reconstruction_loss: 309.6570 - kl_loss: 29.8470\n",
      "Epoch 2264/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6669 - reconstruction_loss: 309.6669 - kl_loss: 29.9087\n",
      "Epoch 2265/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6194 - reconstruction_loss: 309.6194 - kl_loss: 29.9049\n",
      "Epoch 2266/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6319 - reconstruction_loss: 309.6319 - kl_loss: 29.8766\n",
      "Epoch 2267/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7270 - reconstruction_loss: 309.7270 - kl_loss: 29.9104\n",
      "Epoch 2268/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6300 - reconstruction_loss: 309.6300 - kl_loss: 29.9204\n",
      "Epoch 2269/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7436 - reconstruction_loss: 309.7436 - kl_loss: 29.9337\n",
      "Epoch 2270/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7321 - reconstruction_loss: 309.7321 - kl_loss: 29.8642\n",
      "Epoch 2271/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6902 - reconstruction_loss: 309.6902 - kl_loss: 29.9486\n",
      "Epoch 2272/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6308 - reconstruction_loss: 309.6308 - kl_loss: 29.9503\n",
      "Epoch 2273/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6830 - reconstruction_loss: 309.6830 - kl_loss: 29.9144\n",
      "Epoch 2274/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5634 - reconstruction_loss: 309.5634 - kl_loss: 29.9406\n",
      "Epoch 2275/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7229 - reconstruction_loss: 309.7229 - kl_loss: 29.8879\n",
      "Epoch 2276/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6622 - reconstruction_loss: 309.6622 - kl_loss: 29.9921\n",
      "Epoch 2277/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6454 - reconstruction_loss: 309.6454 - kl_loss: 29.9147\n",
      "Epoch 2278/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6270 - reconstruction_loss: 309.6270 - kl_loss: 29.9329\n",
      "Epoch 2279/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6892 - reconstruction_loss: 309.6892 - kl_loss: 29.9583\n",
      "Epoch 2280/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5369 - reconstruction_loss: 309.5369 - kl_loss: 29.9458\n",
      "Epoch 2281/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5922 - reconstruction_loss: 309.5922 - kl_loss: 29.9402\n",
      "Epoch 2282/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6657 - reconstruction_loss: 309.6657 - kl_loss: 29.9558\n",
      "Epoch 2283/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6159 - reconstruction_loss: 309.6159 - kl_loss: 29.9591\n",
      "Epoch 2284/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6465 - reconstruction_loss: 309.6465 - kl_loss: 30.0003\n",
      "Epoch 2285/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6377 - reconstruction_loss: 309.6377 - kl_loss: 30.0239\n",
      "Epoch 2286/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5603 - reconstruction_loss: 309.5603 - kl_loss: 30.0311\n",
      "Epoch 2287/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5883 - reconstruction_loss: 309.5883 - kl_loss: 29.9725\n",
      "Epoch 2288/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5463 - reconstruction_loss: 309.5463 - kl_loss: 29.9771\n",
      "Epoch 2289/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7327 - reconstruction_loss: 309.7327 - kl_loss: 29.9883\n",
      "Epoch 2290/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5506 - reconstruction_loss: 309.5506 - kl_loss: 30.0017\n",
      "Epoch 2291/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5660 - reconstruction_loss: 309.5660 - kl_loss: 30.0030\n",
      "Epoch 2292/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7228 - reconstruction_loss: 309.7228 - kl_loss: 30.0557\n",
      "Epoch 2293/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6861 - reconstruction_loss: 309.6861 - kl_loss: 30.0073\n",
      "Epoch 2294/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6552 - reconstruction_loss: 309.6552 - kl_loss: 30.0561\n",
      "Epoch 2295/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6146 - reconstruction_loss: 309.6146 - kl_loss: 30.0681\n",
      "Epoch 2296/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7359 - reconstruction_loss: 309.7359 - kl_loss: 30.0303\n",
      "Epoch 2297/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6559 - reconstruction_loss: 309.6559 - kl_loss: 30.0343\n",
      "Epoch 2298/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6206 - reconstruction_loss: 309.6206 - kl_loss: 30.0442\n",
      "Epoch 2299/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5659 - reconstruction_loss: 309.5659 - kl_loss: 30.0217\n",
      "Epoch 2300/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6780 - reconstruction_loss: 309.6780 - kl_loss: 30.0052\n",
      "Epoch 2301/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6090 - reconstruction_loss: 309.6090 - kl_loss: 30.0558\n",
      "Epoch 2302/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5223 - reconstruction_loss: 309.5223 - kl_loss: 30.0730\n",
      "Epoch 2303/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6836 - reconstruction_loss: 309.6836 - kl_loss: 30.0463\n",
      "Epoch 2304/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5577 - reconstruction_loss: 309.5577 - kl_loss: 30.0472\n",
      "Epoch 2305/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5953 - reconstruction_loss: 309.5953 - kl_loss: 30.0823\n",
      "Epoch 2306/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6076 - reconstruction_loss: 309.6076 - kl_loss: 30.1462\n",
      "Epoch 2307/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5712 - reconstruction_loss: 309.5712 - kl_loss: 30.1140\n",
      "Epoch 2308/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7747 - reconstruction_loss: 309.7747 - kl_loss: 30.0795\n",
      "Epoch 2309/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5555 - reconstruction_loss: 309.5555 - kl_loss: 30.0632\n",
      "Epoch 2310/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5719 - reconstruction_loss: 309.5719 - kl_loss: 30.0679\n",
      "Epoch 2311/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4828 - reconstruction_loss: 309.4828 - kl_loss: 30.1051\n",
      "Epoch 2312/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5342 - reconstruction_loss: 309.5342 - kl_loss: 30.0965\n",
      "Epoch 2313/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5887 - reconstruction_loss: 309.5887 - kl_loss: 30.1269\n",
      "Epoch 2314/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6374 - reconstruction_loss: 309.6374 - kl_loss: 30.0817\n",
      "Epoch 2315/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6939 - reconstruction_loss: 309.6939 - kl_loss: 30.0727\n",
      "Epoch 2316/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6024 - reconstruction_loss: 309.6024 - kl_loss: 30.1164\n",
      "Epoch 2317/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4990 - reconstruction_loss: 309.4990 - kl_loss: 30.1536\n",
      "Epoch 2318/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6421 - reconstruction_loss: 309.6421 - kl_loss: 30.1427\n",
      "Epoch 2319/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6006 - reconstruction_loss: 309.6006 - kl_loss: 30.1546\n",
      "Epoch 2320/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6051 - reconstruction_loss: 309.6051 - kl_loss: 30.1421\n",
      "Epoch 2321/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5796 - reconstruction_loss: 309.5796 - kl_loss: 30.1293\n",
      "Epoch 2322/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5194 - reconstruction_loss: 309.5194 - kl_loss: 30.1361\n",
      "Epoch 2323/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6248 - reconstruction_loss: 309.6248 - kl_loss: 30.1191\n",
      "Epoch 2324/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.7742 - reconstruction_loss: 309.7742 - kl_loss: 30.1683\n",
      "Epoch 2325/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4598 - reconstruction_loss: 309.4598 - kl_loss: 30.1719\n",
      "Epoch 2326/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5500 - reconstruction_loss: 309.5500 - kl_loss: 30.2210\n",
      "Epoch 2327/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5939 - reconstruction_loss: 309.5939 - kl_loss: 30.1811\n",
      "Epoch 2328/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5711 - reconstruction_loss: 309.5711 - kl_loss: 30.1811\n",
      "Epoch 2329/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4828 - reconstruction_loss: 309.4828 - kl_loss: 30.1833\n",
      "Epoch 2330/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5472 - reconstruction_loss: 309.5472 - kl_loss: 30.1631\n",
      "Epoch 2331/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5869 - reconstruction_loss: 309.5869 - kl_loss: 30.2210\n",
      "Epoch 2332/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4654 - reconstruction_loss: 309.4654 - kl_loss: 30.1556\n",
      "Epoch 2333/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4472 - reconstruction_loss: 309.4472 - kl_loss: 30.2050\n",
      "Epoch 2334/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4675 - reconstruction_loss: 309.4675 - kl_loss: 30.1784\n",
      "Epoch 2335/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5284 - reconstruction_loss: 309.5284 - kl_loss: 30.2003\n",
      "Epoch 2336/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5504 - reconstruction_loss: 309.5504 - kl_loss: 30.1620\n",
      "Epoch 2337/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5132 - reconstruction_loss: 309.5132 - kl_loss: 30.2062\n",
      "Epoch 2338/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5669 - reconstruction_loss: 309.5669 - kl_loss: 30.2148\n",
      "Epoch 2339/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4663 - reconstruction_loss: 309.4663 - kl_loss: 30.2198\n",
      "Epoch 2340/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5973 - reconstruction_loss: 309.5973 - kl_loss: 30.2147\n",
      "Epoch 2341/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6438 - reconstruction_loss: 309.6438 - kl_loss: 30.2245\n",
      "Epoch 2342/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5812 - reconstruction_loss: 309.5812 - kl_loss: 30.2675\n",
      "Epoch 2343/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6005 - reconstruction_loss: 309.6005 - kl_loss: 30.2124\n",
      "Epoch 2344/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5835 - reconstruction_loss: 309.5835 - kl_loss: 30.2176\n",
      "Epoch 2345/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5968 - reconstruction_loss: 309.5968 - kl_loss: 30.2441\n",
      "Epoch 2346/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5253 - reconstruction_loss: 309.5253 - kl_loss: 30.2835\n",
      "Epoch 2347/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5088 - reconstruction_loss: 309.5088 - kl_loss: 30.2262\n",
      "Epoch 2348/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4781 - reconstruction_loss: 309.4781 - kl_loss: 30.2911\n",
      "Epoch 2349/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4796 - reconstruction_loss: 309.4796 - kl_loss: 30.2218\n",
      "Epoch 2350/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5683 - reconstruction_loss: 309.5683 - kl_loss: 30.2748\n",
      "Epoch 2351/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5039 - reconstruction_loss: 309.5039 - kl_loss: 30.2751\n",
      "Epoch 2352/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6166 - reconstruction_loss: 309.6166 - kl_loss: 30.2849\n",
      "Epoch 2353/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5188 - reconstruction_loss: 309.5188 - kl_loss: 30.2428\n",
      "Epoch 2354/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5178 - reconstruction_loss: 309.5178 - kl_loss: 30.2537\n",
      "Epoch 2355/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5232 - reconstruction_loss: 309.5232 - kl_loss: 30.2578\n",
      "Epoch 2356/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6522 - reconstruction_loss: 309.6522 - kl_loss: 30.3109\n",
      "Epoch 2357/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4632 - reconstruction_loss: 309.4632 - kl_loss: 30.3072\n",
      "Epoch 2358/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5248 - reconstruction_loss: 309.5248 - kl_loss: 30.2987\n",
      "Epoch 2359/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5180 - reconstruction_loss: 309.5180 - kl_loss: 30.2687\n",
      "Epoch 2360/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4295 - reconstruction_loss: 309.4295 - kl_loss: 30.2904\n",
      "Epoch 2361/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4405 - reconstruction_loss: 309.4405 - kl_loss: 30.3335\n",
      "Epoch 2362/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4854 - reconstruction_loss: 309.4854 - kl_loss: 30.3174\n",
      "Epoch 2363/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4473 - reconstruction_loss: 309.4473 - kl_loss: 30.2816\n",
      "Epoch 2364/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4829 - reconstruction_loss: 309.4829 - kl_loss: 30.3051\n",
      "Epoch 2365/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6299 - reconstruction_loss: 309.6299 - kl_loss: 30.3123\n",
      "Epoch 2366/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6782 - reconstruction_loss: 309.6782 - kl_loss: 30.3009\n",
      "Epoch 2367/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4678 - reconstruction_loss: 309.4678 - kl_loss: 30.3161\n",
      "Epoch 2368/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4330 - reconstruction_loss: 309.4330 - kl_loss: 30.3105\n",
      "Epoch 2369/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4850 - reconstruction_loss: 309.4850 - kl_loss: 30.4153\n",
      "Epoch 2370/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6165 - reconstruction_loss: 309.6165 - kl_loss: 30.2751\n",
      "Epoch 2371/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6999 - reconstruction_loss: 309.6999 - kl_loss: 30.3402\n",
      "Epoch 2372/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5458 - reconstruction_loss: 309.5458 - kl_loss: 30.2991\n",
      "Epoch 2373/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5258 - reconstruction_loss: 309.5258 - kl_loss: 30.3572\n",
      "Epoch 2374/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4287 - reconstruction_loss: 309.4287 - kl_loss: 30.3403\n",
      "Epoch 2375/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5160 - reconstruction_loss: 309.5160 - kl_loss: 30.3967\n",
      "Epoch 2376/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4006 - reconstruction_loss: 309.4006 - kl_loss: 30.3148\n",
      "Epoch 2377/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4315 - reconstruction_loss: 309.4315 - kl_loss: 30.3417\n",
      "Epoch 2378/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5556 - reconstruction_loss: 309.5556 - kl_loss: 30.3517\n",
      "Epoch 2379/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5595 - reconstruction_loss: 309.5595 - kl_loss: 30.3845\n",
      "Epoch 2380/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5778 - reconstruction_loss: 309.5778 - kl_loss: 30.3335\n",
      "Epoch 2381/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5907 - reconstruction_loss: 309.5907 - kl_loss: 30.3590\n",
      "Epoch 2382/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5275 - reconstruction_loss: 309.5275 - kl_loss: 30.3837\n",
      "Epoch 2383/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5057 - reconstruction_loss: 309.5057 - kl_loss: 30.3916\n",
      "Epoch 2384/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5527 - reconstruction_loss: 309.5527 - kl_loss: 30.3588\n",
      "Epoch 2385/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5495 - reconstruction_loss: 309.5495 - kl_loss: 30.3953\n",
      "Epoch 2386/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6243 - reconstruction_loss: 309.6243 - kl_loss: 30.3683\n",
      "Epoch 2387/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6452 - reconstruction_loss: 309.6452 - kl_loss: 30.3561\n",
      "Epoch 2388/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5274 - reconstruction_loss: 309.5274 - kl_loss: 30.3599\n",
      "Epoch 2389/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5530 - reconstruction_loss: 309.5530 - kl_loss: 30.4079\n",
      "Epoch 2390/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5382 - reconstruction_loss: 309.5382 - kl_loss: 30.3525\n",
      "Epoch 2391/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5008 - reconstruction_loss: 309.5008 - kl_loss: 30.3909\n",
      "Epoch 2392/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4659 - reconstruction_loss: 309.4659 - kl_loss: 30.4371\n",
      "Epoch 2393/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5532 - reconstruction_loss: 309.5532 - kl_loss: 30.4206\n",
      "Epoch 2394/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5565 - reconstruction_loss: 309.5565 - kl_loss: 30.4220\n",
      "Epoch 2395/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5280 - reconstruction_loss: 309.5280 - kl_loss: 30.3963\n",
      "Epoch 2396/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4926 - reconstruction_loss: 309.4926 - kl_loss: 30.4491\n",
      "Epoch 2397/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4951 - reconstruction_loss: 309.4951 - kl_loss: 30.3842\n",
      "Epoch 2398/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4504 - reconstruction_loss: 309.4504 - kl_loss: 30.3774\n",
      "Epoch 2399/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4613 - reconstruction_loss: 309.4613 - kl_loss: 30.4883\n",
      "Epoch 2400/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3610 - reconstruction_loss: 309.3610 - kl_loss: 30.4380\n",
      "Epoch 2401/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5682 - reconstruction_loss: 309.5682 - kl_loss: 30.4027\n",
      "Epoch 2402/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4896 - reconstruction_loss: 309.4896 - kl_loss: 30.4210\n",
      "Epoch 2403/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4917 - reconstruction_loss: 309.4917 - kl_loss: 30.4185\n",
      "Epoch 2404/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4601 - reconstruction_loss: 309.4601 - kl_loss: 30.4628\n",
      "Epoch 2405/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5702 - reconstruction_loss: 309.5702 - kl_loss: 30.4586\n",
      "Epoch 2406/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3766 - reconstruction_loss: 309.3766 - kl_loss: 30.4494\n",
      "Epoch 2407/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4757 - reconstruction_loss: 309.4757 - kl_loss: 30.4084\n",
      "Epoch 2408/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3675 - reconstruction_loss: 309.3675 - kl_loss: 30.4971\n",
      "Epoch 2409/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5889 - reconstruction_loss: 309.5889 - kl_loss: 30.3894\n",
      "Epoch 2410/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4837 - reconstruction_loss: 309.4837 - kl_loss: 30.4956\n",
      "Epoch 2411/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4706 - reconstruction_loss: 309.4706 - kl_loss: 30.4953\n",
      "Epoch 2412/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4019 - reconstruction_loss: 309.4019 - kl_loss: 30.4540\n",
      "Epoch 2413/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5125 - reconstruction_loss: 309.5125 - kl_loss: 30.4898\n",
      "Epoch 2414/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6128 - reconstruction_loss: 309.6128 - kl_loss: 30.4876\n",
      "Epoch 2415/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.6215 - reconstruction_loss: 309.6215 - kl_loss: 30.4684\n",
      "Epoch 2416/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3852 - reconstruction_loss: 309.3852 - kl_loss: 30.5462\n",
      "Epoch 2417/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4338 - reconstruction_loss: 309.4338 - kl_loss: 30.5065\n",
      "Epoch 2418/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3046 - reconstruction_loss: 309.3046 - kl_loss: 30.5223\n",
      "Epoch 2419/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3665 - reconstruction_loss: 309.3665 - kl_loss: 30.5289\n",
      "Epoch 2420/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3783 - reconstruction_loss: 309.3783 - kl_loss: 30.5318\n",
      "Epoch 2421/3000\n",
      "166/166 [==============================] - 3s 20ms/step - loss: 309.4945 - reconstruction_loss: 309.4945 - kl_loss: 30.5249\n",
      "Epoch 2422/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4463 - reconstruction_loss: 309.4463 - kl_loss: 30.5353\n",
      "Epoch 2423/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3744 - reconstruction_loss: 309.3744 - kl_loss: 30.4712\n",
      "Epoch 2424/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5023 - reconstruction_loss: 309.5023 - kl_loss: 30.5580\n",
      "Epoch 2425/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4542 - reconstruction_loss: 309.4542 - kl_loss: 30.5349\n",
      "Epoch 2426/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4208 - reconstruction_loss: 309.4208 - kl_loss: 30.5467\n",
      "Epoch 2427/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4044 - reconstruction_loss: 309.4044 - kl_loss: 30.5654\n",
      "Epoch 2428/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4974 - reconstruction_loss: 309.4974 - kl_loss: 30.5145\n",
      "Epoch 2429/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4993 - reconstruction_loss: 309.4993 - kl_loss: 30.5329\n",
      "Epoch 2430/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5561 - reconstruction_loss: 309.5561 - kl_loss: 30.5395\n",
      "Epoch 2431/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5009 - reconstruction_loss: 309.5009 - kl_loss: 30.4970\n",
      "Epoch 2432/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4984 - reconstruction_loss: 309.4984 - kl_loss: 30.5088\n",
      "Epoch 2433/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4352 - reconstruction_loss: 309.4352 - kl_loss: 30.5611\n",
      "Epoch 2434/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4429 - reconstruction_loss: 309.4429 - kl_loss: 30.5399\n",
      "Epoch 2435/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5745 - reconstruction_loss: 309.5745 - kl_loss: 30.5666\n",
      "Epoch 2436/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3568 - reconstruction_loss: 309.3568 - kl_loss: 30.6387\n",
      "Epoch 2437/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4441 - reconstruction_loss: 309.4441 - kl_loss: 30.6518\n",
      "Epoch 2438/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4802 - reconstruction_loss: 309.4802 - kl_loss: 30.5817\n",
      "Epoch 2439/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3873 - reconstruction_loss: 309.3873 - kl_loss: 30.6340\n",
      "Epoch 2440/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4389 - reconstruction_loss: 309.4389 - kl_loss: 30.5627\n",
      "Epoch 2441/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4365 - reconstruction_loss: 309.4365 - kl_loss: 30.6135\n",
      "Epoch 2442/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3991 - reconstruction_loss: 309.3991 - kl_loss: 30.6034\n",
      "Epoch 2443/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4223 - reconstruction_loss: 309.4223 - kl_loss: 30.6007\n",
      "Epoch 2444/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4137 - reconstruction_loss: 309.4137 - kl_loss: 30.6587\n",
      "Epoch 2445/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4261 - reconstruction_loss: 309.4261 - kl_loss: 30.6219\n",
      "Epoch 2446/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4128 - reconstruction_loss: 309.4128 - kl_loss: 30.5983\n",
      "Epoch 2447/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3022 - reconstruction_loss: 309.3022 - kl_loss: 30.6340\n",
      "Epoch 2448/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3037 - reconstruction_loss: 309.3037 - kl_loss: 30.6405\n",
      "Epoch 2449/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3969 - reconstruction_loss: 309.3969 - kl_loss: 30.6264\n",
      "Epoch 2450/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3921 - reconstruction_loss: 309.3921 - kl_loss: 30.6575\n",
      "Epoch 2451/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4200 - reconstruction_loss: 309.4200 - kl_loss: 30.6194\n",
      "Epoch 2452/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3590 - reconstruction_loss: 309.3590 - kl_loss: 30.6390\n",
      "Epoch 2453/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4386 - reconstruction_loss: 309.4386 - kl_loss: 30.6218\n",
      "Epoch 2454/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3741 - reconstruction_loss: 309.3741 - kl_loss: 30.6288\n",
      "Epoch 2455/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4077 - reconstruction_loss: 309.4077 - kl_loss: 30.6262\n",
      "Epoch 2456/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3966 - reconstruction_loss: 309.3966 - kl_loss: 30.6206\n",
      "Epoch 2457/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3488 - reconstruction_loss: 309.3488 - kl_loss: 30.6300\n",
      "Epoch 2458/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3964 - reconstruction_loss: 309.3964 - kl_loss: 30.6966\n",
      "Epoch 2459/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3643 - reconstruction_loss: 309.3643 - kl_loss: 30.6653\n",
      "Epoch 2460/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3426 - reconstruction_loss: 309.3426 - kl_loss: 30.6706\n",
      "Epoch 2461/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4312 - reconstruction_loss: 309.4312 - kl_loss: 30.7111\n",
      "Epoch 2462/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4971 - reconstruction_loss: 309.4971 - kl_loss: 30.6619\n",
      "Epoch 2463/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4309 - reconstruction_loss: 309.4309 - kl_loss: 30.6837\n",
      "Epoch 2464/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3610 - reconstruction_loss: 309.3610 - kl_loss: 30.6926\n",
      "Epoch 2465/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3722 - reconstruction_loss: 309.3722 - kl_loss: 30.7132\n",
      "Epoch 2466/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3028 - reconstruction_loss: 309.3028 - kl_loss: 30.6978\n",
      "Epoch 2467/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5024 - reconstruction_loss: 309.5024 - kl_loss: 30.7277\n",
      "Epoch 2468/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3244 - reconstruction_loss: 309.3244 - kl_loss: 30.7106\n",
      "Epoch 2469/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3474 - reconstruction_loss: 309.3474 - kl_loss: 30.6770\n",
      "Epoch 2470/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3837 - reconstruction_loss: 309.3837 - kl_loss: 30.6955\n",
      "Epoch 2471/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3850 - reconstruction_loss: 309.3850 - kl_loss: 30.6638\n",
      "Epoch 2472/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4440 - reconstruction_loss: 309.4440 - kl_loss: 30.6963\n",
      "Epoch 2473/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3760 - reconstruction_loss: 309.3760 - kl_loss: 30.7091\n",
      "Epoch 2474/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3671 - reconstruction_loss: 309.3671 - kl_loss: 30.6997\n",
      "Epoch 2475/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3044 - reconstruction_loss: 309.3044 - kl_loss: 30.7218\n",
      "Epoch 2476/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2596 - reconstruction_loss: 309.2596 - kl_loss: 30.7224\n",
      "Epoch 2477/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2626 - reconstruction_loss: 309.2626 - kl_loss: 30.7346\n",
      "Epoch 2478/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3641 - reconstruction_loss: 309.3641 - kl_loss: 30.7331\n",
      "Epoch 2479/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3560 - reconstruction_loss: 309.3560 - kl_loss: 30.7738\n",
      "Epoch 2480/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3998 - reconstruction_loss: 309.3998 - kl_loss: 30.7161\n",
      "Epoch 2481/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4076 - reconstruction_loss: 309.4076 - kl_loss: 30.7859\n",
      "Epoch 2482/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3900 - reconstruction_loss: 309.3900 - kl_loss: 30.7430\n",
      "Epoch 2483/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3315 - reconstruction_loss: 309.3315 - kl_loss: 30.7688\n",
      "Epoch 2484/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3190 - reconstruction_loss: 309.3190 - kl_loss: 30.7354\n",
      "Epoch 2485/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3944 - reconstruction_loss: 309.3944 - kl_loss: 30.7677\n",
      "Epoch 2486/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3196 - reconstruction_loss: 309.3196 - kl_loss: 30.7620\n",
      "Epoch 2487/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4512 - reconstruction_loss: 309.4512 - kl_loss: 30.7537\n",
      "Epoch 2488/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.5113 - reconstruction_loss: 309.5113 - kl_loss: 30.7915\n",
      "Epoch 2489/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3435 - reconstruction_loss: 309.3435 - kl_loss: 30.8312\n",
      "Epoch 2490/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3613 - reconstruction_loss: 309.3613 - kl_loss: 30.7797\n",
      "Epoch 2491/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4060 - reconstruction_loss: 309.4060 - kl_loss: 30.8393\n",
      "Epoch 2492/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3970 - reconstruction_loss: 309.3970 - kl_loss: 30.7660\n",
      "Epoch 2493/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3405 - reconstruction_loss: 309.3405 - kl_loss: 30.7770\n",
      "Epoch 2494/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3027 - reconstruction_loss: 309.3027 - kl_loss: 30.7902\n",
      "Epoch 2495/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3450 - reconstruction_loss: 309.3450 - kl_loss: 30.8264\n",
      "Epoch 2496/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3884 - reconstruction_loss: 309.3884 - kl_loss: 30.7941\n",
      "Epoch 2497/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4939 - reconstruction_loss: 309.4939 - kl_loss: 30.8477\n",
      "Epoch 2498/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2928 - reconstruction_loss: 309.2928 - kl_loss: 30.8333\n",
      "Epoch 2499/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3142 - reconstruction_loss: 309.3142 - kl_loss: 30.7964\n",
      "Epoch 2500/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3329 - reconstruction_loss: 309.3329 - kl_loss: 30.8104\n",
      "Epoch 2501/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3429 - reconstruction_loss: 309.3429 - kl_loss: 30.8430\n",
      "Epoch 2502/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4208 - reconstruction_loss: 309.4208 - kl_loss: 30.8866\n",
      "Epoch 2503/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2996 - reconstruction_loss: 309.2996 - kl_loss: 30.8502\n",
      "Epoch 2504/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3692 - reconstruction_loss: 309.3692 - kl_loss: 30.8345\n",
      "Epoch 2505/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3224 - reconstruction_loss: 309.3224 - kl_loss: 30.8865\n",
      "Epoch 2506/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3382 - reconstruction_loss: 309.3382 - kl_loss: 30.9170\n",
      "Epoch 2507/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2860 - reconstruction_loss: 309.2860 - kl_loss: 30.8720\n",
      "Epoch 2508/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3985 - reconstruction_loss: 309.3985 - kl_loss: 30.8491\n",
      "Epoch 2509/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3560 - reconstruction_loss: 309.3560 - kl_loss: 30.8120\n",
      "Epoch 2510/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2448 - reconstruction_loss: 309.2448 - kl_loss: 30.8268\n",
      "Epoch 2511/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3022 - reconstruction_loss: 309.3022 - kl_loss: 30.8566\n",
      "Epoch 2512/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4193 - reconstruction_loss: 309.4193 - kl_loss: 30.8234\n",
      "Epoch 2513/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3669 - reconstruction_loss: 309.3669 - kl_loss: 30.8060\n",
      "Epoch 2514/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3328 - reconstruction_loss: 309.3328 - kl_loss: 30.9185\n",
      "Epoch 2515/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3242 - reconstruction_loss: 309.3242 - kl_loss: 30.8624\n",
      "Epoch 2516/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3612 - reconstruction_loss: 309.3612 - kl_loss: 30.9006\n",
      "Epoch 2517/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2474 - reconstruction_loss: 309.2474 - kl_loss: 30.8980\n",
      "Epoch 2518/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3274 - reconstruction_loss: 309.3274 - kl_loss: 30.8761\n",
      "Epoch 2519/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3940 - reconstruction_loss: 309.3940 - kl_loss: 30.8925\n",
      "Epoch 2520/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3133 - reconstruction_loss: 309.3133 - kl_loss: 30.8872\n",
      "Epoch 2521/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2782 - reconstruction_loss: 309.2782 - kl_loss: 30.9030\n",
      "Epoch 2522/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3991 - reconstruction_loss: 309.3991 - kl_loss: 30.8847\n",
      "Epoch 2523/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3253 - reconstruction_loss: 309.3253 - kl_loss: 30.8829\n",
      "Epoch 2524/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3134 - reconstruction_loss: 309.3134 - kl_loss: 30.9026\n",
      "Epoch 2525/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3267 - reconstruction_loss: 309.3267 - kl_loss: 30.8578\n",
      "Epoch 2526/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3774 - reconstruction_loss: 309.3774 - kl_loss: 30.9381\n",
      "Epoch 2527/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3799 - reconstruction_loss: 309.3799 - kl_loss: 30.8755\n",
      "Epoch 2528/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2573 - reconstruction_loss: 309.2573 - kl_loss: 30.9386\n",
      "Epoch 2529/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3679 - reconstruction_loss: 309.3679 - kl_loss: 30.8665\n",
      "Epoch 2530/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3081 - reconstruction_loss: 309.3081 - kl_loss: 30.8626\n",
      "Epoch 2531/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4458 - reconstruction_loss: 309.4458 - kl_loss: 30.8975\n",
      "Epoch 2532/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4354 - reconstruction_loss: 309.4354 - kl_loss: 30.8912\n",
      "Epoch 2533/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.4277 - reconstruction_loss: 309.4277 - kl_loss: 30.9582\n",
      "Epoch 2534/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2631 - reconstruction_loss: 309.2631 - kl_loss: 30.9049\n",
      "Epoch 2535/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3196 - reconstruction_loss: 309.3196 - kl_loss: 30.9806\n",
      "Epoch 2536/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2297 - reconstruction_loss: 309.2297 - kl_loss: 30.9432\n",
      "Epoch 2537/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2313 - reconstruction_loss: 309.2313 - kl_loss: 30.9472\n",
      "Epoch 2538/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3226 - reconstruction_loss: 309.3226 - kl_loss: 30.9357\n",
      "Epoch 2539/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3320 - reconstruction_loss: 309.3320 - kl_loss: 30.9252\n",
      "Epoch 2540/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2764 - reconstruction_loss: 309.2764 - kl_loss: 30.9761\n",
      "Epoch 2541/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3310 - reconstruction_loss: 309.3310 - kl_loss: 30.9267\n",
      "Epoch 2542/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2179 - reconstruction_loss: 309.2179 - kl_loss: 30.9647\n",
      "Epoch 2543/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2937 - reconstruction_loss: 309.2937 - kl_loss: 30.8859\n",
      "Epoch 2544/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3874 - reconstruction_loss: 309.3874 - kl_loss: 30.9217\n",
      "Epoch 2545/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3332 - reconstruction_loss: 309.3332 - kl_loss: 30.8947\n",
      "Epoch 2546/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3482 - reconstruction_loss: 309.3482 - kl_loss: 30.9020\n",
      "Epoch 2547/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2554 - reconstruction_loss: 309.2554 - kl_loss: 30.9931\n",
      "Epoch 2548/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2266 - reconstruction_loss: 309.2266 - kl_loss: 30.9806\n",
      "Epoch 2549/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2883 - reconstruction_loss: 309.2883 - kl_loss: 30.9630\n",
      "Epoch 2550/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1930 - reconstruction_loss: 309.1930 - kl_loss: 30.9493\n",
      "Epoch 2551/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2822 - reconstruction_loss: 309.2822 - kl_loss: 31.0070\n",
      "Epoch 2552/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2435 - reconstruction_loss: 309.2435 - kl_loss: 30.9644\n",
      "Epoch 2553/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2873 - reconstruction_loss: 309.2873 - kl_loss: 31.0043\n",
      "Epoch 2554/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2403 - reconstruction_loss: 309.2403 - kl_loss: 30.9811\n",
      "Epoch 2555/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3945 - reconstruction_loss: 309.3945 - kl_loss: 31.0077\n",
      "Epoch 2556/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2977 - reconstruction_loss: 309.2977 - kl_loss: 30.9514\n",
      "Epoch 2557/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1956 - reconstruction_loss: 309.1956 - kl_loss: 30.9360\n",
      "Epoch 2558/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2870 - reconstruction_loss: 309.2870 - kl_loss: 31.0383\n",
      "Epoch 2559/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2691 - reconstruction_loss: 309.2691 - kl_loss: 31.0115\n",
      "Epoch 2560/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3321 - reconstruction_loss: 309.3321 - kl_loss: 30.9905\n",
      "Epoch 2561/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2189 - reconstruction_loss: 309.2189 - kl_loss: 30.9531\n",
      "Epoch 2562/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2545 - reconstruction_loss: 309.2545 - kl_loss: 31.0552\n",
      "Epoch 2563/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2749 - reconstruction_loss: 309.2749 - kl_loss: 31.0215\n",
      "Epoch 2564/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2582 - reconstruction_loss: 309.2582 - kl_loss: 31.0483\n",
      "Epoch 2565/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2304 - reconstruction_loss: 309.2304 - kl_loss: 30.9923\n",
      "Epoch 2566/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2095 - reconstruction_loss: 309.2095 - kl_loss: 31.0145\n",
      "Epoch 2567/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2288 - reconstruction_loss: 309.2288 - kl_loss: 31.0335\n",
      "Epoch 2568/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2011 - reconstruction_loss: 309.2011 - kl_loss: 31.0052\n",
      "Epoch 2569/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2316 - reconstruction_loss: 309.2316 - kl_loss: 30.9966\n",
      "Epoch 2570/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2864 - reconstruction_loss: 309.2864 - kl_loss: 31.0797\n",
      "Epoch 2571/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3534 - reconstruction_loss: 309.3534 - kl_loss: 31.0021\n",
      "Epoch 2572/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1364 - reconstruction_loss: 309.1364 - kl_loss: 31.0523\n",
      "Epoch 2573/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2856 - reconstruction_loss: 309.2856 - kl_loss: 31.0079\n",
      "Epoch 2574/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3535 - reconstruction_loss: 309.3535 - kl_loss: 31.0247\n",
      "Epoch 2575/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3308 - reconstruction_loss: 309.3308 - kl_loss: 30.9944\n",
      "Epoch 2576/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2034 - reconstruction_loss: 309.2034 - kl_loss: 31.0078\n",
      "Epoch 2577/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2730 - reconstruction_loss: 309.2730 - kl_loss: 31.0291\n",
      "Epoch 2578/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2982 - reconstruction_loss: 309.2982 - kl_loss: 30.9792\n",
      "Epoch 2579/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3481 - reconstruction_loss: 309.3481 - kl_loss: 31.0708\n",
      "Epoch 2580/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1576 - reconstruction_loss: 309.1576 - kl_loss: 30.9934\n",
      "Epoch 2581/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2764 - reconstruction_loss: 309.2764 - kl_loss: 31.0552\n",
      "Epoch 2582/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1935 - reconstruction_loss: 309.1935 - kl_loss: 31.0601\n",
      "Epoch 2583/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1910 - reconstruction_loss: 309.1910 - kl_loss: 31.0894\n",
      "Epoch 2584/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2945 - reconstruction_loss: 309.2945 - kl_loss: 31.0975\n",
      "Epoch 2585/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1822 - reconstruction_loss: 309.1822 - kl_loss: 31.0694\n",
      "Epoch 2586/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1464 - reconstruction_loss: 309.1464 - kl_loss: 31.0810\n",
      "Epoch 2587/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2586 - reconstruction_loss: 309.2586 - kl_loss: 31.0542\n",
      "Epoch 2588/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1485 - reconstruction_loss: 309.1485 - kl_loss: 31.0707\n",
      "Epoch 2589/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1859 - reconstruction_loss: 309.1859 - kl_loss: 31.1022\n",
      "Epoch 2590/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3125 - reconstruction_loss: 309.3125 - kl_loss: 31.0635\n",
      "Epoch 2591/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3999 - reconstruction_loss: 309.3999 - kl_loss: 31.0404\n",
      "Epoch 2592/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2350 - reconstruction_loss: 309.2350 - kl_loss: 31.1164\n",
      "Epoch 2593/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2624 - reconstruction_loss: 309.2624 - kl_loss: 31.0567\n",
      "Epoch 2594/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2131 - reconstruction_loss: 309.2131 - kl_loss: 31.0412\n",
      "Epoch 2595/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3155 - reconstruction_loss: 309.3155 - kl_loss: 31.1066\n",
      "Epoch 2596/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2733 - reconstruction_loss: 309.2733 - kl_loss: 31.1032\n",
      "Epoch 2597/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2748 - reconstruction_loss: 309.2748 - kl_loss: 31.1133\n",
      "Epoch 2598/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1918 - reconstruction_loss: 309.1918 - kl_loss: 31.1184\n",
      "Epoch 2599/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2478 - reconstruction_loss: 309.2478 - kl_loss: 31.0780\n",
      "Epoch 2600/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2340 - reconstruction_loss: 309.2340 - kl_loss: 31.0919\n",
      "Epoch 2601/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2639 - reconstruction_loss: 309.2639 - kl_loss: 31.1427\n",
      "Epoch 2602/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1570 - reconstruction_loss: 309.1570 - kl_loss: 31.0835\n",
      "Epoch 2603/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2752 - reconstruction_loss: 309.2752 - kl_loss: 31.0554\n",
      "Epoch 2604/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2890 - reconstruction_loss: 309.2890 - kl_loss: 31.1213\n",
      "Epoch 2605/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2037 - reconstruction_loss: 309.2037 - kl_loss: 31.1675\n",
      "Epoch 2606/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2616 - reconstruction_loss: 309.2616 - kl_loss: 31.0982\n",
      "Epoch 2607/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1925 - reconstruction_loss: 309.1925 - kl_loss: 31.1558\n",
      "Epoch 2608/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1961 - reconstruction_loss: 309.1961 - kl_loss: 31.0665\n",
      "Epoch 2609/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2612 - reconstruction_loss: 309.2612 - kl_loss: 31.1113\n",
      "Epoch 2610/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2787 - reconstruction_loss: 309.2787 - kl_loss: 31.1367\n",
      "Epoch 2611/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1123 - reconstruction_loss: 309.1123 - kl_loss: 31.1461\n",
      "Epoch 2612/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3009 - reconstruction_loss: 309.3009 - kl_loss: 31.1427\n",
      "Epoch 2613/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1435 - reconstruction_loss: 309.1435 - kl_loss: 31.1252\n",
      "Epoch 2614/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2230 - reconstruction_loss: 309.2230 - kl_loss: 31.1537\n",
      "Epoch 2615/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1774 - reconstruction_loss: 309.1774 - kl_loss: 31.1129\n",
      "Epoch 2616/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3667 - reconstruction_loss: 309.3667 - kl_loss: 31.1378\n",
      "Epoch 2617/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1553 - reconstruction_loss: 309.1553 - kl_loss: 31.1121\n",
      "Epoch 2618/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2241 - reconstruction_loss: 309.2241 - kl_loss: 31.1818\n",
      "Epoch 2619/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2299 - reconstruction_loss: 309.2299 - kl_loss: 31.1453\n",
      "Epoch 2620/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3002 - reconstruction_loss: 309.3002 - kl_loss: 31.1592\n",
      "Epoch 2621/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1472 - reconstruction_loss: 309.1472 - kl_loss: 31.2107\n",
      "Epoch 2622/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1627 - reconstruction_loss: 309.1627 - kl_loss: 31.1994\n",
      "Epoch 2623/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1581 - reconstruction_loss: 309.1581 - kl_loss: 31.1785\n",
      "Epoch 2624/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1272 - reconstruction_loss: 309.1272 - kl_loss: 31.1541\n",
      "Epoch 2625/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1670 - reconstruction_loss: 309.1670 - kl_loss: 31.1939\n",
      "Epoch 2626/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3569 - reconstruction_loss: 309.3569 - kl_loss: 31.1614\n",
      "Epoch 2627/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2096 - reconstruction_loss: 309.2096 - kl_loss: 31.1967\n",
      "Epoch 2628/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1445 - reconstruction_loss: 309.1445 - kl_loss: 31.2481\n",
      "Epoch 2629/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1377 - reconstruction_loss: 309.1377 - kl_loss: 31.1916\n",
      "Epoch 2630/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1136 - reconstruction_loss: 309.1136 - kl_loss: 31.2217\n",
      "Epoch 2631/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0893 - reconstruction_loss: 309.0893 - kl_loss: 31.1777\n",
      "Epoch 2632/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1992 - reconstruction_loss: 309.1992 - kl_loss: 31.2088\n",
      "Epoch 2633/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1504 - reconstruction_loss: 309.1504 - kl_loss: 31.2138\n",
      "Epoch 2634/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0272 - reconstruction_loss: 309.0272 - kl_loss: 31.2544\n",
      "Epoch 2635/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1388 - reconstruction_loss: 309.1388 - kl_loss: 31.2030\n",
      "Epoch 2636/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2711 - reconstruction_loss: 309.2711 - kl_loss: 31.2656\n",
      "Epoch 2637/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2896 - reconstruction_loss: 309.2896 - kl_loss: 31.2455\n",
      "Epoch 2638/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2080 - reconstruction_loss: 309.2080 - kl_loss: 31.1922\n",
      "Epoch 2639/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1936 - reconstruction_loss: 309.1936 - kl_loss: 31.2400\n",
      "Epoch 2640/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1793 - reconstruction_loss: 309.1793 - kl_loss: 31.2551\n",
      "Epoch 2641/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0779 - reconstruction_loss: 309.0779 - kl_loss: 31.2119\n",
      "Epoch 2642/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9999 - reconstruction_loss: 308.9999 - kl_loss: 31.2870\n",
      "Epoch 2643/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1576 - reconstruction_loss: 309.1576 - kl_loss: 31.2495\n",
      "Epoch 2644/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1464 - reconstruction_loss: 309.1464 - kl_loss: 31.2371\n",
      "Epoch 2645/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2434 - reconstruction_loss: 309.2434 - kl_loss: 31.2381\n",
      "Epoch 2646/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2972 - reconstruction_loss: 309.2972 - kl_loss: 31.2459\n",
      "Epoch 2647/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1538 - reconstruction_loss: 309.1538 - kl_loss: 31.2679\n",
      "Epoch 2648/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2133 - reconstruction_loss: 309.2133 - kl_loss: 31.2418\n",
      "Epoch 2649/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2004 - reconstruction_loss: 309.2004 - kl_loss: 31.2400\n",
      "Epoch 2650/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2635 - reconstruction_loss: 309.2635 - kl_loss: 31.2721\n",
      "Epoch 2651/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1221 - reconstruction_loss: 309.1221 - kl_loss: 31.2637\n",
      "Epoch 2652/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1390 - reconstruction_loss: 309.1390 - kl_loss: 31.2494\n",
      "Epoch 2653/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1850 - reconstruction_loss: 309.1850 - kl_loss: 31.2282\n",
      "Epoch 2654/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1887 - reconstruction_loss: 309.1887 - kl_loss: 31.2580\n",
      "Epoch 2655/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1401 - reconstruction_loss: 309.1401 - kl_loss: 31.2752\n",
      "Epoch 2656/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1000 - reconstruction_loss: 309.1000 - kl_loss: 31.3292\n",
      "Epoch 2657/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2293 - reconstruction_loss: 309.2293 - kl_loss: 31.2765\n",
      "Epoch 2658/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.3659 - reconstruction_loss: 309.3659 - kl_loss: 31.2422\n",
      "Epoch 2659/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0947 - reconstruction_loss: 309.0947 - kl_loss: 31.3029\n",
      "Epoch 2660/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1403 - reconstruction_loss: 309.1403 - kl_loss: 31.2740\n",
      "Epoch 2661/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2007 - reconstruction_loss: 309.2007 - kl_loss: 31.2690\n",
      "Epoch 2662/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1179 - reconstruction_loss: 309.1179 - kl_loss: 31.2651\n",
      "Epoch 2663/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1973 - reconstruction_loss: 309.1973 - kl_loss: 31.3078\n",
      "Epoch 2664/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0458 - reconstruction_loss: 309.0458 - kl_loss: 31.2383\n",
      "Epoch 2665/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1698 - reconstruction_loss: 309.1698 - kl_loss: 31.3537\n",
      "Epoch 2666/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0379 - reconstruction_loss: 309.0379 - kl_loss: 31.2866\n",
      "Epoch 2667/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1211 - reconstruction_loss: 309.1211 - kl_loss: 31.3046\n",
      "Epoch 2668/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0187 - reconstruction_loss: 309.0187 - kl_loss: 31.3106\n",
      "Epoch 2669/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1721 - reconstruction_loss: 309.1721 - kl_loss: 31.3089\n",
      "Epoch 2670/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1747 - reconstruction_loss: 309.1747 - kl_loss: 31.3283\n",
      "Epoch 2671/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0988 - reconstruction_loss: 309.0988 - kl_loss: 31.3168\n",
      "Epoch 2672/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2418 - reconstruction_loss: 309.2418 - kl_loss: 31.2805\n",
      "Epoch 2673/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1734 - reconstruction_loss: 309.1734 - kl_loss: 31.3287\n",
      "Epoch 2674/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2067 - reconstruction_loss: 309.2067 - kl_loss: 31.3304\n",
      "Epoch 2675/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1026 - reconstruction_loss: 309.1026 - kl_loss: 31.3588\n",
      "Epoch 2676/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1354 - reconstruction_loss: 309.1354 - kl_loss: 31.3292\n",
      "Epoch 2677/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1314 - reconstruction_loss: 309.1314 - kl_loss: 31.2897\n",
      "Epoch 2678/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1422 - reconstruction_loss: 309.1422 - kl_loss: 31.3664\n",
      "Epoch 2679/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1971 - reconstruction_loss: 309.1971 - kl_loss: 31.2725\n",
      "Epoch 2680/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0440 - reconstruction_loss: 309.0440 - kl_loss: 31.3767\n",
      "Epoch 2681/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1887 - reconstruction_loss: 309.1887 - kl_loss: 31.3445\n",
      "Epoch 2682/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9965 - reconstruction_loss: 308.9965 - kl_loss: 31.3845\n",
      "Epoch 2683/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1376 - reconstruction_loss: 309.1376 - kl_loss: 31.3440\n",
      "Epoch 2684/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2325 - reconstruction_loss: 309.2325 - kl_loss: 31.3330\n",
      "Epoch 2685/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1811 - reconstruction_loss: 309.1811 - kl_loss: 31.3475\n",
      "Epoch 2686/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1214 - reconstruction_loss: 309.1214 - kl_loss: 31.3577\n",
      "Epoch 2687/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0808 - reconstruction_loss: 309.0808 - kl_loss: 31.3685\n",
      "Epoch 2688/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2710 - reconstruction_loss: 309.2710 - kl_loss: 31.4117\n",
      "Epoch 2689/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1357 - reconstruction_loss: 309.1357 - kl_loss: 31.3871\n",
      "Epoch 2690/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1132 - reconstruction_loss: 309.1132 - kl_loss: 31.4147\n",
      "Epoch 2691/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0943 - reconstruction_loss: 309.0943 - kl_loss: 31.3651\n",
      "Epoch 2692/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1954 - reconstruction_loss: 309.1954 - kl_loss: 31.3819\n",
      "Epoch 2693/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1712 - reconstruction_loss: 309.1712 - kl_loss: 31.3773\n",
      "Epoch 2694/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0447 - reconstruction_loss: 309.0447 - kl_loss: 31.4144\n",
      "Epoch 2695/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0538 - reconstruction_loss: 309.0538 - kl_loss: 31.4231\n",
      "Epoch 2696/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1846 - reconstruction_loss: 309.1846 - kl_loss: 31.4113\n",
      "Epoch 2697/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0022 - reconstruction_loss: 309.0022 - kl_loss: 31.4337\n",
      "Epoch 2698/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1324 - reconstruction_loss: 309.1324 - kl_loss: 31.3905\n",
      "Epoch 2699/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0774 - reconstruction_loss: 309.0774 - kl_loss: 31.3868\n",
      "Epoch 2700/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0910 - reconstruction_loss: 309.0910 - kl_loss: 31.3879\n",
      "Epoch 2701/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0378 - reconstruction_loss: 309.0378 - kl_loss: 31.4471\n",
      "Epoch 2702/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0960 - reconstruction_loss: 309.0960 - kl_loss: 31.4248\n",
      "Epoch 2703/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1624 - reconstruction_loss: 309.1624 - kl_loss: 31.4268\n",
      "Epoch 2704/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0591 - reconstruction_loss: 309.0591 - kl_loss: 31.4100\n",
      "Epoch 2705/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0119 - reconstruction_loss: 309.0119 - kl_loss: 31.4251\n",
      "Epoch 2706/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2109 - reconstruction_loss: 309.2109 - kl_loss: 31.4267\n",
      "Epoch 2707/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1761 - reconstruction_loss: 309.1761 - kl_loss: 31.4344\n",
      "Epoch 2708/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1197 - reconstruction_loss: 309.1197 - kl_loss: 31.4917\n",
      "Epoch 2709/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1488 - reconstruction_loss: 309.1488 - kl_loss: 31.4239\n",
      "Epoch 2710/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1755 - reconstruction_loss: 309.1755 - kl_loss: 31.4521\n",
      "Epoch 2711/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2438 - reconstruction_loss: 309.2438 - kl_loss: 31.4257\n",
      "Epoch 2712/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1574 - reconstruction_loss: 309.1574 - kl_loss: 31.3876\n",
      "Epoch 2713/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1864 - reconstruction_loss: 309.1864 - kl_loss: 31.4553\n",
      "Epoch 2714/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1292 - reconstruction_loss: 309.1292 - kl_loss: 31.5018\n",
      "Epoch 2715/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1697 - reconstruction_loss: 309.1697 - kl_loss: 31.3851\n",
      "Epoch 2716/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1396 - reconstruction_loss: 309.1396 - kl_loss: 31.4767\n",
      "Epoch 2717/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1680 - reconstruction_loss: 309.1680 - kl_loss: 31.4538\n",
      "Epoch 2718/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9926 - reconstruction_loss: 308.9926 - kl_loss: 31.5012\n",
      "Epoch 2719/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1587 - reconstruction_loss: 309.1587 - kl_loss: 31.4655\n",
      "Epoch 2720/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0423 - reconstruction_loss: 309.0423 - kl_loss: 31.4999\n",
      "Epoch 2721/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2777 - reconstruction_loss: 309.2777 - kl_loss: 31.4517\n",
      "Epoch 2722/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0994 - reconstruction_loss: 309.0994 - kl_loss: 31.4884\n",
      "Epoch 2723/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1204 - reconstruction_loss: 309.1204 - kl_loss: 31.4689\n",
      "Epoch 2724/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1385 - reconstruction_loss: 309.1385 - kl_loss: 31.4826\n",
      "Epoch 2725/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1094 - reconstruction_loss: 309.1094 - kl_loss: 31.4909\n",
      "Epoch 2726/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0867 - reconstruction_loss: 309.0867 - kl_loss: 31.4612\n",
      "Epoch 2727/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0136 - reconstruction_loss: 309.0136 - kl_loss: 31.4903\n",
      "Epoch 2728/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1424 - reconstruction_loss: 309.1424 - kl_loss: 31.4875\n",
      "Epoch 2729/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1743 - reconstruction_loss: 309.1743 - kl_loss: 31.5534\n",
      "Epoch 2730/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1047 - reconstruction_loss: 309.1047 - kl_loss: 31.4968\n",
      "Epoch 2731/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1657 - reconstruction_loss: 309.1657 - kl_loss: 31.4759\n",
      "Epoch 2732/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0118 - reconstruction_loss: 309.0118 - kl_loss: 31.5167\n",
      "Epoch 2733/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1822 - reconstruction_loss: 309.1822 - kl_loss: 31.5036\n",
      "Epoch 2734/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1640 - reconstruction_loss: 309.1640 - kl_loss: 31.5256\n",
      "Epoch 2735/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1409 - reconstruction_loss: 309.1409 - kl_loss: 31.4631\n",
      "Epoch 2736/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1188 - reconstruction_loss: 309.1188 - kl_loss: 31.5200\n",
      "Epoch 2737/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0784 - reconstruction_loss: 309.0784 - kl_loss: 31.5039\n",
      "Epoch 2738/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1229 - reconstruction_loss: 309.1229 - kl_loss: 31.5118\n",
      "Epoch 2739/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1930 - reconstruction_loss: 309.1930 - kl_loss: 31.5039\n",
      "Epoch 2740/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1710 - reconstruction_loss: 309.1710 - kl_loss: 31.5530\n",
      "Epoch 2741/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1190 - reconstruction_loss: 309.1190 - kl_loss: 31.5518\n",
      "Epoch 2742/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1501 - reconstruction_loss: 309.1501 - kl_loss: 31.5265\n",
      "Epoch 2743/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0961 - reconstruction_loss: 309.0961 - kl_loss: 31.5043\n",
      "Epoch 2744/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.2072 - reconstruction_loss: 309.2072 - kl_loss: 31.5652\n",
      "Epoch 2745/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1303 - reconstruction_loss: 309.1303 - kl_loss: 31.6201\n",
      "Epoch 2746/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0401 - reconstruction_loss: 309.0401 - kl_loss: 31.5021\n",
      "Epoch 2747/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1276 - reconstruction_loss: 309.1276 - kl_loss: 31.5380\n",
      "Epoch 2748/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0872 - reconstruction_loss: 309.0872 - kl_loss: 31.5668\n",
      "Epoch 2749/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0402 - reconstruction_loss: 309.0402 - kl_loss: 31.5107\n",
      "Epoch 2750/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9541 - reconstruction_loss: 308.9541 - kl_loss: 31.5809\n",
      "Epoch 2751/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0435 - reconstruction_loss: 309.0435 - kl_loss: 31.5674\n",
      "Epoch 2752/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9700 - reconstruction_loss: 308.9700 - kl_loss: 31.5328\n",
      "Epoch 2753/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0808 - reconstruction_loss: 309.0808 - kl_loss: 31.5570\n",
      "Epoch 2754/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0386 - reconstruction_loss: 309.0386 - kl_loss: 31.5488\n",
      "Epoch 2755/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0655 - reconstruction_loss: 309.0655 - kl_loss: 31.5468\n",
      "Epoch 2756/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1740 - reconstruction_loss: 309.1740 - kl_loss: 31.5575\n",
      "Epoch 2757/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0049 - reconstruction_loss: 309.0049 - kl_loss: 31.5283\n",
      "Epoch 2758/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0589 - reconstruction_loss: 309.0589 - kl_loss: 31.5673\n",
      "Epoch 2759/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1009 - reconstruction_loss: 309.1009 - kl_loss: 31.5737\n",
      "Epoch 2760/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0827 - reconstruction_loss: 309.0827 - kl_loss: 31.5904\n",
      "Epoch 2761/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0560 - reconstruction_loss: 309.0560 - kl_loss: 31.5335\n",
      "Epoch 2762/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9612 - reconstruction_loss: 308.9612 - kl_loss: 31.5793\n",
      "Epoch 2763/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9888 - reconstruction_loss: 308.9888 - kl_loss: 31.5779\n",
      "Epoch 2764/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0466 - reconstruction_loss: 309.0466 - kl_loss: 31.6460\n",
      "Epoch 2765/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0598 - reconstruction_loss: 309.0598 - kl_loss: 31.5989\n",
      "Epoch 2766/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1683 - reconstruction_loss: 309.1683 - kl_loss: 31.6229\n",
      "Epoch 2767/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1085 - reconstruction_loss: 309.1085 - kl_loss: 31.5651\n",
      "Epoch 2768/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0220 - reconstruction_loss: 309.0220 - kl_loss: 31.6176\n",
      "Epoch 2769/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0527 - reconstruction_loss: 309.0527 - kl_loss: 31.5893\n",
      "Epoch 2770/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9805 - reconstruction_loss: 308.9805 - kl_loss: 31.6262\n",
      "Epoch 2771/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1089 - reconstruction_loss: 309.1089 - kl_loss: 31.6338\n",
      "Epoch 2772/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1137 - reconstruction_loss: 309.1137 - kl_loss: 31.6231\n",
      "Epoch 2773/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1014 - reconstruction_loss: 309.1014 - kl_loss: 31.6644\n",
      "Epoch 2774/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0163 - reconstruction_loss: 309.0163 - kl_loss: 31.6046\n",
      "Epoch 2775/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0614 - reconstruction_loss: 309.0614 - kl_loss: 31.5770\n",
      "Epoch 2776/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0056 - reconstruction_loss: 309.0056 - kl_loss: 31.6434\n",
      "Epoch 2777/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0368 - reconstruction_loss: 309.0368 - kl_loss: 31.6397\n",
      "Epoch 2778/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0507 - reconstruction_loss: 309.0507 - kl_loss: 31.6075\n",
      "Epoch 2779/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9762 - reconstruction_loss: 308.9762 - kl_loss: 31.6386\n",
      "Epoch 2780/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0192 - reconstruction_loss: 309.0192 - kl_loss: 31.6512\n",
      "Epoch 2781/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0487 - reconstruction_loss: 309.0487 - kl_loss: 31.5991\n",
      "Epoch 2782/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1437 - reconstruction_loss: 309.1437 - kl_loss: 31.6576\n",
      "Epoch 2783/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9425 - reconstruction_loss: 308.9425 - kl_loss: 31.6633\n",
      "Epoch 2784/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9675 - reconstruction_loss: 308.9675 - kl_loss: 31.7030\n",
      "Epoch 2785/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1531 - reconstruction_loss: 309.1531 - kl_loss: 31.6564\n",
      "Epoch 2786/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0392 - reconstruction_loss: 309.0392 - kl_loss: 31.6415\n",
      "Epoch 2787/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1561 - reconstruction_loss: 309.1561 - kl_loss: 31.6587\n",
      "Epoch 2788/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9748 - reconstruction_loss: 308.9748 - kl_loss: 31.6855\n",
      "Epoch 2789/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9575 - reconstruction_loss: 308.9575 - kl_loss: 31.6829\n",
      "Epoch 2790/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8992 - reconstruction_loss: 308.8992 - kl_loss: 31.6653\n",
      "Epoch 2791/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0935 - reconstruction_loss: 309.0935 - kl_loss: 31.7137\n",
      "Epoch 2792/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9531 - reconstruction_loss: 308.9531 - kl_loss: 31.6971\n",
      "Epoch 2793/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9198 - reconstruction_loss: 308.9198 - kl_loss: 31.6771\n",
      "Epoch 2794/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1307 - reconstruction_loss: 309.1307 - kl_loss: 31.6505\n",
      "Epoch 2795/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0447 - reconstruction_loss: 309.0447 - kl_loss: 31.6436\n",
      "Epoch 2796/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0563 - reconstruction_loss: 309.0563 - kl_loss: 31.7380\n",
      "Epoch 2797/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0360 - reconstruction_loss: 309.0360 - kl_loss: 31.6473\n",
      "Epoch 2798/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9921 - reconstruction_loss: 308.9921 - kl_loss: 31.6998\n",
      "Epoch 2799/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1174 - reconstruction_loss: 309.1174 - kl_loss: 31.7122\n",
      "Epoch 2800/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9221 - reconstruction_loss: 308.9221 - kl_loss: 31.7408\n",
      "Epoch 2801/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1438 - reconstruction_loss: 309.1438 - kl_loss: 31.7374\n",
      "Epoch 2802/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9673 - reconstruction_loss: 308.9673 - kl_loss: 31.7445\n",
      "Epoch 2803/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9795 - reconstruction_loss: 308.9795 - kl_loss: 31.7506\n",
      "Epoch 2804/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0436 - reconstruction_loss: 309.0436 - kl_loss: 31.7270\n",
      "Epoch 2805/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0089 - reconstruction_loss: 309.0089 - kl_loss: 31.6926\n",
      "Epoch 2806/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9415 - reconstruction_loss: 308.9415 - kl_loss: 31.7174\n",
      "Epoch 2807/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9942 - reconstruction_loss: 308.9942 - kl_loss: 31.7217\n",
      "Epoch 2808/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0082 - reconstruction_loss: 309.0082 - kl_loss: 31.7879\n",
      "Epoch 2809/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0179 - reconstruction_loss: 309.0179 - kl_loss: 31.7224\n",
      "Epoch 2810/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1231 - reconstruction_loss: 309.1231 - kl_loss: 31.7254\n",
      "Epoch 2811/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9511 - reconstruction_loss: 308.9511 - kl_loss: 31.7270\n",
      "Epoch 2812/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0981 - reconstruction_loss: 309.0981 - kl_loss: 31.7234\n",
      "Epoch 2813/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0518 - reconstruction_loss: 309.0518 - kl_loss: 31.7264\n",
      "Epoch 2814/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9753 - reconstruction_loss: 308.9753 - kl_loss: 31.7571\n",
      "Epoch 2815/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1623 - reconstruction_loss: 309.1623 - kl_loss: 31.7881\n",
      "Epoch 2816/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9711 - reconstruction_loss: 308.9711 - kl_loss: 31.7860\n",
      "Epoch 2817/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9202 - reconstruction_loss: 308.9202 - kl_loss: 31.7450\n",
      "Epoch 2818/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9636 - reconstruction_loss: 308.9636 - kl_loss: 31.7354\n",
      "Epoch 2819/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0699 - reconstruction_loss: 309.0699 - kl_loss: 31.7731\n",
      "Epoch 2820/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0325 - reconstruction_loss: 309.0325 - kl_loss: 31.8180\n",
      "Epoch 2821/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0473 - reconstruction_loss: 309.0473 - kl_loss: 31.7707\n",
      "Epoch 2822/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9924 - reconstruction_loss: 308.9924 - kl_loss: 31.7542\n",
      "Epoch 2823/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9873 - reconstruction_loss: 308.9873 - kl_loss: 31.7959\n",
      "Epoch 2824/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0485 - reconstruction_loss: 309.0485 - kl_loss: 31.8017\n",
      "Epoch 2825/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9817 - reconstruction_loss: 308.9817 - kl_loss: 31.7447\n",
      "Epoch 2826/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0983 - reconstruction_loss: 309.0983 - kl_loss: 31.7916\n",
      "Epoch 2827/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9863 - reconstruction_loss: 308.9863 - kl_loss: 31.7558\n",
      "Epoch 2828/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0748 - reconstruction_loss: 309.0748 - kl_loss: 31.7973\n",
      "Epoch 2829/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0401 - reconstruction_loss: 309.0401 - kl_loss: 31.7831\n",
      "Epoch 2830/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0550 - reconstruction_loss: 309.0550 - kl_loss: 31.7714\n",
      "Epoch 2831/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0337 - reconstruction_loss: 309.0337 - kl_loss: 31.8304\n",
      "Epoch 2832/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9409 - reconstruction_loss: 308.9409 - kl_loss: 31.7886\n",
      "Epoch 2833/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9658 - reconstruction_loss: 308.9658 - kl_loss: 31.7958\n",
      "Epoch 2834/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8043 - reconstruction_loss: 308.8043 - kl_loss: 31.8205\n",
      "Epoch 2835/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9905 - reconstruction_loss: 308.9905 - kl_loss: 31.8205\n",
      "Epoch 2836/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0219 - reconstruction_loss: 309.0219 - kl_loss: 31.7723\n",
      "Epoch 2837/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9316 - reconstruction_loss: 308.9316 - kl_loss: 31.8003\n",
      "Epoch 2838/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0326 - reconstruction_loss: 309.0326 - kl_loss: 31.8168\n",
      "Epoch 2839/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9453 - reconstruction_loss: 308.9453 - kl_loss: 31.7797\n",
      "Epoch 2840/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0481 - reconstruction_loss: 309.0481 - kl_loss: 31.7962\n",
      "Epoch 2841/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9627 - reconstruction_loss: 308.9627 - kl_loss: 31.8932\n",
      "Epoch 2842/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9786 - reconstruction_loss: 308.9786 - kl_loss: 31.7768\n",
      "Epoch 2843/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0723 - reconstruction_loss: 309.0723 - kl_loss: 31.8262\n",
      "Epoch 2844/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9985 - reconstruction_loss: 308.9985 - kl_loss: 31.7912\n",
      "Epoch 2845/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9506 - reconstruction_loss: 308.9506 - kl_loss: 31.8197\n",
      "Epoch 2846/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0172 - reconstruction_loss: 309.0172 - kl_loss: 31.7936\n",
      "Epoch 2847/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9411 - reconstruction_loss: 308.9411 - kl_loss: 31.8679\n",
      "Epoch 2848/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9867 - reconstruction_loss: 308.9867 - kl_loss: 31.7984\n",
      "Epoch 2849/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8914 - reconstruction_loss: 308.8914 - kl_loss: 31.8826\n",
      "Epoch 2850/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0892 - reconstruction_loss: 309.0892 - kl_loss: 31.8252\n",
      "Epoch 2851/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0867 - reconstruction_loss: 309.0867 - kl_loss: 31.8298\n",
      "Epoch 2852/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9860 - reconstruction_loss: 308.9860 - kl_loss: 31.8189\n",
      "Epoch 2853/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9815 - reconstruction_loss: 308.9815 - kl_loss: 31.8581\n",
      "Epoch 2854/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0488 - reconstruction_loss: 309.0488 - kl_loss: 31.8855\n",
      "Epoch 2855/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9737 - reconstruction_loss: 308.9737 - kl_loss: 31.8656\n",
      "Epoch 2856/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9244 - reconstruction_loss: 308.9244 - kl_loss: 31.8672\n",
      "Epoch 2857/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0046 - reconstruction_loss: 309.0046 - kl_loss: 31.8990\n",
      "Epoch 2858/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0173 - reconstruction_loss: 309.0173 - kl_loss: 31.8636\n",
      "Epoch 2859/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8894 - reconstruction_loss: 308.8894 - kl_loss: 31.8739\n",
      "Epoch 2860/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0183 - reconstruction_loss: 309.0183 - kl_loss: 31.8551\n",
      "Epoch 2861/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9094 - reconstruction_loss: 308.9094 - kl_loss: 31.8672\n",
      "Epoch 2862/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0252 - reconstruction_loss: 309.0252 - kl_loss: 31.8768\n",
      "Epoch 2863/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9248 - reconstruction_loss: 308.9248 - kl_loss: 31.9070\n",
      "Epoch 2864/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9597 - reconstruction_loss: 308.9597 - kl_loss: 31.8718\n",
      "Epoch 2865/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9438 - reconstruction_loss: 308.9438 - kl_loss: 31.8737\n",
      "Epoch 2866/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9183 - reconstruction_loss: 308.9183 - kl_loss: 31.8536\n",
      "Epoch 2867/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9641 - reconstruction_loss: 308.9641 - kl_loss: 31.9169\n",
      "Epoch 2868/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9082 - reconstruction_loss: 308.9082 - kl_loss: 31.9169\n",
      "Epoch 2869/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9610 - reconstruction_loss: 308.9610 - kl_loss: 31.8849\n",
      "Epoch 2870/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9104 - reconstruction_loss: 308.9104 - kl_loss: 31.8712\n",
      "Epoch 2871/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9008 - reconstruction_loss: 308.9008 - kl_loss: 31.9145\n",
      "Epoch 2872/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9359 - reconstruction_loss: 308.9359 - kl_loss: 31.9897\n",
      "Epoch 2873/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8499 - reconstruction_loss: 308.8499 - kl_loss: 31.9441\n",
      "Epoch 2874/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9605 - reconstruction_loss: 308.9605 - kl_loss: 31.8847\n",
      "Epoch 2875/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9980 - reconstruction_loss: 308.9980 - kl_loss: 31.9227\n",
      "Epoch 2876/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8807 - reconstruction_loss: 308.8807 - kl_loss: 31.8921\n",
      "Epoch 2877/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9595 - reconstruction_loss: 308.9595 - kl_loss: 31.9539\n",
      "Epoch 2878/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9134 - reconstruction_loss: 308.9134 - kl_loss: 31.9325\n",
      "Epoch 2879/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9411 - reconstruction_loss: 308.9411 - kl_loss: 31.8911\n",
      "Epoch 2880/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8790 - reconstruction_loss: 308.8790 - kl_loss: 31.8962\n",
      "Epoch 2881/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8724 - reconstruction_loss: 308.8724 - kl_loss: 32.0060\n",
      "Epoch 2882/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9551 - reconstruction_loss: 308.9551 - kl_loss: 31.9691\n",
      "Epoch 2883/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9911 - reconstruction_loss: 308.9911 - kl_loss: 31.9147\n",
      "Epoch 2884/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0282 - reconstruction_loss: 309.0282 - kl_loss: 31.9525\n",
      "Epoch 2885/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.1566 - reconstruction_loss: 309.1566 - kl_loss: 31.9696\n",
      "Epoch 2886/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9947 - reconstruction_loss: 308.9947 - kl_loss: 31.9824\n",
      "Epoch 2887/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9862 - reconstruction_loss: 308.9862 - kl_loss: 31.9438\n",
      "Epoch 2888/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9202 - reconstruction_loss: 308.9202 - kl_loss: 31.9839\n",
      "Epoch 2889/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8531 - reconstruction_loss: 308.8531 - kl_loss: 31.9578\n",
      "Epoch 2890/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9966 - reconstruction_loss: 308.9966 - kl_loss: 31.9740\n",
      "Epoch 2891/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8988 - reconstruction_loss: 308.8988 - kl_loss: 31.9290\n",
      "Epoch 2892/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8322 - reconstruction_loss: 308.8322 - kl_loss: 31.9934\n",
      "Epoch 2893/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8880 - reconstruction_loss: 308.8880 - kl_loss: 32.0012\n",
      "Epoch 2894/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9825 - reconstruction_loss: 308.9825 - kl_loss: 31.9748\n",
      "Epoch 2895/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8934 - reconstruction_loss: 308.8934 - kl_loss: 32.0257\n",
      "Epoch 2896/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0174 - reconstruction_loss: 309.0174 - kl_loss: 31.9857\n",
      "Epoch 2897/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8932 - reconstruction_loss: 308.8932 - kl_loss: 32.0048\n",
      "Epoch 2898/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8687 - reconstruction_loss: 308.8687 - kl_loss: 31.9649\n",
      "Epoch 2899/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9883 - reconstruction_loss: 308.9883 - kl_loss: 31.9869\n",
      "Epoch 2900/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0302 - reconstruction_loss: 309.0302 - kl_loss: 32.0445\n",
      "Epoch 2901/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9300 - reconstruction_loss: 308.9300 - kl_loss: 32.0511\n",
      "Epoch 2902/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8998 - reconstruction_loss: 308.8998 - kl_loss: 32.0153\n",
      "Epoch 2903/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9118 - reconstruction_loss: 308.9118 - kl_loss: 32.0546\n",
      "Epoch 2904/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9301 - reconstruction_loss: 308.9301 - kl_loss: 32.0308\n",
      "Epoch 2905/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0618 - reconstruction_loss: 309.0618 - kl_loss: 32.0680\n",
      "Epoch 2906/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8203 - reconstruction_loss: 308.8203 - kl_loss: 32.0222\n",
      "Epoch 2907/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9724 - reconstruction_loss: 308.9724 - kl_loss: 32.0653\n",
      "Epoch 2908/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0599 - reconstruction_loss: 309.0599 - kl_loss: 32.0644\n",
      "Epoch 2909/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0748 - reconstruction_loss: 309.0748 - kl_loss: 32.0737\n",
      "Epoch 2910/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0112 - reconstruction_loss: 309.0112 - kl_loss: 32.0868\n",
      "Epoch 2911/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8322 - reconstruction_loss: 308.8322 - kl_loss: 32.0039\n",
      "Epoch 2912/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9758 - reconstruction_loss: 308.9758 - kl_loss: 32.0167\n",
      "Epoch 2913/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8790 - reconstruction_loss: 308.8790 - kl_loss: 32.0687\n",
      "Epoch 2914/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8312 - reconstruction_loss: 308.8312 - kl_loss: 32.0767\n",
      "Epoch 2915/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9007 - reconstruction_loss: 308.9007 - kl_loss: 32.0937\n",
      "Epoch 2916/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8953 - reconstruction_loss: 308.8953 - kl_loss: 32.0675\n",
      "Epoch 2917/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0483 - reconstruction_loss: 309.0483 - kl_loss: 32.0922\n",
      "Epoch 2918/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9286 - reconstruction_loss: 308.9286 - kl_loss: 32.0659\n",
      "Epoch 2919/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8759 - reconstruction_loss: 308.8759 - kl_loss: 32.0505\n",
      "Epoch 2920/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9896 - reconstruction_loss: 308.9896 - kl_loss: 32.1081\n",
      "Epoch 2921/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0206 - reconstruction_loss: 309.0206 - kl_loss: 32.0679\n",
      "Epoch 2922/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8899 - reconstruction_loss: 308.8899 - kl_loss: 32.1073\n",
      "Epoch 2923/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.6792 - reconstruction_loss: 308.6792 - kl_loss: 32.0669\n",
      "Epoch 2924/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9497 - reconstruction_loss: 308.9497 - kl_loss: 32.0863\n",
      "Epoch 2925/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9238 - reconstruction_loss: 308.9238 - kl_loss: 32.1011\n",
      "Epoch 2926/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8895 - reconstruction_loss: 308.8895 - kl_loss: 32.0263\n",
      "Epoch 2927/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8690 - reconstruction_loss: 308.8690 - kl_loss: 32.0422\n",
      "Epoch 2928/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9589 - reconstruction_loss: 308.9589 - kl_loss: 32.0376\n",
      "Epoch 2929/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8524 - reconstruction_loss: 308.8524 - kl_loss: 32.1010\n",
      "Epoch 2930/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8317 - reconstruction_loss: 308.8317 - kl_loss: 32.0994\n",
      "Epoch 2931/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9074 - reconstruction_loss: 308.9074 - kl_loss: 32.0873\n",
      "Epoch 2932/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9673 - reconstruction_loss: 308.9673 - kl_loss: 32.0838\n",
      "Epoch 2933/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8487 - reconstruction_loss: 308.8487 - kl_loss: 32.0911\n",
      "Epoch 2934/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8689 - reconstruction_loss: 308.8689 - kl_loss: 32.1455\n",
      "Epoch 2935/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9618 - reconstruction_loss: 308.9618 - kl_loss: 32.0592\n",
      "Epoch 2936/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9371 - reconstruction_loss: 308.9371 - kl_loss: 32.1707\n",
      "Epoch 2937/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9541 - reconstruction_loss: 308.9541 - kl_loss: 32.1084\n",
      "Epoch 2938/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0642 - reconstruction_loss: 309.0642 - kl_loss: 32.1152\n",
      "Epoch 2939/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8553 - reconstruction_loss: 308.8553 - kl_loss: 32.0884\n",
      "Epoch 2940/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8733 - reconstruction_loss: 308.8733 - kl_loss: 32.1179\n",
      "Epoch 2941/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9292 - reconstruction_loss: 308.9292 - kl_loss: 32.1626\n",
      "Epoch 2942/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8967 - reconstruction_loss: 308.8967 - kl_loss: 32.1336\n",
      "Epoch 2943/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8070 - reconstruction_loss: 308.8070 - kl_loss: 32.1311\n",
      "Epoch 2944/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0032 - reconstruction_loss: 309.0032 - kl_loss: 32.1254\n",
      "Epoch 2945/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.7814 - reconstruction_loss: 308.7814 - kl_loss: 32.1115\n",
      "Epoch 2946/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9487 - reconstruction_loss: 308.9487 - kl_loss: 32.1378\n",
      "Epoch 2947/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8511 - reconstruction_loss: 308.8511 - kl_loss: 32.1251\n",
      "Epoch 2948/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9118 - reconstruction_loss: 308.9118 - kl_loss: 32.1158\n",
      "Epoch 2949/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9865 - reconstruction_loss: 308.9865 - kl_loss: 32.1827\n",
      "Epoch 2950/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9122 - reconstruction_loss: 308.9122 - kl_loss: 32.1939\n",
      "Epoch 2951/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0216 - reconstruction_loss: 309.0216 - kl_loss: 32.2156\n",
      "Epoch 2952/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9603 - reconstruction_loss: 308.9603 - kl_loss: 32.2337\n",
      "Epoch 2953/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8267 - reconstruction_loss: 308.8267 - kl_loss: 32.2067\n",
      "Epoch 2954/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8637 - reconstruction_loss: 308.8637 - kl_loss: 32.2423\n",
      "Epoch 2955/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8951 - reconstruction_loss: 308.8951 - kl_loss: 32.2314\n",
      "Epoch 2956/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9332 - reconstruction_loss: 308.9332 - kl_loss: 32.2402\n",
      "Epoch 2957/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.7378 - reconstruction_loss: 308.7378 - kl_loss: 32.2194\n",
      "Epoch 2958/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0019 - reconstruction_loss: 309.0019 - kl_loss: 32.2307\n",
      "Epoch 2959/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8587 - reconstruction_loss: 308.8587 - kl_loss: 32.1867\n",
      "Epoch 2960/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9551 - reconstruction_loss: 308.9551 - kl_loss: 32.2154\n",
      "Epoch 2961/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8713 - reconstruction_loss: 308.8713 - kl_loss: 32.2234\n",
      "Epoch 2962/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8520 - reconstruction_loss: 308.8520 - kl_loss: 32.1851\n",
      "Epoch 2963/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8381 - reconstruction_loss: 308.8381 - kl_loss: 32.1877\n",
      "Epoch 2964/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9623 - reconstruction_loss: 308.9623 - kl_loss: 32.2452\n",
      "Epoch 2965/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8636 - reconstruction_loss: 308.8636 - kl_loss: 32.2271\n",
      "Epoch 2966/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9386 - reconstruction_loss: 308.9386 - kl_loss: 32.2083\n",
      "Epoch 2967/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8013 - reconstruction_loss: 308.8013 - kl_loss: 32.2294\n",
      "Epoch 2968/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8742 - reconstruction_loss: 308.8742 - kl_loss: 32.2594\n",
      "Epoch 2969/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8939 - reconstruction_loss: 308.8939 - kl_loss: 32.2267\n",
      "Epoch 2970/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8167 - reconstruction_loss: 308.8167 - kl_loss: 32.2421\n",
      "Epoch 2971/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9035 - reconstruction_loss: 308.9035 - kl_loss: 32.2526\n",
      "Epoch 2972/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8202 - reconstruction_loss: 308.8202 - kl_loss: 32.2374\n",
      "Epoch 2973/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8710 - reconstruction_loss: 308.8710 - kl_loss: 32.2159\n",
      "Epoch 2974/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8788 - reconstruction_loss: 308.8788 - kl_loss: 32.2024\n",
      "Epoch 2975/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0060 - reconstruction_loss: 309.0060 - kl_loss: 32.2048\n",
      "Epoch 2976/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9095 - reconstruction_loss: 308.9095 - kl_loss: 32.2874\n",
      "Epoch 2977/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8790 - reconstruction_loss: 308.8790 - kl_loss: 32.2196\n",
      "Epoch 2978/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8069 - reconstruction_loss: 308.8069 - kl_loss: 32.2837\n",
      "Epoch 2979/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9041 - reconstruction_loss: 308.9041 - kl_loss: 32.2810\n",
      "Epoch 2980/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9796 - reconstruction_loss: 308.9796 - kl_loss: 32.2861\n",
      "Epoch 2981/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8281 - reconstruction_loss: 308.8281 - kl_loss: 32.2785\n",
      "Epoch 2982/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8903 - reconstruction_loss: 308.8903 - kl_loss: 32.2979\n",
      "Epoch 2983/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9034 - reconstruction_loss: 308.9034 - kl_loss: 32.2525\n",
      "Epoch 2984/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9273 - reconstruction_loss: 308.9273 - kl_loss: 32.2977\n",
      "Epoch 2985/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 309.0284 - reconstruction_loss: 309.0284 - kl_loss: 32.2713\n",
      "Epoch 2986/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8501 - reconstruction_loss: 308.8501 - kl_loss: 32.2717\n",
      "Epoch 2987/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8526 - reconstruction_loss: 308.8526 - kl_loss: 32.3126\n",
      "Epoch 2988/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8520 - reconstruction_loss: 308.8520 - kl_loss: 32.3060\n",
      "Epoch 2989/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9125 - reconstruction_loss: 308.9125 - kl_loss: 32.2713\n",
      "Epoch 2990/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8823 - reconstruction_loss: 308.8823 - kl_loss: 32.2447\n",
      "Epoch 2991/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8251 - reconstruction_loss: 308.8251 - kl_loss: 32.3259\n",
      "Epoch 2992/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8561 - reconstruction_loss: 308.8561 - kl_loss: 32.2465\n",
      "Epoch 2993/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9037 - reconstruction_loss: 308.9037 - kl_loss: 32.3513\n",
      "Epoch 2994/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9718 - reconstruction_loss: 308.9718 - kl_loss: 32.3253\n",
      "Epoch 2995/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.9464 - reconstruction_loss: 308.9464 - kl_loss: 32.3131\n",
      "Epoch 2996/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.7550 - reconstruction_loss: 308.7550 - kl_loss: 32.3365\n",
      "Epoch 2997/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8307 - reconstruction_loss: 308.8307 - kl_loss: 32.3187\n",
      "Epoch 2998/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8233 - reconstruction_loss: 308.8233 - kl_loss: 32.3426\n",
      "Epoch 2999/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8287 - reconstruction_loss: 308.8287 - kl_loss: 32.3519\n",
      "Epoch 3000/3000\n",
      "166/166 [==============================] - 3s 19ms/step - loss: 308.8889 - reconstruction_loss: 308.8889 - kl_loss: 32.3597\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    for f_size in [10]:\n",
    "        for latent_dim in [128]:\n",
    "            filter_size = (f_size, 4)\n",
    "            model_path = os.path.join(model_root, ckpt_num, 'fsize'+str(f_size)+'_'+'latentdim'+str(latent_dim)+'_'+'beta'+str(beta)+'_'+'lr'+str(lr)+'.h5')\n",
    "            hist_path = os.path.join(model_root, ckpt_num, 'fsize'+str(f_size)+'_'+'latentdim'+str(latent_dim)+'_'+'beta'+str(beta)+'_'+'lr'+str(lr))\n",
    "            encoder_inputs = keras.Input(shape=input_size)\n",
    "            x = layers.Conv2D(width, filter_size, activation=\"sigmoid\", strides=(2,1), padding=\"same\")(encoder_inputs)\n",
    "            x = layers.Conv2D(width, filter_size, activation=\"sigmoid\", strides=(2,1), padding=\"same\")(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            x = layers.Conv2D(width, filter_size, activation=\"sigmoid\", strides=(2,1), padding=\"same\")(x)\n",
    "            x = layers.Flatten()(x)\n",
    "            x = layers.Dense(width, activation=\"relu\")(x)\n",
    "            z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "            z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "            z = Sampling()([z_mean, z_log_var])\n",
    "            encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "\n",
    "            latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "            x = layers.Dense(19 * 4 * width, activation=\"relu\")(latent_inputs)\n",
    "            x = layers.Reshape((19, 4, width))(x)\n",
    "            x = layers.Conv2DTranspose(width, filter_size, strides=(2, 1), padding=\"same\")(x)\n",
    "            x = layers.Conv2DTranspose(width, filter_size, strides=(2, 1), padding=\"same\")(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            x = layers.Cropping2D(cropping=((0, 1), (0, 0)))(x)\n",
    "            x = layers.Conv2DTranspose(width, filter_size, strides=(2, 1), padding=\"same\")(x)\n",
    "            decoder_outputs = layers.Conv2D(1, filter_size, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "            decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "            print(decoder.summary())\n",
    "            vae = VAE(encoder, decoder, beta)\n",
    "            vae.compile(optimizer=keras.optimizers.Adam(lr))\n",
    "            history = vae.fit(train_reads, epochs=epochs, batch_size=batch_size, verbose =1)\n",
    "            with open(hist_path, 'wb') as f:\n",
    "                pickle.dump(history.history, f)\n",
    "            encoder.save(model_path)\n",
    "            \n",
    "            fig, ax1 = plt.subplots()\n",
    "            ax1.plot(history.history['reconstruction_loss'], color='green')\n",
    "            ax1.plot(history.history['loss'], color='red')\n",
    "\n",
    "\n",
    "            ax2 = ax1.twinx()\n",
    "            ax2.plot(history.history['kl_loss'])\n",
    "            plot_path = os.path.join(plot_root, 'fsize'+str(f_size)+'_'+'latentdim'+str(latent_dim)+'_'+'beta'+str(beta)+'_'+'lr'+str(lr)+'_loss''.png')\n",
    "            plt.savefig(plot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
