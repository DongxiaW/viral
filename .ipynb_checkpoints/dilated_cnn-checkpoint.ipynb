{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Viral vs. Human Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import keras.backend as K\n",
    "from keras import models\n",
    "import os\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.utils import multi_gpu_model \n",
    "import matplotlib.pylab as plt\n",
    "from skimage.transform import resize\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from IPython.display import SVG\n",
    "from tqdm import tnrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encodings are as follows:\n",
    "1. A = [1, 0, 0, 0, 0]\n",
    "2. C = [0, 1, 0, 0, 0]\n",
    "3. G = [0, 0, 1, 0, 0]\n",
    "4. N = [0, 0, 0, 1, 0]\n",
    "5. T = [0, 0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/ecvol/data/viral/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (1674000, 150, 5, 1) Y_train shape:  (1674000,) X_test shape (1010000, 150, 5, 1)\n"
     ]
    }
   ],
   "source": [
    "X_test = np.load(root_dir + 'test_set.npy')\n",
    "Y_test = np.load(root_dir + 'test_set_label.npy')\n",
    "X_train = np.load(root_dir + 'train_set.npy')\n",
    "Y_train = np.load(root_dir + 'train_set_label.npy')\n",
    "print(\"X_train shape: \", X_train.shape, \"Y_train shape: \", Y_train.shape, \"X_test shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "674000 reads from 337 hpv references\n",
    "1M reads from chr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of filters:  64 ; K-Mer size: 10\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 5, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 150, 5, 64)        3264      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 150, 5, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 150, 5, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 150, 5, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 150, 5, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 150, 5, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 150, 5, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 150, 5, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 150, 5, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 150, 5, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 150, 5, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 150, 5, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 150, 5, 64)        20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 150, 5, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 150, 5, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 48000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 48001     \n",
      "=================================================================\n",
      "Total params: 1,097,921\n",
      "Trainable params: 1,097,025\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1339200 samples, validate on 334800 samples\n",
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "sample = open('results.txt', 'w') \n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)\n",
    "split = kfold.split(X_train, Y_train)\n",
    "train, test = next(split)\n",
    "\n",
    "earlystopper = EarlyStopping(monitor='train_loss', patience=7, verbose=1)\n",
    "for num_filters in [64]:\n",
    "    for kmer_size in [10]:\n",
    "        print(\"Number of filters: \", num_filters, \"; K-Mer size:\", kmer_size, file = sample)\n",
    "        print(\"Number of filters: \", num_filters, \"; K-Mer size:\", kmer_size)\n",
    "        inputs = Input(shape=(150,5,1))\n",
    "        x = Conv2D(64, kernel_size=(kmer_size,5), activation='relu', dilation_rate = (1,1), padding='same')(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(64, kernel_size=(kmer_size,5), activation='relu', dilation_rate = (1,1), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(64, kernel_size=(kmer_size,5), activation='relu', dilation_rate = (2,1), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(64, kernel_size=(kmer_size,5), activation='relu', dilation_rate = (4,1), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(64, kernel_size=(kmer_size,5), activation='relu', dilation_rate = (8,1), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(64, kernel_size=(kmer_size,5), activation='relu', dilation_rate = (1,1), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(64, kernel_size=(1,5), activation='relu', dilation_rate = (1,1), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Flatten()(x)\n",
    "        outputs = Dense(1, activation='sigmoid')(x)\n",
    "        model = Model(inputs=[inputs], outputs=[outputs])\n",
    "        print(model.summary())\n",
    "        model = multi_gpu_model(model, gpus=8)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        history = model.fit(X_train[train], Y_train[train], epochs=50, validation_data=(X_train[test], Y_train[test]), \n",
    "                  batch_size=5000, verbose=1, callbacks=[earlystopper])\n",
    "sample.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"viral_pred.h5\")\n",
    "print(history.history.keys())\n",
    "# #  \"Accuracy\"\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 150, 5, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 150, 5, 64)        3264      \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 150, 5, 64)        204864    \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 150, 5, 64)        204864    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 150, 5, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 48000)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 48001     \n",
      "=================================================================\n",
      "Total params: 460,993\n",
      "Trainable params: 460,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model.layers[-2]\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test, verbose=1)\n",
    "Y_test = Y_test == 1\n",
    "print(Y_test[:10], Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = []\n",
    "R = []\n",
    "E = []\n",
    "num_viral = 10000\n",
    "num_hum = 1000000\n",
    "for t in [0.1, 0.2, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95]:\n",
    "    temp = (predictions > t)\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    for i,j in zip(temp, Y_test):\n",
    "        if (i and j):\n",
    "            TP += 1\n",
    "        if (i and not j):\n",
    "            FP += 1\n",
    "    \n",
    "    FN = num_viral - TP\n",
    "    P.append(TP / (TP + FP))\n",
    "    R.append(TP / (TP + FN))\n",
    "    E.append(1 - (FP/(num_hum)))\n",
    "sns.lineplot(R, P)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()\n",
    "sns.lineplot(R, E)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Efficiency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def de_transform(one_hot):\n",
    "    one_hot = np.squeeze(one_hot)\n",
    "    mapping = dict(zip(range(5), 'ACGNT'))\n",
    "    sequences = []\n",
    "    for idx, i in enumerate(one_hot):\n",
    "        seq = np.argmax(i, axis=1)\n",
    "        seq = [mapping[j] for j in seq]\n",
    "        sequences.append(''.join(seq))\n",
    "    return np.array(sequences)\n",
    "\n",
    "def hamming_distance(train, test): \n",
    "    def distance(s1, s2):\n",
    "        return sum(ch1 != ch2 for ch1,ch2 in zip(s1,s2))\n",
    "    \n",
    "    ham_matrix = np.zeros((len(train), len(test)))\n",
    "    for te_id, te in enumerate(test):\n",
    "        for tr_id, tr in enumerate(train):\n",
    "            ham_matrix[tr_id][te_id] = distance(te, tr)\n",
    "    return ham_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
