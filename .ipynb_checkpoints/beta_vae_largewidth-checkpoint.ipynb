{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import re, random, pickle, glob, os, difflib\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from utils import *\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root = 'train/'\n",
    "test_root = 'test/'\n",
    "model_root = 'models/'\n",
    "plot_root = 'beta_plots/'\n",
    "train_set = ['x10_reads.fa']\n",
    "test_sets = ['test_easy_1.fa', 'test_easy_2.fa', 'test_intermidate_1.fa', 'test_intermidate_2.fa', 'test_difficult_1.fa', \n",
    "             'test_difficult_2.fa', 'test_very_difficult_1.fa', 'test_very_difficult_2.fa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(169538, 150, 4, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_fasta(train_root + train_set[0])\n",
    "train_reads_original = np.array(seqs2onehot(np.array(df.seqs)))\n",
    "train_reads = np.delete(train_reads_original,3,axis=2)\n",
    "train_reads = np.expand_dims(train_reads, -1)\n",
    "train_reads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        output = z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, beta, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.beta = beta\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = encoder(data)\n",
    "            reconstruction = decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(data, reconstruction)\n",
    "            )\n",
    "            reconstruction_loss *= 150 * 4\n",
    "            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "            kl_loss = -0.5*tf.reduce_mean(kl_loss)\n",
    "            total_loss = reconstruction_loss + beta * kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "        }\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7')\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128\n",
    "width = 1024\n",
    "input_size = (150,4,1)\n",
    "filter_size = (6, 4) \n",
    "epochs = 75\n",
    "batch_size = 1024\n",
    "beta = 10e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_num = 'beta_vae_largewidth'\n",
    "ckpt_dir = os.path.join(model_root, ckpt_num, '')\n",
    "if (os.path.isdir(ckpt_dir) == False):\n",
    "    os.mkdir(os.path.join(ckpt_dir, ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, 150, 4, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 75, 4, 1024)  25600       input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 307200)       0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 128)          39321728    flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 128)          16512       dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 128)          16512       dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sampling_4 (Sampling)           (None, 128)          0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 39,380,352\n",
      "Trainable params: 39,380,352\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Model: \"decoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 38912)        5019648     input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 38, 4, 256)   0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTrans (None, 76, 4, 128)   786560      reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_4 (Cropping2D)       (None, 75, 4, 128)   0           conv2d_transpose_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTrans (None, 150, 4, 64)   196672      cropping2d_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_15 (InputLayer)           [(None, 75, 4, 256)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 150, 4, 1)    1537        conv2d_transpose_9[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 6,004,417\n",
      "Trainable params: 6,004,417\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/75\n",
      "INFO:tensorflow:batch_all_reduce: 16 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 16 all-reduces with algorithm = nccl, num_packs = 1\n",
      "166/166 [==============================] - 18s 106ms/step - loss: 336.9987 - reconstruction_loss: 336.9987 - kl_loss: 1.5428\n",
      "Epoch 2/75\n",
      "166/166 [==============================] - 18s 107ms/step - loss: 335.3557 - reconstruction_loss: 335.3557 - kl_loss: 1.8555\n",
      "Epoch 3/75\n",
      "105/166 [=================>............] - ETA: 6s - loss: 335.3436 - reconstruction_loss: 335.3436 - kl_loss: 1.6326"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-9cd274cef544>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mvae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_reads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/ecseg/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/ecseg/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/ecseg/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/ecseg/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/ecseg/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/ecseg/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/ecseg/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/ecseg/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/envs/ecseg/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    for f_size in [6]:\n",
    "        for latent_dim in [128]:\n",
    "            filter_size = (f_size, 4)\n",
    "            model_path = os.path.join(model_root, ckpt_num, str(f_size)+'_'+str(latent_dim)+'_'+str(beta)+'.h5')\n",
    "            hist_path = os.path.join(model_root, ckpt_num, str(f_size)+'_'+str(latent_dim)+'_'+str(beta))\n",
    "            encoder_inputs = keras.Input(shape=input_size)\n",
    "            c1 = layers.Conv2D(1024, filter_size, strides=(2, 1), activation=\"sigmoid\", padding=\"same\")(encoder_inputs)\n",
    "            x = layers.Flatten()(c1)\n",
    "            x = layers.Dense(128, activation=\"sigmoid\")(x)\n",
    "            z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "            z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "            z = Sampling()([z_mean, z_log_var])\n",
    "            encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "            print(encoder.summary())\n",
    "            \n",
    "            latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "            skip = keras.Input(shape=(75,4,256))\n",
    "            x = layers.Dense(38 * 4 * 256, activation=\"sigmoid\")(latent_inputs)\n",
    "            x = layers.Reshape((38, 4, 256))(x)\n",
    "            x = layers.Conv2DTranspose(128, filter_size, strides=(2, 1), activation=\"sigmoid\", padding=\"same\")(x)\n",
    "            x = layers.Cropping2D(cropping=((0, 1), (0, 0)))(x)\n",
    "            x = layers.Conv2DTranspose(64, filter_size, strides=(2, 1), activation=\"sigmoid\", padding=\"same\")(x)\n",
    "            decoder_outputs = layers.Conv2D(1, filter_size, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "            decoder = keras.Model([latent_inputs, skip], decoder_outputs, name=\"decoder\")\n",
    "            print(decoder.summary())\n",
    "            \n",
    "            vae = VAE(encoder, decoder,beta)\n",
    "            vae.compile(optimizer=keras.optimizers.Adam(0.001))\n",
    "            history = vae.fit(train_reads, epochs=epochs, batch_size=batch_size, verbose =1)\n",
    "            with open(hist_path, 'wb') as f:\n",
    "                pickle.dump(history.history, f)\n",
    "            encoder.save(model_path)\n",
    "            \n",
    "            fig, ax1 = plt.subplots()\n",
    "            ax1.plot(history.history['reconstruction_loss'], color='green')\n",
    "            ax1.plot(history.history['loss'], color='red')\n",
    "\n",
    "\n",
    "            ax2 = ax1.twinx()\n",
    "            ax2.plot(history.history['kl_loss'])\n",
    "            plot_path = os.path.join(plot_root, str(f_size)+'_'+str(latent_dim)+'_'+str(beta)+'_loss''.png')\n",
    "            plt.savefig(plot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105492, 2)\n"
     ]
    }
   ],
   "source": [
    "easy_1 = assign_labels(read_fasta(test_root + test_sets[0]), True)\n",
    "test_reads_1 = np.array(seqs2onehot(np.array(easy_1.seqs)))\n",
    "test_reads_1 = np.delete(test_reads_1, 3, axis=2)\n",
    "test_reads_1 = np.expand_dims(test_reads_1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 75, 4, 256) for input Tensor(\"input_6:0\", shape=(None, 75, 4, 256), dtype=float32), but it was called on an input with incompatible shape (None, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 75, 4, 256) for input Tensor(\"input_6:0\", shape=(None, 75, 4, 256), dtype=float32), but it was called on an input with incompatible shape (None, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 75, 4, 256) for input Tensor(\"input_6:0\", shape=(None, 75, 4, 256), dtype=float32), but it was called on an input with incompatible shape (None, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 75, 4, 256) for input Tensor(\"input_6:0\", shape=(None, 75, 4, 256), dtype=float32), but it was called on an input with incompatible shape (None, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 75, 4, 256) for input Tensor(\"input_6:0\", shape=(None, 75, 4, 256), dtype=float32), but it was called on an input with incompatible shape (None, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 75, 4, 256) for input Tensor(\"input_6:0\", shape=(None, 75, 4, 256), dtype=float32), but it was called on an input with incompatible shape (None, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 75, 4, 256) for input Tensor(\"input_6:0\", shape=(None, 75, 4, 256), dtype=float32), but it was called on an input with incompatible shape (None, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 75, 4, 256) for input Tensor(\"input_6:0\", shape=(None, 75, 4, 256), dtype=float32), but it was called on an input with incompatible shape (None, 8).\n",
      "3297/3297 [==============================] - 13s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "r1 = vae.predict(test_reads_1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3297/3297 [==============================] - 11s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "r2 = encoder.predict(test_reads_1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105492, 8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105492, 150, 4, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vclass = 1\n",
    "l = keras.losses.binary_crossentropy(test_reads_1[np.array(easy_1.viral==vclass)], r1[np.array(easy_1.viral==vclass)])\n",
    "x = tf.reduce_mean(l, [1,2])*600\n",
    "plt.hist(np.array(x)); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vclass = 2\n",
    "l = keras.losses.binary_crossentropy(test_reads_1[np.array(easy_1.viral==vclass)], r1[np.array(easy_1.viral==vclass)])\n",
    "x = tf.reduce_mean(l, [1,2])*600\n",
    "plt.hist(np.array(x)); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vclass = 0\n",
    "l = keras.losses.binary_crossentropy(test_reads_1[np.array(easy_1.viral==vclass)], r1[np.array(easy_1.viral==vclass)])\n",
    "x = tf.reduce_mean(l, [1,2])*600\n",
    "plt.hist(np.array(x)); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
